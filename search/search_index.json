{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introduction \u00b6 When I switched to data science, I built my digital garden, datumorphism . I deliberately designed this digital garden as my second brain. As a result, most of the articles are fragments of knowledge and require context to understand them. Making bricks is easy but assembling them into a house is not easy. So I have decided to use this repository to practice my house-building techniques. I do not have a finished blueprint yet. But I have a framework in my mind: I want to consolidate some of my thoughts and learnings in a good way. However, I do not want to compile a reference book, as datumorphism already serves this purpose. I should create stories. Open Source \u00b6 This is an open source project on GitHub: emptymalei/deep-learning . How Do I Write It \u00b6 I am trying out a more \"agile\" method. Instead of finishing the whole project at once, I will release the book by chapter. A few thoughts on this plan: Each new section should be a PR. Every PR is reviewed. Release on every new section. Blueprint \u00b6 The following is an initial design of the blueprint. Tech Onboarding Python, Environment, VSCode, Git, ... Pytorch Lightning Time Series Data Datasets Data Generating Process (DGP) Data Processing Data Augmentation Metrics Tasks Forecasting Classification Generation Models (Focus on Deep Models) AR and Variants RNN, e.g., LSTM DeepAR Conformal Prediction Transformer Spatial-temporal Models, e.g., GNN Energy-based Models Self-supervised Learning Graph Neural Networks Other Topics Graph Neural Networks Spiking Neural Networks Transformers","title":"Home"},{"location":"#introduction","text":"When I switched to data science, I built my digital garden, datumorphism . I deliberately designed this digital garden as my second brain. As a result, most of the articles are fragments of knowledge and require context to understand them. Making bricks is easy but assembling them into a house is not easy. So I have decided to use this repository to practice my house-building techniques. I do not have a finished blueprint yet. But I have a framework in my mind: I want to consolidate some of my thoughts and learnings in a good way. However, I do not want to compile a reference book, as datumorphism already serves this purpose. I should create stories.","title":"Introduction"},{"location":"#open-source","text":"This is an open source project on GitHub: emptymalei/deep-learning .","title":" Open Source"},{"location":"#how-do-i-write-it","text":"I am trying out a more \"agile\" method. Instead of finishing the whole project at once, I will release the book by chapter. A few thoughts on this plan: Each new section should be a PR. Every PR is reviewed. Release on every new section.","title":" How Do I Write It"},{"location":"#blueprint","text":"The following is an initial design of the blueprint. Tech Onboarding Python, Environment, VSCode, Git, ... Pytorch Lightning Time Series Data Datasets Data Generating Process (DGP) Data Processing Data Augmentation Metrics Tasks Forecasting Classification Generation Models (Focus on Deep Models) AR and Variants RNN, e.g., LSTM DeepAR Conformal Prediction Transformer Spatial-temporal Models, e.g., GNN Energy-based Models Self-supervised Learning Graph Neural Networks Other Topics Graph Neural Networks Spiking Neural Networks Transformers","title":" Blueprint"},{"location":"changelog/","text":"Daily Plan \u00b6 2023.01.11 1-3pm rest 3-5pm Web design 5-7pm cook 8-9pm send e-mail asking for equipment/ accept offer","title":"Plan"},{"location":"changelog/#daily-plan","text":"2023.01.11 1-3pm rest 3-5pm Web design 5-7pm cook 8-9pm send e-mail asking for equipment/ accept offer","title":" Daily Plan"},{"location":"tags/","text":"Tags \u00b6 Following is a list of relevant tags:","title":"Tags"},{"location":"tags/#tags","text":"Following is a list of relevant tags:","title":"Tags"},{"location":"Lattice%20dynamics/","text":"Introduction \u00b6 The large lattice dynamics in MHPs is a distinguishing property compared to conventional semiconductors such as silicon and gallium arsenide. One the one hand, it is proved in both experiment and theory, the crystal structure has a big impact on MHPs' optoelectronic properties such as bandgap. Structral phase transitions have long been studied in MHPs. However, the local dynamics disorder of MHPs creates domains with cubic phase and tetragonal phase at high temperature, which makes the understanding of structral phase be dynamic rather than static and so does the structral phase transition. The nature of structral phase transition is generally understood as a zone-center or zone-boundary softening phonon freezing the distortion in lower symmetry. And the soft phonons that drives the phase transition in these materials remain largely unexplored. On the other hand, When I switched to data science, I built my digital garden, datumorphism . I deliberately designed this digital garden as my second brain. As a result, most of the articles are fragments of knowledge and require context to understand them. Making bricks is easy but assembling them into a house is not easy. So I have decided to use this repository to practice my house-building techniques. I do not have a finished blueprint yet. But I have a framework in my mind: I want to consolidate some of my thoughts and learnings in a good way. However, I do not want to compile a reference book, as datumorphism already serves this purpose. I should create stories. Open Source \u00b6 This is an open source project on GitHub: emptymalei/deep-learning . How Do I Write It \u00b6 I am trying out a more \"agile\" method. Instead of finishing the whole project at once, I will release the book by chapter. A few thoughts on this plan: Each new section should be a PR. Every PR is reviewed. Release on every new section. Blueprint \u00b6 The following is an initial design of the blueprint. Tech Onboarding Python, Environment, VSCode, Git, ... Pytorch Lightning Time Series Data Datasets Data Generating Process (DGP) Data Processing Data Augmentation Metrics Tasks Forecasting Classification Generation Models (Focus on Deep Models) AR and Variants RNN, e.g., LSTM DeepAR Conformal Prediction Transformer Spatial-temporal Models, e.g., GNN Energy-based Models Self-supervised Learning Graph Neural Networks Other Topics Graph Neural Networks Spiking Neural Networks Transformers","title":"Cs2AgBiBr6"},{"location":"Lattice%20dynamics/#introduction","text":"The large lattice dynamics in MHPs is a distinguishing property compared to conventional semiconductors such as silicon and gallium arsenide. One the one hand, it is proved in both experiment and theory, the crystal structure has a big impact on MHPs' optoelectronic properties such as bandgap. Structral phase transitions have long been studied in MHPs. However, the local dynamics disorder of MHPs creates domains with cubic phase and tetragonal phase at high temperature, which makes the understanding of structral phase be dynamic rather than static and so does the structral phase transition. The nature of structral phase transition is generally understood as a zone-center or zone-boundary softening phonon freezing the distortion in lower symmetry. And the soft phonons that drives the phase transition in these materials remain largely unexplored. On the other hand, When I switched to data science, I built my digital garden, datumorphism . I deliberately designed this digital garden as my second brain. As a result, most of the articles are fragments of knowledge and require context to understand them. Making bricks is easy but assembling them into a house is not easy. So I have decided to use this repository to practice my house-building techniques. I do not have a finished blueprint yet. But I have a framework in my mind: I want to consolidate some of my thoughts and learnings in a good way. However, I do not want to compile a reference book, as datumorphism already serves this purpose. I should create stories.","title":"Introduction"},{"location":"Lattice%20dynamics/#open-source","text":"This is an open source project on GitHub: emptymalei/deep-learning .","title":" Open Source"},{"location":"Lattice%20dynamics/#how-do-i-write-it","text":"I am trying out a more \"agile\" method. Instead of finishing the whole project at once, I will release the book by chapter. A few thoughts on this plan: Each new section should be a PR. Every PR is reviewed. Release on every new section.","title":" How Do I Write It"},{"location":"Lattice%20dynamics/#blueprint","text":"The following is an initial design of the blueprint. Tech Onboarding Python, Environment, VSCode, Git, ... Pytorch Lightning Time Series Data Datasets Data Generating Process (DGP) Data Processing Data Augmentation Metrics Tasks Forecasting Classification Generation Models (Focus on Deep Models) AR and Variants RNN, e.g., LSTM DeepAR Conformal Prediction Transformer Spatial-temporal Models, e.g., GNN Energy-based Models Self-supervised Learning Graph Neural Networks Other Topics Graph Neural Networks Spiking Neural Networks Transformers","title":" Blueprint"},{"location":"Lattice%20dynamics/Sample_preparation/","text":"MAPbI \\(_3\\) and MAPbBr \\(_3\\) were made into 1 M solutions with DMF : DMSO = 3 : 1. The solutions were stirred for 12 hours before being mixed into MAPbI \\(_{1.5}\\) Br \\(_{1.5}\\) , MAPb(I \\(_{0.33}\\) Br \\(_{0.67}\\) ) \\(_3\\) , and MAPb(I \\(_{0.67}\\) Br \\(_{0.33}\\) ) \\(_3\\) . The mixed solutions were then spin-coated onto SiN \\(_x\\) windows. Glass substrates were washed and plasma cleaned for holding the SiN \\(_x\\) windows. The condition is RPM = 4000, T = 1 min. Then the films were annealed at 110 \\(^o\\) C for 15 mins. The Cs \\(_y\\) FA \\(_{1-y}\\) Pb(Br \\(_x\\) I \\(_{1-x}\\) ) \\(_3\\) series were made with the same method except that the spin-coating condition is RPM = 4000, T = 2 mins and the annealing condition is 140 \\(^o\\) C (15 or 30 mins). Spin-coated perovskite films on SiN windows.","title":"Sample preparation"},{"location":"RSoXS/","text":"Introduction \u00b6 In this book, we focus on python-based deep learning projects. In the main chapters, we will focus on the theories and actual code. Thus all the tech stack related topics are shoved into this chapter as references. (a) PL measurement of mixed halide perovskite films. (b) Illustration of light induced phase segregation. Info This chapter is not aiming to be a comprehensive note on these technologies but a few key components that may be missing in many research oriented data science tech stacks. We assume the readers have worked with the essential technologies in a python-based deep learning project. A Checklist of Tech Stack for This Book Git IDE Visual Studio Code PyCharm Jupyter Python Environment Management Conda Pyenv Poetry Test Pytest Code quality tools Formatter: black , isort Linter: pylint , flake8 , mypy , pylama pre-commit Docstring Machine Learning Related Pandas Pytorch Pytorch Lightning","title":"Introduction"},{"location":"RSoXS/#introduction","text":"In this book, we focus on python-based deep learning projects. In the main chapters, we will focus on the theories and actual code. Thus all the tech stack related topics are shoved into this chapter as references. (a) PL measurement of mixed halide perovskite films. (b) Illustration of light induced phase segregation. Info This chapter is not aiming to be a comprehensive note on these technologies but a few key components that may be missing in many research oriented data science tech stacks. We assume the readers have worked with the essential technologies in a python-based deep learning project. A Checklist of Tech Stack for This Book Git IDE Visual Studio Code PyCharm Jupyter Python Environment Management Conda Pyenv Poetry Test Pytest Code quality tools Formatter: black , isort Linter: pylint , flake8 , mypy , pylama pre-commit Docstring Machine Learning Related Pandas Pytorch Pytorch Lightning","title":"Introduction"},{"location":"RSoXS/Beam_damage/","text":"","title":"Beam damage"},{"location":"RSoXS/Compositional_heterogeneity/","text":"","title":"Compositional heterogeneity"},{"location":"RSoXS/Contrast_function%20copy%204/","text":"ALS beamline 11.0.1.2 is capable of doing soft X-ray absorption from 165 - 1500 eV in both transmission and total electron yield(TEY) mode with polarization control. A CCD detector and a photodiode are installed in a vacuum chamber with the sample stage. The sample-detector distance is tunable and the q range is from 0.001 to 0.7 \\AA. The light exposure device can be fixed at the window of the chamber which gives a 45 \\(^o\\) incident angle when the sample was set to be perpendicular to the incoming X-Ray. The perovskite films were prepared at Berkeley Lab Molecular Foundry and transferred to the ALS beamline in 15 minutes. It takes around 30-40 minutes to pump down the chamber and cool down the CCD camera. So the samples were exposed to air for \\(\\sim\\) 20 minutes. This may lead to degradation for MAPbBr \\(_3\\) and MAPbI \\(_3\\) . The chamber is vacuumed at room temperature, but since an external light source was used, it is hard to determine the sample temperature for those in-situ measurements. The measurement geometry for this experiment is transmission, incident angle = 90 \\(^o\\) . The size of the SiN \\(_x\\) window is 1.5 x 1.5 mm \\(^2\\) and the beam size is 80 \\(\\mu\\) m. We scanned an empty SiN \\(_x\\) with the sample holder moving in the x direction to determine the actual beam size. The fitting with a \\(\\sigma\\) = 80 \\(\\mu\\) m Gaussian peak is shown below.","title":"Contrast function copy 4"},{"location":"RSoXS/Contrast_function/","text":"The contrast of RSoXS is strongly dependent on the dispersion ( \\(\\delta\\) ) and the absorption ( \\(\\beta\\) ) components of the refractive index (n) as represented in the equations below. The refractive index [ \\(n(E)\\) ] at a photon energy \\(E\\) can be calculated using equation: \\[\\begin{equation} \\begin{aligned} n(E)=&1-\\delta(E)+i\\beta(E)\\\\ =&1-\\frac{r_0}{2\\pi}\\lambda^2\\sum_j N_j[f_{1j}(E)+if_{2j}(E)] \\end{aligned} \\label{eq:contrast1} \\end{equation}\\] The contrast function ( \\(C\\) ) can be estimated from equation: \\begin{equation} C\\propto{(\\Delta n)^2}\\propto{(\\Delta\\delta)^2+(\\Delta\\beta)^2} \\label{eq:contrast2} \\end{equation} Where \\(r_0\\) is the classical electron radius, \\(\\lambda\\) is the wavelength of incident X-rays, \\(N_M\\) the number density of an atom ( \\(M\\) ), \\(f_1\\) and \\(f_2\\) are the real and imaginary parts of the complex atomic scattering factor, and the summation is performed for all atoms ( \\(M\\) ). Kramers\u2013Kronig relations: \\begin{equation} \\chi_1(\\omega)=\\frac{1}{\\pi} \\mathcal{P} \\int_{-\\infty}^{\\infty} \\frac{\\omega^{\\prime} \\chi_2\\left(\\omega^{\\prime}\\right)}{\\omega^{\\prime 2}-\\omega^2} d \\omega^{\\prime}+\\frac{\\omega}{\\pi} \\mathcal{P} \\int_{-\\infty}^{\\infty} \\frac{\\chi_2\\left(\\omega^{\\prime}\\right)}{\\omega^{\\prime 2}-\\omega^2} d \\omega^{\\prime} \\end{equation} \\[\\begin{equation} \\chi_2(\\omega)=-\\frac{2}{\\pi} \\mathcal{P} \\int_0^{\\infty} \\frac{\\omega \\chi_1\\left(\\omega^{\\prime}\\right)}{\\omega^{\\prime 2}-\\omega^2} d \\omega^{\\prime}=-\\frac{2 \\omega}{\\pi} \\mathcal{P} \\int_0^{\\infty} \\frac{\\chi_1\\left(\\omega^{\\prime}\\right)}{\\omega^{\\prime 2}-\\omega^2} d \\omega^{\\prime} \\end{equation}\\] To confirm the feasibility of the measurements, we performed near-edge X-ray absorption fine structure (NEXAFS) measurements on CsPbI \\(_3\\) and CsPbBr \\(_3\\) thin films and calculated their \\(f_1\\) , \\(f_2\\) , \\(\\delta\\) and \\(\\beta\\) , and the corresponding contrast function between the two phases (see Figure 2). Clear differences appear in and profiles at Iodine M4 & M5-edges ( \\(\\sim\\) 620 - 631 eV). The calculated contrast for CsPbI \\(_3\\) vs CsPbBr \\(_3\\) reveals that the proposed RSoXS measurements can be used to decouple the contribution from I-rich and Br-rich domains, showing highest contrast near \\(\\sim\\) 640 eV.","title":"Contrast function"},{"location":"RSoXS/Intrinsic_heterogeneity/","text":"","title":"Intrinsic heterogeneity"},{"location":"RSoXS/Light_induced_phase_segregation/","text":"","title":"Light induced phase segregation"},{"location":"RSoXS/Sample_preparation/","text":"MAPbI \\(_3\\) and MAPbBr \\(_3\\) were made into 1 M solutions with DMF : DMSO = 3 : 1. The solutions were stirred for 12 hours before being mixed into MAPbI \\(_{1.5}\\) Br \\(_{1.5}\\) , MAPb(I \\(_{0.33}\\) Br \\(_{0.67}\\) ) \\(_3\\) , and MAPb(I \\(_{0.67}\\) Br \\(_{0.33}\\) ) \\(_3\\) . The mixed solutions were then spin-coated onto SiN \\(_x\\) windows. Glass substrates were washed and plasma cleaned for holding the SiN \\(_x\\) windows. The condition is RPM = 4000, T = 1 min. Then the films were annealed at 110 \\(^o\\) C for 15 mins. The Cs \\(_y\\) FA \\(_{1-y}\\) Pb(Br \\(_x\\) I \\(_{1-x}\\) ) \\(_3\\) series were made with the same method except that the spin-coating condition is RPM = 4000, T = 2 mins and the annealing condition is 140 \\(^o\\) C (15 or 30 mins). Spin-coated perovskite films on SiN windows.","title":"Sample preparation"},{"location":"RSoXS/beamline/","text":"ALS beamline 11.0.1.2 is capable of doing soft X-ray absorption from 165 - 1500 eV in both transmission and total electron yield(TEY) mode with polarization control. A CCD detector and a photodiode are installed in a vacuum chamber with the sample stage. The sample-detector distance is tunable and the q range is from 0.001 to 0.7 \\AA. The light exposure device can be fixed at the window of the chamber which gives a 45 \\(^o\\) incident angle when the sample was set to be perpendicular to the incoming X-Ray. The perovskite films were prepared at Berkeley Lab Molecular Foundry and transferred to the ALS beamline in 15 minutes. It takes around 30-40 minutes to pump down the chamber and cool down the CCD camera. So the samples were exposed to air for \\(\\sim\\) 20 minutes. This may lead to degradation for MAPbBr \\(_3\\) and MAPbI \\(_3\\) . The chamber is vacuumed at room temperature, but since an external light source was used, it is hard to determine the sample temperature for those in-situ measurements. The measurement geometry for this experiment is transmission, incident angle = 90 \\(^o\\) . The size of the SiN \\(_x\\) window is 1.5 x 1.5 mm \\(^2\\) and the beam size is 80 \\(\\mu\\) m. We scanned an empty SiN \\(_x\\) with the sample holder moving in the x direction to determine the actual beam size. The fitting with a \\(\\sigma\\) = 80 \\(\\mu\\) m Gaussian peak is shown below.","title":"Beamline ALS 11.0.1"},{"location":"RSoXS/index%20copy/","text":"","title":"Index copy"},{"location":"RSoXS/python/","text":"Python \u00b6 Python will be our primary programming language. Thus we assume the readers have a good understanding of the Python language in this section. We will cover the following topics. Environment management; Dependency management; pre-commit . Environment Management \u00b6 Python is notorious in environment management. We recommend using conda to manage our environments. conda cheatsheet The most useful commands for conda are the following. Create an environment: conda create -n my-env-name python=3.9 pip , where my-env-name is the name of the environment, python=3.9 specifies the version of Python, pip is telling conda to install pip in this new environment. Activate an environment: conda activate my-env-name List all available environments: conda env list Anaconda provides a nice cheatsheet . Alternative to conda pyenv is also a good tool for managing different versions and environments of python. Dependency Management \u00b6 We have a few choices to specify the dependencies. The most used method at the moment is requirements.txt . conda 's environment.yml Alternatively, conda provides its own requirement specification using environment.yaml . However, this method doesn't make things better. If we ever need to make it more complicated than requirements.txt , pyproject.toml is the way to go. Modern Python with pyproject.toml and poetry Python introduced pyproject.toml in PEP518 which can be used together with poetry to sepcify dependencies . Both conda and pyenv have trouble solving the actual full dependency graphs of all the packages used. This problem is solved by poetry . However, this also means poetry can be very slow as it has to load many different versions of the packages to try out. 5 While tutorials on how to use poetry is not within the scope of this book, we highly recommend using poetry in a formal project. Python Styles and pre-commit \u00b6 In a Python project, it is important to have some certain conventions or styles. To be consistent, one could follow some style guides for python. There are official proposals, such as PEP8 , and \"third party\" style guides, such as Google Python Style Guide . 3 4 We also recommend using pre-commit . pre-commit helps us manage git hooks to be executed before each commit. Once installed, every time we run git commit -m \"my commit message here\" , a series of commands will be executed first based on the configurations. Some pre-commit Configs An Example Config pre-commit officially provides some hooks already, e.g., trailing-whitespace . 2 We also recommend the following hooks, black , which formats the code based on pre-defined styles, isort , which orders the Python imports 1 , mypy , which is a linter for Python. The following is an example .pre-commit-config.yaml file for a Python project. repos : - repo : https://github.com/pre-commit/pre-commit-hooks rev : v4.2.0 hooks : - id : check-added-large-files - id : debug-statements - id : detect-private-key - id : end-of-file-fixer - id : requirements-txt-fixer - id : trailing-whitespace - repo : https://github.com/pre-commit/mirrors-mypy rev : v0.960 hooks : - id : mypy args : - \"--no-strict-optional\" - \"--ignore-missing-imports\" - repo : https://github.com/ambv/black rev : 22.6.0 hooks : - id : black language : python args : - \"--line-length=120\" - repo : https://github.com/pycqa/isort rev : 5.10.1 hooks : - id : isort name : isort (python) Write docstrings \u00b6 Writing docstrings for functions and classes can help our future self understand them more easily. There are different styles for docstrings. Two of the popular ones are reStructuredText Docstring Format , and Google style docstrings . Test Saves Time \u00b6 Adding tests to our code can save us time. We will not list all these benefits of having tests. But tests can help us debug our code and ship results more confidently. For example, suppose we are developing a function and spot a bug. One of the best ways of debugging it is to write a test and put a debugger breakpoint at the suspicious line of the code. With the help of IDEs such as Visual Studio Code, this process can save us a lot of time in debugging. Use pytest Use pytest . RealPython provides a good short introduction . Pre Commit. In: isort [Internet]. [cited 22 Jul 2022]. Available: https://pycqa.github.io/isort/docs/configuration/pre-commit.html \u21a9 pre-commit-config-pre-commit-hooks.yaml. In: Gist [Internet]. [cited 22 Jul 2022]. Available: https://gist.github.com/lynnkwong/f7591525cfc903ec592943e0f2a61ed9 \u21a9 Guido van Rossum, Barry Warsaw, Nick Coghlan. PEP 8 \u2013 Style Guide for Python Code. In: peps.python.org [Internet]. 5 Jul 2001 [cited 23 Jul 2022]. Available: https://peps.python.org/pep-0008/ \u21a9 Google Python Style Guide. In: Google Python Style Guide [Internet]. [cited 22 Jul 2022]. Available: https://google.github.io/styleguide/pyguide.html \u21a9 Poetry is extremely slow when resolving the dependencies \u00b7 Issue #2094 \u00b7 python-poetry/poetry. In: GitHub [Internet]. [cited 23 Jul 2022]. Available: https://github.com/python-poetry/poetry/issues/2094 \u21a9","title":"Python"},{"location":"RSoXS/python/#python","text":"Python will be our primary programming language. Thus we assume the readers have a good understanding of the Python language in this section. We will cover the following topics. Environment management; Dependency management; pre-commit .","title":"Python"},{"location":"RSoXS/python/#environment-management","text":"Python is notorious in environment management. We recommend using conda to manage our environments. conda cheatsheet The most useful commands for conda are the following. Create an environment: conda create -n my-env-name python=3.9 pip , where my-env-name is the name of the environment, python=3.9 specifies the version of Python, pip is telling conda to install pip in this new environment. Activate an environment: conda activate my-env-name List all available environments: conda env list Anaconda provides a nice cheatsheet . Alternative to conda pyenv is also a good tool for managing different versions and environments of python.","title":"Environment Management"},{"location":"RSoXS/python/#dependency-management","text":"We have a few choices to specify the dependencies. The most used method at the moment is requirements.txt . conda 's environment.yml Alternatively, conda provides its own requirement specification using environment.yaml . However, this method doesn't make things better. If we ever need to make it more complicated than requirements.txt , pyproject.toml is the way to go. Modern Python with pyproject.toml and poetry Python introduced pyproject.toml in PEP518 which can be used together with poetry to sepcify dependencies . Both conda and pyenv have trouble solving the actual full dependency graphs of all the packages used. This problem is solved by poetry . However, this also means poetry can be very slow as it has to load many different versions of the packages to try out. 5 While tutorials on how to use poetry is not within the scope of this book, we highly recommend using poetry in a formal project.","title":"Dependency Management"},{"location":"RSoXS/python/#python-styles-and-pre-commit","text":"In a Python project, it is important to have some certain conventions or styles. To be consistent, one could follow some style guides for python. There are official proposals, such as PEP8 , and \"third party\" style guides, such as Google Python Style Guide . 3 4 We also recommend using pre-commit . pre-commit helps us manage git hooks to be executed before each commit. Once installed, every time we run git commit -m \"my commit message here\" , a series of commands will be executed first based on the configurations. Some pre-commit Configs An Example Config pre-commit officially provides some hooks already, e.g., trailing-whitespace . 2 We also recommend the following hooks, black , which formats the code based on pre-defined styles, isort , which orders the Python imports 1 , mypy , which is a linter for Python. The following is an example .pre-commit-config.yaml file for a Python project. repos : - repo : https://github.com/pre-commit/pre-commit-hooks rev : v4.2.0 hooks : - id : check-added-large-files - id : debug-statements - id : detect-private-key - id : end-of-file-fixer - id : requirements-txt-fixer - id : trailing-whitespace - repo : https://github.com/pre-commit/mirrors-mypy rev : v0.960 hooks : - id : mypy args : - \"--no-strict-optional\" - \"--ignore-missing-imports\" - repo : https://github.com/ambv/black rev : 22.6.0 hooks : - id : black language : python args : - \"--line-length=120\" - repo : https://github.com/pycqa/isort rev : 5.10.1 hooks : - id : isort name : isort (python)","title":"Python Styles and pre-commit"},{"location":"RSoXS/python/#write-docstrings","text":"Writing docstrings for functions and classes can help our future self understand them more easily. There are different styles for docstrings. Two of the popular ones are reStructuredText Docstring Format , and Google style docstrings .","title":"Write docstrings"},{"location":"RSoXS/python/#test-saves-time","text":"Adding tests to our code can save us time. We will not list all these benefits of having tests. But tests can help us debug our code and ship results more confidently. For example, suppose we are developing a function and spot a bug. One of the best ways of debugging it is to write a test and put a debugger breakpoint at the suspicious line of the code. With the help of IDEs such as Visual Studio Code, this process can save us a lot of time in debugging. Use pytest Use pytest . RealPython provides a good short introduction . Pre Commit. In: isort [Internet]. [cited 22 Jul 2022]. Available: https://pycqa.github.io/isort/docs/configuration/pre-commit.html \u21a9 pre-commit-config-pre-commit-hooks.yaml. In: Gist [Internet]. [cited 22 Jul 2022]. Available: https://gist.github.com/lynnkwong/f7591525cfc903ec592943e0f2a61ed9 \u21a9 Guido van Rossum, Barry Warsaw, Nick Coghlan. PEP 8 \u2013 Style Guide for Python Code. In: peps.python.org [Internet]. 5 Jul 2001 [cited 23 Jul 2022]. Available: https://peps.python.org/pep-0008/ \u21a9 Google Python Style Guide. In: Google Python Style Guide [Internet]. [cited 22 Jul 2022]. Available: https://google.github.io/styleguide/pyguide.html \u21a9 Poetry is extremely slow when resolving the dependencies \u00b7 Issue #2094 \u00b7 python-poetry/poetry. In: GitHub [Internet]. [cited 23 Jul 2022]. Available: https://github.com/python-poetry/poetry/issues/2094 \u21a9","title":"Test Saves Time"},{"location":"Strain-in-perovskites/GIWAXS/","text":"Strain in perovskites \u00b6","title":"GIWAXS experiment"},{"location":"Strain-in-perovskites/GIWAXS/#strain-in-perovskites","text":"","title":"Strain in perovskites"},{"location":"Strain-in-perovskites/intro/","text":"Strain in perovskites \u00b6","title":"Introduction"},{"location":"Strain-in-perovskites/intro/#strain-in-perovskites","text":"","title":"Strain in perovskites"},{"location":"self-supervised/","text":"Self-supervised Learning Introduction \u00b6 Notations \u00b6 In this document, we use the following notations. Sets, domains, abstract variables, \\(X\\) , \\(Y\\) ; Probability distribution \\(P\\) , \\(Q\\) ; Probability density \\(p\\) , \\(q\\) . Why Self-supervised Learning \u00b6 Self-supervised learning helps with downstream visual tasks 1 . Image from Newell2020 Newell A, Deng J. How Useful is Self-Supervised Pretraining for Visual Tasks? arXiv [cs.CV]. 2020. Available: http://arxiv.org/abs/2003.14323 \u21a9","title":"Introduction"},{"location":"self-supervised/#self-supervised-learning-introduction","text":"","title":"Self-supervised Learning Introduction"},{"location":"self-supervised/#notations","text":"In this document, we use the following notations. Sets, domains, abstract variables, \\(X\\) , \\(Y\\) ; Probability distribution \\(P\\) , \\(Q\\) ; Probability density \\(p\\) , \\(q\\) .","title":"Notations"},{"location":"self-supervised/#why-self-supervised-learning","text":"Self-supervised learning helps with downstream visual tasks 1 . Image from Newell2020 Newell A, Deng J. How Useful is Self-Supervised Pretraining for Visual Tasks? arXiv [cs.CV]. 2020. Available: http://arxiv.org/abs/2003.14323 \u21a9","title":"Why Self-supervised Learning"},{"location":"self-supervised/adversarial/f-gan/","text":"f-GAN \u00b6 The essence of GAN is comparing the generated distribution \\(p_G\\) and the data distribution \\(p_\\text{data}\\) . The vanilla GAN considers the Jensen-Shannon divergence \\(\\operatorname{D}_\\text{JS}(p_\\text{data}\\Vert p_{G})\\) . The discriminator \\({\\color{green}D}\\) serves the purpose of forcing this divergence to be small. Why do we need the discriminator? If the JS divergence is an objective, why do we need the discriminator? Even in f-GAN we need a functional to approximate the f-divergence. This functional we choose works like the discriminator of GAN. There exists a more generic form of JS divergence, which is called f-divergence 1 . f-GAN obtains the model by estimating the f-divergence between the data distribution and the generated distribution 2 . Variational Divergence Minimization \u00b6 The Variational Divergence Minimization (VDM) extends the variational estimation of f-divergence 2 . VDM searches for the saddle point of an objective \\(F({\\color{red}\\theta}, {\\color{blue}\\omega})\\) , i.e., min w.r.t. \\(\\theta\\) and max w.r.t \\({\\color{blue}\\omega}\\) , where \\({\\color{red}\\theta}\\) is the parameter set of the generator \\({\\color{red}Q_\\theta}\\) , and \\({\\color{blue}\\omega}\\) is the parameter set of the variational approximation to estimate f-divergence, \\({\\color{blue}T_\\omega}\\) . The objective \\(F({\\color{red}\\theta}, {\\color{blue}\\omega})\\) is related to the choice of \\(f\\) in f-divergence and the variational functional \\({\\color{blue}T}\\) , \\[ \\begin{align} & F(\\theta, \\omega)\\\\ =& \\mathbb E_{x\\sim p_\\text{data}} \\left[ {\\color{blue}T_\\omega}(x) \\right] - \\mathbb E_{x\\sim {\\color{red}Q_\\theta} } \\left[ f^*({\\color{blue}T_\\omega}(x)) \\right] \\\\ =& \\mathbb E_{x\\sim p_\\text{data}} \\left[ g_f(V_{\\color{blue}\\omega}(x)) \\right] - \\mathbb E_{x\\sim {\\color{red}Q_\\theta} } \\left[ f^*(g_f(V_{\\color{blue}\\omega}(x))) \\right]. \\end{align} \\] In the above objective, \\(f^*\\) is the Legendre\u2013Fenchel transformation of \\(f\\) , i.e., \\(f^*(t) = \\operatorname{sup}_{u\\in \\mathrm{dom}_f}\\left\\{ ut - f(u) \\right\\}\\) . \\(T\\) The function \\(T\\) is used to estimate the lower bound of f-divergence 2 . Choice of \\(g_f\\) and \\(V\\) Nowozin et al provided a table for \\(g_f\\) and \\(V\\) 2 . We estimate \\(\\mathbb E_{x\\sim p_\\text{data}}\\) by sampling from the mini-batch, and \\(\\mathbb E_{x\\sim {\\color{red}Q_\\theta} }\\) by sampling from the generator. Reduce to GAN The VDM loss can be reduced to the loss of GAN by setting 2 \\[ \\begin{align} \\log {\\color{green}D_\\omega} =& g_f(V_{\\color{blue}\\omega}(x)) \\\\ \\log \\left( 1 - {\\color{green}D_\\omega} \\right) =& -f^*\\left( g_f(V_{\\color{blue}\\omega}(x)) \\right). \\end{align} \\] It is straightforward to validate that the following result is a solution to the above set of equations, \\[ g_f(V) = \\log \\frac{1}{1 + e^{-V}}. \\] Code \u00b6 minlee077/f-GAN-pytorch shayneobrien/generative-models Contributors to Wikimedia projects. F-divergence. In: Wikipedia [Internet]. 17 Jul 2021 [cited 6 Sep 2021]. Available: https://en.wikipedia.org/wiki/F-divergence#Instances_of_f-divergences \u21a9 Nowozin S, Cseke B, Tomioka R. f-GAN: Training Generative Neural Samplers using Variational Divergence Minimization. arXiv [stat.ML]. 2016. Available: http://arxiv.org/abs/1606.00709 \u21a9 \u21a9 \u21a9 \u21a9 \u21a9 Contributors to Wikimedia projects. Convex conjugate. In: Wikipedia [Internet]. 20 Feb 2021 [cited 7 Sep 2021]. Available: https://en.wikipedia.org/wiki/Convex_conjugate \u21a9","title":"f-GAN"},{"location":"self-supervised/adversarial/f-gan/#f-gan","text":"The essence of GAN is comparing the generated distribution \\(p_G\\) and the data distribution \\(p_\\text{data}\\) . The vanilla GAN considers the Jensen-Shannon divergence \\(\\operatorname{D}_\\text{JS}(p_\\text{data}\\Vert p_{G})\\) . The discriminator \\({\\color{green}D}\\) serves the purpose of forcing this divergence to be small. Why do we need the discriminator? If the JS divergence is an objective, why do we need the discriminator? Even in f-GAN we need a functional to approximate the f-divergence. This functional we choose works like the discriminator of GAN. There exists a more generic form of JS divergence, which is called f-divergence 1 . f-GAN obtains the model by estimating the f-divergence between the data distribution and the generated distribution 2 .","title":"f-GAN"},{"location":"self-supervised/adversarial/f-gan/#variational-divergence-minimization","text":"The Variational Divergence Minimization (VDM) extends the variational estimation of f-divergence 2 . VDM searches for the saddle point of an objective \\(F({\\color{red}\\theta}, {\\color{blue}\\omega})\\) , i.e., min w.r.t. \\(\\theta\\) and max w.r.t \\({\\color{blue}\\omega}\\) , where \\({\\color{red}\\theta}\\) is the parameter set of the generator \\({\\color{red}Q_\\theta}\\) , and \\({\\color{blue}\\omega}\\) is the parameter set of the variational approximation to estimate f-divergence, \\({\\color{blue}T_\\omega}\\) . The objective \\(F({\\color{red}\\theta}, {\\color{blue}\\omega})\\) is related to the choice of \\(f\\) in f-divergence and the variational functional \\({\\color{blue}T}\\) , \\[ \\begin{align} & F(\\theta, \\omega)\\\\ =& \\mathbb E_{x\\sim p_\\text{data}} \\left[ {\\color{blue}T_\\omega}(x) \\right] - \\mathbb E_{x\\sim {\\color{red}Q_\\theta} } \\left[ f^*({\\color{blue}T_\\omega}(x)) \\right] \\\\ =& \\mathbb E_{x\\sim p_\\text{data}} \\left[ g_f(V_{\\color{blue}\\omega}(x)) \\right] - \\mathbb E_{x\\sim {\\color{red}Q_\\theta} } \\left[ f^*(g_f(V_{\\color{blue}\\omega}(x))) \\right]. \\end{align} \\] In the above objective, \\(f^*\\) is the Legendre\u2013Fenchel transformation of \\(f\\) , i.e., \\(f^*(t) = \\operatorname{sup}_{u\\in \\mathrm{dom}_f}\\left\\{ ut - f(u) \\right\\}\\) . \\(T\\) The function \\(T\\) is used to estimate the lower bound of f-divergence 2 . Choice of \\(g_f\\) and \\(V\\) Nowozin et al provided a table for \\(g_f\\) and \\(V\\) 2 . We estimate \\(\\mathbb E_{x\\sim p_\\text{data}}\\) by sampling from the mini-batch, and \\(\\mathbb E_{x\\sim {\\color{red}Q_\\theta} }\\) by sampling from the generator. Reduce to GAN The VDM loss can be reduced to the loss of GAN by setting 2 \\[ \\begin{align} \\log {\\color{green}D_\\omega} =& g_f(V_{\\color{blue}\\omega}(x)) \\\\ \\log \\left( 1 - {\\color{green}D_\\omega} \\right) =& -f^*\\left( g_f(V_{\\color{blue}\\omega}(x)) \\right). \\end{align} \\] It is straightforward to validate that the following result is a solution to the above set of equations, \\[ g_f(V) = \\log \\frac{1}{1 + e^{-V}}. \\]","title":"Variational Divergence Minimization"},{"location":"self-supervised/adversarial/f-gan/#code","text":"minlee077/f-GAN-pytorch shayneobrien/generative-models Contributors to Wikimedia projects. F-divergence. In: Wikipedia [Internet]. 17 Jul 2021 [cited 6 Sep 2021]. Available: https://en.wikipedia.org/wiki/F-divergence#Instances_of_f-divergences \u21a9 Nowozin S, Cseke B, Tomioka R. f-GAN: Training Generative Neural Samplers using Variational Divergence Minimization. arXiv [stat.ML]. 2016. Available: http://arxiv.org/abs/1606.00709 \u21a9 \u21a9 \u21a9 \u21a9 \u21a9 Contributors to Wikimedia projects. Convex conjugate. In: Wikipedia [Internet]. 20 Feb 2021 [cited 7 Sep 2021]. Available: https://en.wikipedia.org/wiki/Convex_conjugate \u21a9","title":"Code"},{"location":"self-supervised/adversarial/gan/","text":"GAN \u00b6 GAN is a generative neural sampler 1 . To train the sampler, the task of GAN is designed to generate features \\(X\\) from a latent space \\(\\xi\\) and class labels \\(Y\\) , \\[\\xi, Y \\to X.\\] Many different formulations of GANs are proposed. As an introduction to this topic, we will discuss vanilla GAN in this section 3 . Theory \u00b6 The Minimax Game Loss \u00b6 The minimax game is a game to \"minimizing the possible loss for a worst case\" 2 . In GAN, the game is to train the generator \\({\\color{red}G}\\) to fool the discriminator \\({\\color{green}D}\\) while minimizing the discrimination error of \\({\\color{green}D}\\) . Goodfellow prosed a loss 3 \\[ \\begin{equation} \\underset{{\\color{red}G}}{\\operatorname{min}}\\underset{{\\color{green}D}}{\\operatorname{max}} V({\\color{green}D}, {\\color{red}G}) = \\mathbb E_{x\\sim p_{data}} \\left[ \\log {\\color{green}D}(x) \\right] + \\mathbb E_{z\\sim p_z} \\left[ \\log( 1- {\\color{green}D}({\\color{red}G}(z)) ) \\right]. \\end{equation} \\] Divergence \u00b6 Goodfellow et al proved that the global minimum of such a setup is reached only and if only \\(p_{G} = p_\\text{data}\\) . GAN is comparing the generated distribution to the data distribution, using the Jensen-Shannon divergence 3 , \\[ \\operatorname{D}_{\\text{JS}}(p_\\text{data}\\Vert p_{{\\color{red}G}}) = \\frac{1}{2}\\left[ \\operatorname{D}_\\text{KL} \\left( p_\\text{data} \\bigg\\Vert \\frac{p_\\text{data} + p_{\\color{red}G}}{2} \\right) + \\operatorname{D}_\\text{KL} \\left( p_{{\\color{red}G}} \\bigg\\Vert \\frac{p_\\text{data} + p_{\\color{red}G}}{2} \\right) \\right]. \\] Off by a Constant The value function of GAN for fixed \\(G\\) is slightly different from JS divergence 3 , \\[ \\underset{G}{\\operatorname{max}}V({\\color{red}G},{\\color{green}D}) = 2 \\operatorname{D}_\\text{JS}( p_\\text{data} \\Vert p_{\\color{red}G} ) - \\log 4. \\] Alternating Training \u00b6 GAN training requires two stages, train discriminator \\({\\color{green}D}\\) , and train generator \\({\\color{red}G}\\) . Code \u00b6 We built a simple GAN using MNIST dataset. Result Code The generated images looks quite close to hand writings. import matplotlib.pyplot as plt import torch from pathlib import Path import torchvision import torchvision.transforms as transforms from loguru import logger from torch import nn import click logger . debug ( f \"Setting device ...\" ) device = \"\" if torch . cuda . is_available (): device = torch . device ( \"cuda\" ) else : device = torch . device ( \"cpu\" ) logger . info ( f \"Device in use: { device } \" ) def plot_images ( image_samples , target ): \"\"\"Plot a grid of images and save to a file.\"\"\" if not Path ( target ) . parent . exists (): Path ( target ) . parent . mkdir ( parents = True ) # real_samples, mnist_labels = next(iter(train_loader)) for i in range ( 16 ): ax = plt . subplot ( 4 , 4 , i + 1 ) plt . imshow ( image_samples [ i ] . reshape ( 28 , 28 ), cmap = \"gray_r\" ) plt . xticks ([]) plt . yticks ([]) plt . savefig ( target ) def get_data_loaders ( batch_size = 32 , data_dir = \"data/mnist\" , download = True , plot_samples = True ): \"\"\"Get MNIST data and built a dataloader for the dataset\"\"\" transform = transforms . Compose ( [ transforms . ToTensor (), transforms . Normalize (( 0.5 ,), ( 0.5 ,))] ) train_set = torchvision . datasets . MNIST ( root = data_dir , train = True , download = download , transform = transform ) train_loader = torch . utils . data . DataLoader ( train_set , batch_size = batch_size , shuffle = True ) if plot_samples : real_samples , mnist_labels = next ( iter ( train_loader )) plot_images ( real_samples , target = \"assets/real_images/real_image_samples.png\" ) return train_loader class Discriminator ( nn . Module ): \"\"\"The discrimnator should take data that has the dimension of the image and spit out a probability\"\"\" def __init__ ( self ): super () . __init__ () self . model = nn . Sequential ( nn . Linear ( 784 , 1024 ), nn . ReLU (), nn . Dropout ( 0.3 ), nn . Linear ( 1024 , 512 ), nn . ReLU (), nn . Dropout ( 0.3 ), nn . Linear ( 512 , 256 ), nn . ReLU (), nn . Dropout ( 0.3 ), nn . Linear ( 256 , 1 ), nn . Sigmoid (), ) def forward ( self , x ): x = x . view ( x . size ( 0 ), 784 ) output = self . model ( x ) return output class Generator ( nn . Module ): \"\"\"The generator should take in some noise data (a latent space data) and spit out an image. We use the input noise as a trick to make the generator more general \"\"\" def __init__ ( self ): super () . __init__ () self . model = nn . Sequential ( # nn.Linear(10, 100), # nn.ReLU(), nn . Linear ( 100 , 256 ), nn . ReLU (), nn . Linear ( 256 , 512 ), nn . ReLU (), nn . Linear ( 512 , 1024 ), nn . ReLU (), nn . Linear ( 1024 , 784 ), nn . Tanh (), ) def forward ( self , x ): output = self . model ( x ) output = output . view ( x . size ( 0 ), 1 , 28 , 28 ) return output @click . command () @click . option ( \"--epochs\" , default = 50 , help = \"Number of epochs for the training\" ) @click . option ( \"--learning_rate\" , \"-lr\" , default = 0.0001 , help = \"Learning rate for the optimizer\" ) @click . option ( \"--batch_size\" , default = 32 , help = \"Batch size\" ) @click . option ( \"--data_dir\" , default = \"data/mnist\" , help = \"Directory for storing the dataset\" ) @click . option ( \"--download_mnist\" , \"-d\" , default = True , type = bool , help = \"Whether to download MNIST data\" ) @click . option ( \"--random_seed\" , \"-rs\" , default = 42 , type = int , help = \"Random seed for the random generators\" ) def main ( epochs , learning_rate , batch_size , data_dir , download_mnist , random_seed ): latent_space_dim = 100 torch . manual_seed ( random_seed ) # check the dtypes logger . debug ( f \"torch tensor dtype: { torch . tensor ([ 1.2 , 3 ]) . dtype } \" ) # torch.set_default_dtype(torch.float64) # logger.debug( # f\"set torch tensor dtype to 64: {torch.tensor([1.2, 3]).dtype}\" # ) train_loader = get_data_loaders ( batch_size = batch_size , data_dir = data_dir , download = download_mnist ) logger . debug ( f \"Training data is ready\" ) discriminator = Discriminator () . to ( device = device ) generator = Generator () . to ( device = device ) loss_function = nn . BCELoss () optimizer_discriminator = torch . optim . Adam ( discriminator . parameters (), lr = learning_rate ) optimizer_generator = torch . optim . Adam ( generator . parameters (), lr = learning_rate ) for epoch in range ( epochs ): for n , ( real_samples , mnist_labels ) in enumerate ( train_loader ): # We prepare some data for training the discriminator # Here we will prepare both the generated data and the real data real_samples = real_samples . to ( device = device ) real_samples_labels = torch . ones (( batch_size , 1 )) . to ( device = device ) latent_space_samples = torch . randn (( batch_size , latent_space_dim )) . to ( device = device ) # logger.debug(f\"Latent space samples: {latent_space_samples}\") generated_samples = generator ( latent_space_samples ) # logger.debug(f\"Generated samples:{generated_samples}\") generated_samples_labels = torch . zeros (( batch_size , 1 )) . to ( device = device ) all_samples = torch . cat (( real_samples , generated_samples )) all_samples_labels = torch . cat (( real_samples_labels , generated_samples_labels )) # Training the discriminator # The discrinimator is trained using the samples we generated above, i.e. # the generated samples and the real images discriminator . zero_grad () output_discriminator = discriminator ( all_samples ) loss_discriminator = loss_function ( output_discriminator , all_samples_labels ) loss_discriminator . backward () optimizer_discriminator . step () # Generate some noise data for training the generator # latent_space_samples_generator = torch . randn (( batch_size , latent_space_dim )) . to ( device = device ) # Training the generator using the training optimizer generator . zero_grad () generated_samples_generator = generator ( latent_space_samples_generator ) output_discriminator_generated = discriminator ( generated_samples_generator ) loss_generator = loss_function ( output_discriminator_generated , real_samples_labels ) loss_generator . backward () optimizer_generator . step () # Show loss if n == batch_size - 1 : print ( f \"Epoch: { epoch } Loss D.: { loss_discriminator } \" ) print ( f \"Epoch: { epoch } Loss G.: { loss_generator } \" ) logger . debug ( f \"Plotting for epoch: { epoch } ...\" ) latent_space_samples_epoch = torch . randn ( batch_size , latent_space_dim ) . to ( device = device ) generated_samples_epoch = generator ( latent_space_samples_epoch ) generated_samples_epoch = generated_samples_epoch . cpu () . detach () plot_images ( generated_samples_epoch , target = f \"assets/generated_images/generated_image_samples_ { epoch } .png\" ) logger . debug ( f \"Saved plots for epoch: { epoch } \" ) latent_space_samples = torch . randn ( batch_size , latent_space_dim ) . to ( device = device ) generated_samples = generator ( latent_space_samples ) logger . debug ( f \"Plot generated images...\" ) generated_samples = generated_samples . cpu () . detach () plot_images ( generated_samples , target = \"assets/generated_images/generated_image_samples.png\" ) if __name__ == \"__main__\" : main () Nowozin S, Cseke B, Tomioka R. f-GAN: Training Generative Neural Samplers using Variational Divergence Minimization. arXiv [stat.ML]. 2016. Available: http://arxiv.org/abs/1606.00709 \u21a9 Contributors to Wikimedia projects. Minimax. In: Wikipedia [Internet]. 5 Aug 2021 [cited 6 Sep 2021]. Available: https://en.wikipedia.org/wiki/Minimax \u21a9 Goodfellow IJ, Pouget-Abadie J, Mirza M, Xu B, Warde-Farley D, Ozair S, et al. Generative Adversarial Networks. arXiv [stat.ML]. 2014. Available: http://arxiv.org/abs/1406.2661 \u21a9 \u21a9 \u21a9 \u21a9 Liu X, Zhang F, Hou Z, Wang Z, Mian L, Zhang J, et al. Self-supervised Learning: Generative or Contrastive. arXiv [cs.LG]. 2020. Available: http://arxiv.org/abs/2006.08218 \u21a9 Arjovsky M, Chintala S, Bottou L. Wasserstein GAN. arXiv [stat.ML]. 2017. Available: http://arxiv.org/abs/1701.07875 \u21a9","title":"GAN"},{"location":"self-supervised/adversarial/gan/#gan","text":"GAN is a generative neural sampler 1 . To train the sampler, the task of GAN is designed to generate features \\(X\\) from a latent space \\(\\xi\\) and class labels \\(Y\\) , \\[\\xi, Y \\to X.\\] Many different formulations of GANs are proposed. As an introduction to this topic, we will discuss vanilla GAN in this section 3 .","title":"GAN"},{"location":"self-supervised/adversarial/gan/#theory","text":"","title":"Theory"},{"location":"self-supervised/adversarial/gan/#the-minimax-game-loss","text":"The minimax game is a game to \"minimizing the possible loss for a worst case\" 2 . In GAN, the game is to train the generator \\({\\color{red}G}\\) to fool the discriminator \\({\\color{green}D}\\) while minimizing the discrimination error of \\({\\color{green}D}\\) . Goodfellow prosed a loss 3 \\[ \\begin{equation} \\underset{{\\color{red}G}}{\\operatorname{min}}\\underset{{\\color{green}D}}{\\operatorname{max}} V({\\color{green}D}, {\\color{red}G}) = \\mathbb E_{x\\sim p_{data}} \\left[ \\log {\\color{green}D}(x) \\right] + \\mathbb E_{z\\sim p_z} \\left[ \\log( 1- {\\color{green}D}({\\color{red}G}(z)) ) \\right]. \\end{equation} \\]","title":"The Minimax Game Loss"},{"location":"self-supervised/adversarial/gan/#divergence","text":"Goodfellow et al proved that the global minimum of such a setup is reached only and if only \\(p_{G} = p_\\text{data}\\) . GAN is comparing the generated distribution to the data distribution, using the Jensen-Shannon divergence 3 , \\[ \\operatorname{D}_{\\text{JS}}(p_\\text{data}\\Vert p_{{\\color{red}G}}) = \\frac{1}{2}\\left[ \\operatorname{D}_\\text{KL} \\left( p_\\text{data} \\bigg\\Vert \\frac{p_\\text{data} + p_{\\color{red}G}}{2} \\right) + \\operatorname{D}_\\text{KL} \\left( p_{{\\color{red}G}} \\bigg\\Vert \\frac{p_\\text{data} + p_{\\color{red}G}}{2} \\right) \\right]. \\] Off by a Constant The value function of GAN for fixed \\(G\\) is slightly different from JS divergence 3 , \\[ \\underset{G}{\\operatorname{max}}V({\\color{red}G},{\\color{green}D}) = 2 \\operatorname{D}_\\text{JS}( p_\\text{data} \\Vert p_{\\color{red}G} ) - \\log 4. \\]","title":"Divergence"},{"location":"self-supervised/adversarial/gan/#alternating-training","text":"GAN training requires two stages, train discriminator \\({\\color{green}D}\\) , and train generator \\({\\color{red}G}\\) .","title":"Alternating Training"},{"location":"self-supervised/adversarial/gan/#code","text":"We built a simple GAN using MNIST dataset. Result Code The generated images looks quite close to hand writings. import matplotlib.pyplot as plt import torch from pathlib import Path import torchvision import torchvision.transforms as transforms from loguru import logger from torch import nn import click logger . debug ( f \"Setting device ...\" ) device = \"\" if torch . cuda . is_available (): device = torch . device ( \"cuda\" ) else : device = torch . device ( \"cpu\" ) logger . info ( f \"Device in use: { device } \" ) def plot_images ( image_samples , target ): \"\"\"Plot a grid of images and save to a file.\"\"\" if not Path ( target ) . parent . exists (): Path ( target ) . parent . mkdir ( parents = True ) # real_samples, mnist_labels = next(iter(train_loader)) for i in range ( 16 ): ax = plt . subplot ( 4 , 4 , i + 1 ) plt . imshow ( image_samples [ i ] . reshape ( 28 , 28 ), cmap = \"gray_r\" ) plt . xticks ([]) plt . yticks ([]) plt . savefig ( target ) def get_data_loaders ( batch_size = 32 , data_dir = \"data/mnist\" , download = True , plot_samples = True ): \"\"\"Get MNIST data and built a dataloader for the dataset\"\"\" transform = transforms . Compose ( [ transforms . ToTensor (), transforms . Normalize (( 0.5 ,), ( 0.5 ,))] ) train_set = torchvision . datasets . MNIST ( root = data_dir , train = True , download = download , transform = transform ) train_loader = torch . utils . data . DataLoader ( train_set , batch_size = batch_size , shuffle = True ) if plot_samples : real_samples , mnist_labels = next ( iter ( train_loader )) plot_images ( real_samples , target = \"assets/real_images/real_image_samples.png\" ) return train_loader class Discriminator ( nn . Module ): \"\"\"The discrimnator should take data that has the dimension of the image and spit out a probability\"\"\" def __init__ ( self ): super () . __init__ () self . model = nn . Sequential ( nn . Linear ( 784 , 1024 ), nn . ReLU (), nn . Dropout ( 0.3 ), nn . Linear ( 1024 , 512 ), nn . ReLU (), nn . Dropout ( 0.3 ), nn . Linear ( 512 , 256 ), nn . ReLU (), nn . Dropout ( 0.3 ), nn . Linear ( 256 , 1 ), nn . Sigmoid (), ) def forward ( self , x ): x = x . view ( x . size ( 0 ), 784 ) output = self . model ( x ) return output class Generator ( nn . Module ): \"\"\"The generator should take in some noise data (a latent space data) and spit out an image. We use the input noise as a trick to make the generator more general \"\"\" def __init__ ( self ): super () . __init__ () self . model = nn . Sequential ( # nn.Linear(10, 100), # nn.ReLU(), nn . Linear ( 100 , 256 ), nn . ReLU (), nn . Linear ( 256 , 512 ), nn . ReLU (), nn . Linear ( 512 , 1024 ), nn . ReLU (), nn . Linear ( 1024 , 784 ), nn . Tanh (), ) def forward ( self , x ): output = self . model ( x ) output = output . view ( x . size ( 0 ), 1 , 28 , 28 ) return output @click . command () @click . option ( \"--epochs\" , default = 50 , help = \"Number of epochs for the training\" ) @click . option ( \"--learning_rate\" , \"-lr\" , default = 0.0001 , help = \"Learning rate for the optimizer\" ) @click . option ( \"--batch_size\" , default = 32 , help = \"Batch size\" ) @click . option ( \"--data_dir\" , default = \"data/mnist\" , help = \"Directory for storing the dataset\" ) @click . option ( \"--download_mnist\" , \"-d\" , default = True , type = bool , help = \"Whether to download MNIST data\" ) @click . option ( \"--random_seed\" , \"-rs\" , default = 42 , type = int , help = \"Random seed for the random generators\" ) def main ( epochs , learning_rate , batch_size , data_dir , download_mnist , random_seed ): latent_space_dim = 100 torch . manual_seed ( random_seed ) # check the dtypes logger . debug ( f \"torch tensor dtype: { torch . tensor ([ 1.2 , 3 ]) . dtype } \" ) # torch.set_default_dtype(torch.float64) # logger.debug( # f\"set torch tensor dtype to 64: {torch.tensor([1.2, 3]).dtype}\" # ) train_loader = get_data_loaders ( batch_size = batch_size , data_dir = data_dir , download = download_mnist ) logger . debug ( f \"Training data is ready\" ) discriminator = Discriminator () . to ( device = device ) generator = Generator () . to ( device = device ) loss_function = nn . BCELoss () optimizer_discriminator = torch . optim . Adam ( discriminator . parameters (), lr = learning_rate ) optimizer_generator = torch . optim . Adam ( generator . parameters (), lr = learning_rate ) for epoch in range ( epochs ): for n , ( real_samples , mnist_labels ) in enumerate ( train_loader ): # We prepare some data for training the discriminator # Here we will prepare both the generated data and the real data real_samples = real_samples . to ( device = device ) real_samples_labels = torch . ones (( batch_size , 1 )) . to ( device = device ) latent_space_samples = torch . randn (( batch_size , latent_space_dim )) . to ( device = device ) # logger.debug(f\"Latent space samples: {latent_space_samples}\") generated_samples = generator ( latent_space_samples ) # logger.debug(f\"Generated samples:{generated_samples}\") generated_samples_labels = torch . zeros (( batch_size , 1 )) . to ( device = device ) all_samples = torch . cat (( real_samples , generated_samples )) all_samples_labels = torch . cat (( real_samples_labels , generated_samples_labels )) # Training the discriminator # The discrinimator is trained using the samples we generated above, i.e. # the generated samples and the real images discriminator . zero_grad () output_discriminator = discriminator ( all_samples ) loss_discriminator = loss_function ( output_discriminator , all_samples_labels ) loss_discriminator . backward () optimizer_discriminator . step () # Generate some noise data for training the generator # latent_space_samples_generator = torch . randn (( batch_size , latent_space_dim )) . to ( device = device ) # Training the generator using the training optimizer generator . zero_grad () generated_samples_generator = generator ( latent_space_samples_generator ) output_discriminator_generated = discriminator ( generated_samples_generator ) loss_generator = loss_function ( output_discriminator_generated , real_samples_labels ) loss_generator . backward () optimizer_generator . step () # Show loss if n == batch_size - 1 : print ( f \"Epoch: { epoch } Loss D.: { loss_discriminator } \" ) print ( f \"Epoch: { epoch } Loss G.: { loss_generator } \" ) logger . debug ( f \"Plotting for epoch: { epoch } ...\" ) latent_space_samples_epoch = torch . randn ( batch_size , latent_space_dim ) . to ( device = device ) generated_samples_epoch = generator ( latent_space_samples_epoch ) generated_samples_epoch = generated_samples_epoch . cpu () . detach () plot_images ( generated_samples_epoch , target = f \"assets/generated_images/generated_image_samples_ { epoch } .png\" ) logger . debug ( f \"Saved plots for epoch: { epoch } \" ) latent_space_samples = torch . randn ( batch_size , latent_space_dim ) . to ( device = device ) generated_samples = generator ( latent_space_samples ) logger . debug ( f \"Plot generated images...\" ) generated_samples = generated_samples . cpu () . detach () plot_images ( generated_samples , target = \"assets/generated_images/generated_image_samples.png\" ) if __name__ == \"__main__\" : main () Nowozin S, Cseke B, Tomioka R. f-GAN: Training Generative Neural Samplers using Variational Divergence Minimization. arXiv [stat.ML]. 2016. Available: http://arxiv.org/abs/1606.00709 \u21a9 Contributors to Wikimedia projects. Minimax. In: Wikipedia [Internet]. 5 Aug 2021 [cited 6 Sep 2021]. Available: https://en.wikipedia.org/wiki/Minimax \u21a9 Goodfellow IJ, Pouget-Abadie J, Mirza M, Xu B, Warde-Farley D, Ozair S, et al. Generative Adversarial Networks. arXiv [stat.ML]. 2014. Available: http://arxiv.org/abs/1406.2661 \u21a9 \u21a9 \u21a9 \u21a9 Liu X, Zhang F, Hou Z, Wang Z, Mian L, Zhang J, et al. Self-supervised Learning: Generative or Contrastive. arXiv [cs.LG]. 2020. Available: http://arxiv.org/abs/2006.08218 \u21a9 Arjovsky M, Chintala S, Bottou L. Wasserstein GAN. arXiv [stat.ML]. 2017. Available: http://arxiv.org/abs/1701.07875 \u21a9","title":"Code"},{"location":"self-supervised/adversarial/infogan/","text":"InfoGAN \u00b6 In GAN, the latent space input is usually random noise, e.g., Gaussian noise. The objective of GAN is a very generic one. It doesn't say anything about how exactly the latent space will be used. This is not desirable in many problems. We would like to have more interpretability in the latent space. InfoGAN introduced constraints to the objective to enforce interpretability of the latent space 1 . Constraint \u00b6 The constraint InfoGAN proposed is mutual information , \\[ \\underset{{\\color{red}G}}{\\operatorname{min}} \\underset{{\\color{green}D}}{\\operatorname{max}} V_I ({\\color{green}D}, {\\color{red}G}) = V({\\color{green}D}, {\\color{red}G}) - \\lambda I(c; {\\color{red}G}(z,c)), \\] where \\(c\\) is the latent code, \\(z\\) is the random noise input, \\(V({\\color{green}D}, {\\color{red}G})\\) is the objective of GAN, \\(I(c; {\\color{red}G}(z,c))\\) is the mutual information between the input latent code and generated data. Using the lambda multiplier, we punish the model if the generator loses information in latent code \\(c\\) . Training \u00b6 The training steps are almost the same as GAN but with one extra loss to be calculated in each mini-batch. Train \\(\\color{red}G\\) using loss: \\(\\operatorname{MSE}(v', v)\\) ; Train \\(\\color{green}D\\) using loss: \\(\\operatorname{MSE}(v', v)\\) ; Apply Constraint: Sample data from mini-batch; Calculate loss \\(\\lambda_{l} H(l';l)+\\lambda_c \\operatorname{MSE}(c,c')\\) Code \u00b6 eriklindernoren/PyTorch-GAN Chen X, Duan Y, Houthooft R, Schulman J, Sutskever I, Abbeel P. InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets. arXiv [cs.LG]. 2016. Available: http://arxiv.org/abs/1606.03657 \u21a9 Agakov DBF. The im algorithm: a variational approach to information maximization. Adv Neural Inf Process Syst. 2004. Available: https://books.google.com/books?hl=en&lr=&id=0F-9C7K8fQ8C&oi=fnd&pg=PA201&dq=Algorithm+variational+approach+Information+Maximization+Barber+Agakov&ots=TJGrkVS610&sig=yTKM2ZdcZQBTY4e5Vqk42ayUDxo \u21a9","title":"InfoGAN"},{"location":"self-supervised/adversarial/infogan/#infogan","text":"In GAN, the latent space input is usually random noise, e.g., Gaussian noise. The objective of GAN is a very generic one. It doesn't say anything about how exactly the latent space will be used. This is not desirable in many problems. We would like to have more interpretability in the latent space. InfoGAN introduced constraints to the objective to enforce interpretability of the latent space 1 .","title":"InfoGAN"},{"location":"self-supervised/adversarial/infogan/#constraint","text":"The constraint InfoGAN proposed is mutual information , \\[ \\underset{{\\color{red}G}}{\\operatorname{min}} \\underset{{\\color{green}D}}{\\operatorname{max}} V_I ({\\color{green}D}, {\\color{red}G}) = V({\\color{green}D}, {\\color{red}G}) - \\lambda I(c; {\\color{red}G}(z,c)), \\] where \\(c\\) is the latent code, \\(z\\) is the random noise input, \\(V({\\color{green}D}, {\\color{red}G})\\) is the objective of GAN, \\(I(c; {\\color{red}G}(z,c))\\) is the mutual information between the input latent code and generated data. Using the lambda multiplier, we punish the model if the generator loses information in latent code \\(c\\) .","title":"Constraint"},{"location":"self-supervised/adversarial/infogan/#training","text":"The training steps are almost the same as GAN but with one extra loss to be calculated in each mini-batch. Train \\(\\color{red}G\\) using loss: \\(\\operatorname{MSE}(v', v)\\) ; Train \\(\\color{green}D\\) using loss: \\(\\operatorname{MSE}(v', v)\\) ; Apply Constraint: Sample data from mini-batch; Calculate loss \\(\\lambda_{l} H(l';l)+\\lambda_c \\operatorname{MSE}(c,c')\\)","title":"Training"},{"location":"self-supervised/adversarial/infogan/#code","text":"eriklindernoren/PyTorch-GAN Chen X, Duan Y, Houthooft R, Schulman J, Sutskever I, Abbeel P. InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets. arXiv [cs.LG]. 2016. Available: http://arxiv.org/abs/1606.03657 \u21a9 Agakov DBF. The im algorithm: a variational approach to information maximization. Adv Neural Inf Process Syst. 2004. Available: https://books.google.com/books?hl=en&lr=&id=0F-9C7K8fQ8C&oi=fnd&pg=PA201&dq=Algorithm+variational+approach+Information+Maximization+Barber+Agakov&ots=TJGrkVS610&sig=yTKM2ZdcZQBTY4e5Vqk42ayUDxo \u21a9","title":"Code"},{"location":"self-supervised/adversarial/intro/","text":"Adversarial Models \u00b6 GAN f-GAN","title":"Introduction"},{"location":"self-supervised/adversarial/intro/#adversarial-models","text":"GAN f-GAN","title":"Adversarial Models"},{"location":"self-supervised/contrastive/contrastive-predictive-coding/","text":"Contrastive Predictive Coding \u00b6 Contrastive Predictive Coding, CPC, is an autoregressive model combined with InfoNCE loss 1 . Predictive Coding Refer to predictive coding . There are two key ideas in CPC: Autoregressive models in latent space, and InfoNCE loss that combines mutual information and NCE. For the series of segments, \\(\\{x_t\\}\\) , we apply an encoder on each segment, and calculate the latent space, \\(\\{{\\color{blue}\\hat x_t}\\}\\) . The latent space \\(\\{{\\color{blue}\\hat x_t}\\}\\) is then modeled using an autoregressive model to calculate the coding, \\(\\{{\\color{red}c_t}\\}\\) . van den Oord et al The loss is built on NCE to estimate the lower bound of mutual information, \\[ \\mathcal L = -\\mathbb E_X \\left[ \\log \\frac{f_k(x_{t+k}, c_t)}{\\sum_{j} f_k(x_{j}, c_t) } \\right], \\] where \\(f_k(x_{x+i}, c_t)\\) is estimated using a log-bilinear model, \\(f_k(x_{x+i}, c_t) = \\exp\\left( z_{t+i} W_i c_t \\right)\\) . This is also a cross entropy loss. Minimizing \\(\\mathcal L\\) leads to a \\(f_k\\) that estimates the ratio 1 \\[ \\frac{p(x_{t+k}\\mid c_t)}{p(x_{t+k})} = \\frac{p(x_{t+k}, c_t)}{p(x_{t+k})p(c_t)}. \\] We can perform downstream tasks such as classifications using the encoders. Maximizing this lower bound? This so-called lower bound for mutual information in this case is not always going to work[^Newell2020]. In some cases, the representations learned using this lower bound doesn't help or even worsen the performance of downstream tasks. Code \u00b6 rschwarz15/CPCV2-PyTorch van den Oord A, Li Y, Vinyals O. Representation learning with Contrastive Predictive Coding. arXiv [cs.LG]. 2018. Available: http://arxiv.org/abs/1807.03748 \u21a9 \u21a9","title":"Contrastive Predictive Coding"},{"location":"self-supervised/contrastive/contrastive-predictive-coding/#contrastive-predictive-coding","text":"Contrastive Predictive Coding, CPC, is an autoregressive model combined with InfoNCE loss 1 . Predictive Coding Refer to predictive coding . There are two key ideas in CPC: Autoregressive models in latent space, and InfoNCE loss that combines mutual information and NCE. For the series of segments, \\(\\{x_t\\}\\) , we apply an encoder on each segment, and calculate the latent space, \\(\\{{\\color{blue}\\hat x_t}\\}\\) . The latent space \\(\\{{\\color{blue}\\hat x_t}\\}\\) is then modeled using an autoregressive model to calculate the coding, \\(\\{{\\color{red}c_t}\\}\\) . van den Oord et al The loss is built on NCE to estimate the lower bound of mutual information, \\[ \\mathcal L = -\\mathbb E_X \\left[ \\log \\frac{f_k(x_{t+k}, c_t)}{\\sum_{j} f_k(x_{j}, c_t) } \\right], \\] where \\(f_k(x_{x+i}, c_t)\\) is estimated using a log-bilinear model, \\(f_k(x_{x+i}, c_t) = \\exp\\left( z_{t+i} W_i c_t \\right)\\) . This is also a cross entropy loss. Minimizing \\(\\mathcal L\\) leads to a \\(f_k\\) that estimates the ratio 1 \\[ \\frac{p(x_{t+k}\\mid c_t)}{p(x_{t+k})} = \\frac{p(x_{t+k}, c_t)}{p(x_{t+k})p(c_t)}. \\] We can perform downstream tasks such as classifications using the encoders. Maximizing this lower bound? This so-called lower bound for mutual information in this case is not always going to work[^Newell2020]. In some cases, the representations learned using this lower bound doesn't help or even worsen the performance of downstream tasks.","title":"Contrastive Predictive Coding"},{"location":"self-supervised/contrastive/contrastive-predictive-coding/#code","text":"rschwarz15/CPCV2-PyTorch van den Oord A, Li Y, Vinyals O. Representation learning with Contrastive Predictive Coding. arXiv [cs.LG]. 2018. Available: http://arxiv.org/abs/1807.03748 \u21a9 \u21a9","title":"Code"},{"location":"self-supervised/contrastive/deep-infomax/","text":"Deep Infomax \u00b6 Max Global Mutual Information Why not just use the global mutual information of the input and encoder output as the objective? ... maximizing MI between the complete input and the encoder output (i.e.,globalMI) is ofteninsufficient for learning useful representations. -- Devon et al 1 Mutual information maximization is performed on the input of the encoder \\(X\\) and the encoded feature \\(\\hat X=E_\\theta (X)\\) , \\[ \\operatorname{arg~max}_\\theta I(X;E_\\theta (X)). \\] Being a quantity that is notoriously hard to compute, mutual information \\(I(X;E_\\theta (X))\\) is usually estimated using its lower bound, which depends on a choice of a functional \\(T_\\omega\\) . Thus the objective will be maximizing a parametrized mutual information estimation, \\[ \\operatorname{arg~max}_{\\theta, \\omega} \\hat I_\\omega(X;E_\\theta (X)) \\] Local or Global Two approaches to apply mutual information on encoders: Global mutual information of full input and full encoding. This is useful for reconstruction of the input. Local mutual information of local patches of input full encoding. This is useful for classification. Local Mutual Information \u00b6 To compare local features to the encoder output, we need to extract values from inside the encoder, i.e., \\[ E_{\\theta_f, \\theta_C} = f_{\\theta_f} \\circ C_{\\theta_C}. \\] The first step, \\(C_{\\theta_C}\\) is to map the input into feature maps, the second step, \\(f_{\\theta_f}\\) maps the feature maps into the encoding. The feature map \\(C_{\\theta_C}\\) is splitted into patches, \\(C_{\\theta_C}=\\left\\{ C_\\theta^{(i)} \\right\\}\\) . The objective is \\[ \\operatorname{arg~max}_{\\theta_f, \\theta_C, \\omega}\\mathbb E_{i} \\left[ \\hat I_\\omega( C_{\\theta_C}^{(i)} ;E_\\theta (X)) \\right]. \\] Why does local mutual information help Devon et al explained the idea behind choosing local mutual information 1 . Global mutual information doesn't specify what is the meaningful information. Some very local noise can also be treated as meaningful information too. Local mutual information splits the input into patches, and calculate the mutual information between each patch and the encoding. If the model only uses some information from a few local patches, the mutual information objective will be small after averaging all the patches. Thus local mutual information forces the model to use information that is global in the input. Code \u00b6 rdevon/DIM : by the authors DuaneNielsen/DeepInfomaxPytorch : a clean implementation Devon Hjelm R, Fedorov A, Lavoie-Marchildon S, Grewal K, Bachman P, Trischler A, et al. Learning deep representations by mutual information estimation and maximization. arXiv [stat.ML]. 2018. Available: http://arxiv.org/abs/1808.06670 \u21a9 \u21a9 Newell A, Deng J. How Useful is Self-Supervised Pretraining for Visual Tasks? arXiv [cs.CV]. 2020. Available: http://arxiv.org/abs/2003.14323 \u21a9","title":"Deep Infomax"},{"location":"self-supervised/contrastive/deep-infomax/#deep-infomax","text":"Max Global Mutual Information Why not just use the global mutual information of the input and encoder output as the objective? ... maximizing MI between the complete input and the encoder output (i.e.,globalMI) is ofteninsufficient for learning useful representations. -- Devon et al 1 Mutual information maximization is performed on the input of the encoder \\(X\\) and the encoded feature \\(\\hat X=E_\\theta (X)\\) , \\[ \\operatorname{arg~max}_\\theta I(X;E_\\theta (X)). \\] Being a quantity that is notoriously hard to compute, mutual information \\(I(X;E_\\theta (X))\\) is usually estimated using its lower bound, which depends on a choice of a functional \\(T_\\omega\\) . Thus the objective will be maximizing a parametrized mutual information estimation, \\[ \\operatorname{arg~max}_{\\theta, \\omega} \\hat I_\\omega(X;E_\\theta (X)) \\] Local or Global Two approaches to apply mutual information on encoders: Global mutual information of full input and full encoding. This is useful for reconstruction of the input. Local mutual information of local patches of input full encoding. This is useful for classification.","title":"Deep Infomax"},{"location":"self-supervised/contrastive/deep-infomax/#local-mutual-information","text":"To compare local features to the encoder output, we need to extract values from inside the encoder, i.e., \\[ E_{\\theta_f, \\theta_C} = f_{\\theta_f} \\circ C_{\\theta_C}. \\] The first step, \\(C_{\\theta_C}\\) is to map the input into feature maps, the second step, \\(f_{\\theta_f}\\) maps the feature maps into the encoding. The feature map \\(C_{\\theta_C}\\) is splitted into patches, \\(C_{\\theta_C}=\\left\\{ C_\\theta^{(i)} \\right\\}\\) . The objective is \\[ \\operatorname{arg~max}_{\\theta_f, \\theta_C, \\omega}\\mathbb E_{i} \\left[ \\hat I_\\omega( C_{\\theta_C}^{(i)} ;E_\\theta (X)) \\right]. \\] Why does local mutual information help Devon et al explained the idea behind choosing local mutual information 1 . Global mutual information doesn't specify what is the meaningful information. Some very local noise can also be treated as meaningful information too. Local mutual information splits the input into patches, and calculate the mutual information between each patch and the encoding. If the model only uses some information from a few local patches, the mutual information objective will be small after averaging all the patches. Thus local mutual information forces the model to use information that is global in the input.","title":"Local Mutual Information"},{"location":"self-supervised/contrastive/deep-infomax/#code","text":"rdevon/DIM : by the authors DuaneNielsen/DeepInfomaxPytorch : a clean implementation Devon Hjelm R, Fedorov A, Lavoie-Marchildon S, Grewal K, Bachman P, Trischler A, et al. Learning deep representations by mutual information estimation and maximization. arXiv [stat.ML]. 2018. Available: http://arxiv.org/abs/1808.06670 \u21a9 \u21a9 Newell A, Deng J. How Useful is Self-Supervised Pretraining for Visual Tasks? arXiv [cs.CV]. 2020. Available: http://arxiv.org/abs/2003.14323 \u21a9","title":"Code"},{"location":"self-supervised/contrastive/intro/","text":"Contrastive Models \u00b6 Contrastive Models Learn to compare. Liu X, Zhang F, Hou Z, Wang Z, Mian L, Zhang J, et al. Self-supervised Learning: Generative or Contrastive. arXiv [cs.LG]. 2020. Available: http://arxiv.org/abs/2006.08218 \u21a9","title":"Introduction"},{"location":"self-supervised/contrastive/intro/#contrastive-models","text":"Contrastive Models Learn to compare. Liu X, Zhang F, Hou Z, Wang Z, Mian L, Zhang J, et al. Self-supervised Learning: Generative or Contrastive. arXiv [cs.LG]. 2020. Available: http://arxiv.org/abs/2006.08218 \u21a9","title":"Contrastive Models"},{"location":"self-supervised/generative/ae/","text":"Autoencoders \u00b6 Autoencoders (AE) are machines that encodes inputs into a compact latent space. Notation: dot ( \\(\\cdot\\) ) We use a single vertically centered dot, i.e., \\(\\cdot\\) , to indicate that the function or machine can take in arguments. A simple autoencoder can be achieved using two neural nets, e.g., \\[ \\begin{align} {\\color{green}h} &= {\\color{blue}g}{\\color{blue}(}{\\color{blue}b} + {\\color{blue}w} x{\\color{blue})} \\\\ \\hat x &= {\\color{red}\\sigma}{\\color{red}(c} + {\\color{red}v} {\\color{green}h}{\\color{red})}, \\end{align} \\] where in this simple example, \\({\\color{blue}g(b + w \\cdot )}\\) is the encoder, and \\({\\color{red}\\sigma(c + v \\cdot )}\\) is the decoder. For binary labels, we can use a simple cross entropy as the loss. Code \u00b6 See Lippe 1 . Lippe P. Tutorial 9: Deep Autoencoders \u2014 UvA DL Notebooks v1.1 documentation. In: UvA Deep Learning Tutorials [Internet]. [cited 20 Sep 2021]. Available: https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/tutorial9/AE_CIFAR10.html \u21a9","title":"AE"},{"location":"self-supervised/generative/ae/#autoencoders","text":"Autoencoders (AE) are machines that encodes inputs into a compact latent space. Notation: dot ( \\(\\cdot\\) ) We use a single vertically centered dot, i.e., \\(\\cdot\\) , to indicate that the function or machine can take in arguments. A simple autoencoder can be achieved using two neural nets, e.g., \\[ \\begin{align} {\\color{green}h} &= {\\color{blue}g}{\\color{blue}(}{\\color{blue}b} + {\\color{blue}w} x{\\color{blue})} \\\\ \\hat x &= {\\color{red}\\sigma}{\\color{red}(c} + {\\color{red}v} {\\color{green}h}{\\color{red})}, \\end{align} \\] where in this simple example, \\({\\color{blue}g(b + w \\cdot )}\\) is the encoder, and \\({\\color{red}\\sigma(c + v \\cdot )}\\) is the decoder. For binary labels, we can use a simple cross entropy as the loss.","title":"Autoencoders"},{"location":"self-supervised/generative/ae/#code","text":"See Lippe 1 . Lippe P. Tutorial 9: Deep Autoencoders \u2014 UvA DL Notebooks v1.1 documentation. In: UvA Deep Learning Tutorials [Internet]. [cited 20 Sep 2021]. Available: https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/tutorial9/AE_CIFAR10.html \u21a9","title":"Code"},{"location":"self-supervised/generative/autoregressive/","text":"Autoregressive Model \u00b6 An autoregressive (AR) model is autoregressive, \\[ \\begin{equation} \\log p_\\theta (x) = \\sum_{t=1}^T \\log p_\\theta ( x_{t} \\mid \\{x_{<t}\\} ). \\end{equation} \\] Notations and Conventions In AR models, we have to mention the preceding nodes ( \\(\\{x_{<t}\\}\\) ) of a specific node ( \\(x_{t}\\) ). For \\(t=5\\) , the relations between \\(\\{x_{<5}\\}\\) and \\(x_5\\) is shown in the following illustration. There are different notations for such relations. In Uria et al., the authors use \\(p(x_{o_d}\\mid \\mathbf x_{o_{<d}})\\) 1 . In Liu et al. and Papamakarios et al., the authors use \\(p(x_{t}\\mid \\mathbf x_{1:t-1})\\) 6 4 . In Germain et al., the authors use \\(p(x_t\\mid \\mathbf x_{<t})\\) 5 . In the current review, we expanded the vector notation \\(\\mathbf x_{<t}\\) into a set notation as it is not necessarily a vector. Uria B, C\u00f4t\u00e9 M-A, Gregor K, Murray I, Larochelle H. Neural Autoregressive Distribution Estimation. arXiv [cs.LG]. 2016. Available: http://arxiv.org/abs/1605.02226 \u21a9 Triebe O, Laptev N, Rajagopal R. AR-Net: A simple Auto-Regressive Neural Network for time-series. arXiv [cs.LG]. 2019. Available: http://arxiv.org/abs/1911.12436 \u21a9 Ho G. George Ho. In: Eigenfoo [Internet]. 9 Mar 2019 [cited 19 Sep 2021]. Available: https://www.eigenfoo.xyz/deep-autoregressive-models/ \u21a9 Papamakarios G, Pavlakou T, Murray I. Masked Autoregressive Flow for Density Estimation. arXiv [stat.ML]. 2017. Available: http://arxiv.org/abs/1705.07057 \u21a9 Germain M, Gregor K, Murray I, Larochelle H. MADE: Masked autoencoder for distribution estimation. 32nd International Conference on Machine Learning, ICML 2015. 2015;2: 881\u2013889. Available: http://arxiv.org/abs/1502.03509 \u21a9 Liu X, Zhang F, Hou Z, Wang Z, Mian L, Zhang J, et al. Self-supervised Learning: Generative or Contrastive. arXiv [cs.LG]. 2020. Available: http://arxiv.org/abs/2006.08218 \u21a9 Lippe P. Tutorial 12: Autoregressive Image Modeling \u2014 UvA DL Notebooks v1.1 documentation. In: UvA Deep Learning Tutorials [Internet]. [cited 20 Sep 2021]. Available: https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/tutorial12/Autoregressive_Image_Modeling.html \u21a9 rogen-george. rogen-george/Deep-Autoregressive-Model. In: GitHub [Internet]. [cited 20 Sep 2021]. Available: https://github.com/rogen-george/Deep-Autoregressive-Model \u21a9","title":"Autoregressive"},{"location":"self-supervised/generative/autoregressive/#autoregressive-model","text":"An autoregressive (AR) model is autoregressive, \\[ \\begin{equation} \\log p_\\theta (x) = \\sum_{t=1}^T \\log p_\\theta ( x_{t} \\mid \\{x_{<t}\\} ). \\end{equation} \\] Notations and Conventions In AR models, we have to mention the preceding nodes ( \\(\\{x_{<t}\\}\\) ) of a specific node ( \\(x_{t}\\) ). For \\(t=5\\) , the relations between \\(\\{x_{<5}\\}\\) and \\(x_5\\) is shown in the following illustration. There are different notations for such relations. In Uria et al., the authors use \\(p(x_{o_d}\\mid \\mathbf x_{o_{<d}})\\) 1 . In Liu et al. and Papamakarios et al., the authors use \\(p(x_{t}\\mid \\mathbf x_{1:t-1})\\) 6 4 . In Germain et al., the authors use \\(p(x_t\\mid \\mathbf x_{<t})\\) 5 . In the current review, we expanded the vector notation \\(\\mathbf x_{<t}\\) into a set notation as it is not necessarily a vector. Uria B, C\u00f4t\u00e9 M-A, Gregor K, Murray I, Larochelle H. Neural Autoregressive Distribution Estimation. arXiv [cs.LG]. 2016. Available: http://arxiv.org/abs/1605.02226 \u21a9 Triebe O, Laptev N, Rajagopal R. AR-Net: A simple Auto-Regressive Neural Network for time-series. arXiv [cs.LG]. 2019. Available: http://arxiv.org/abs/1911.12436 \u21a9 Ho G. George Ho. In: Eigenfoo [Internet]. 9 Mar 2019 [cited 19 Sep 2021]. Available: https://www.eigenfoo.xyz/deep-autoregressive-models/ \u21a9 Papamakarios G, Pavlakou T, Murray I. Masked Autoregressive Flow for Density Estimation. arXiv [stat.ML]. 2017. Available: http://arxiv.org/abs/1705.07057 \u21a9 Germain M, Gregor K, Murray I, Larochelle H. MADE: Masked autoencoder for distribution estimation. 32nd International Conference on Machine Learning, ICML 2015. 2015;2: 881\u2013889. Available: http://arxiv.org/abs/1502.03509 \u21a9 Liu X, Zhang F, Hou Z, Wang Z, Mian L, Zhang J, et al. Self-supervised Learning: Generative or Contrastive. arXiv [cs.LG]. 2020. Available: http://arxiv.org/abs/2006.08218 \u21a9 Lippe P. Tutorial 12: Autoregressive Image Modeling \u2014 UvA DL Notebooks v1.1 documentation. In: UvA Deep Learning Tutorials [Internet]. [cited 20 Sep 2021]. Available: https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/tutorial12/Autoregressive_Image_Modeling.html \u21a9 rogen-george. rogen-george/Deep-Autoregressive-Model. In: GitHub [Internet]. [cited 20 Sep 2021]. Available: https://github.com/rogen-george/Deep-Autoregressive-Model \u21a9","title":"Autoregressive Model"},{"location":"self-supervised/generative/flow/","text":"Flow \u00b6 For a probability density \\(p(x)\\) and a transformation of coordinate \\(x=g(z)\\) or \\(z=f(x)\\) , the density can be expressed using the coordinate transformations, i.e., \\[ \\begin{align} p(x) &= \\tilde p (f(x)) \\lvert \\operatorname{det} \\operatorname{D} g(f(x)) \\rvert^{-1} \\\\ &= \\tilde p(f(x)) \\lvert \\operatorname{det}\\operatorname{D} f(x) \\rvert \\end{align} \\] where the Jacobian is \\[ \\operatorname{D} g(z) \\to \\frac{\\partial }{\\partial z} g. \\] The operation \\(g_{*}\\circ \\tilde p(z)\\) is the push forward of \\(\\tilde p(z)\\) . The operation \\(g_{*}\\) will pushforward simple distribution \\(\\tilde p(z)\\) to a more complex distribution \\(p(x)\\) . The generative direction: sample \\(z\\) from distribution \\(\\tilde p(z)\\) , apply transformation \\(g(z)\\) ; The normalizing direction: \"simplify\" \\(p(x)\\) to some simple distribution \\(\\tilde p(z)\\) . The key to the flow model is the chaining of the transformations \\[ \\operatorname{det} \\operatorname{D} f(x) = \\Pi_{i=1}^N \\operatorname{det} \\operatorname{D} f_i (x_i) \\] where \\[ \\begin{align} x_i &= g_i \\circ \\cdots \\circ g_1 (z)\\\\ &= f_{i+1} \\circ \\cdots \\circ f_N (x). \\end{align} \\] Liu X, Zhang F, Hou Z, Wang Z, Mian L, Zhang J, et al. Self-supervised Learning: Generative or Contrastive. arXiv [cs.LG]. 2020. Available: http://arxiv.org/abs/2006.08218 \u21a9","title":"Flow"},{"location":"self-supervised/generative/flow/#flow","text":"For a probability density \\(p(x)\\) and a transformation of coordinate \\(x=g(z)\\) or \\(z=f(x)\\) , the density can be expressed using the coordinate transformations, i.e., \\[ \\begin{align} p(x) &= \\tilde p (f(x)) \\lvert \\operatorname{det} \\operatorname{D} g(f(x)) \\rvert^{-1} \\\\ &= \\tilde p(f(x)) \\lvert \\operatorname{det}\\operatorname{D} f(x) \\rvert \\end{align} \\] where the Jacobian is \\[ \\operatorname{D} g(z) \\to \\frac{\\partial }{\\partial z} g. \\] The operation \\(g_{*}\\circ \\tilde p(z)\\) is the push forward of \\(\\tilde p(z)\\) . The operation \\(g_{*}\\) will pushforward simple distribution \\(\\tilde p(z)\\) to a more complex distribution \\(p(x)\\) . The generative direction: sample \\(z\\) from distribution \\(\\tilde p(z)\\) , apply transformation \\(g(z)\\) ; The normalizing direction: \"simplify\" \\(p(x)\\) to some simple distribution \\(\\tilde p(z)\\) . The key to the flow model is the chaining of the transformations \\[ \\operatorname{det} \\operatorname{D} f(x) = \\Pi_{i=1}^N \\operatorname{det} \\operatorname{D} f_i (x_i) \\] where \\[ \\begin{align} x_i &= g_i \\circ \\cdots \\circ g_1 (z)\\\\ &= f_{i+1} \\circ \\cdots \\circ f_N (x). \\end{align} \\] Liu X, Zhang F, Hou Z, Wang Z, Mian L, Zhang J, et al. Self-supervised Learning: Generative or Contrastive. arXiv [cs.LG]. 2020. Available: http://arxiv.org/abs/2006.08218 \u21a9","title":"Flow"},{"location":"self-supervised/generative/intro/","text":"Generative Models \u00b6 Generative models comes with an encoder, an explicit latent space, and a decoder.","title":"Introduction"},{"location":"self-supervised/generative/intro/#generative-models","text":"Generative models comes with an encoder, an explicit latent space, and a decoder.","title":"Generative Models"},{"location":"self-supervised/generative/made/","text":"MADE: Masked Autoencoder for Distribution Estimation \u00b6","title":"MADE"},{"location":"self-supervised/generative/made/#made-masked-autoencoder-for-distribution-estimation","text":"","title":"MADE: Masked Autoencoder for Distribution Estimation"},{"location":"self-supervised/generative/maf/","text":"MAF: Masked Autoregressive Flow \u00b6","title":"MAF"},{"location":"self-supervised/generative/maf/#maf-masked-autoregressive-flow","text":"","title":"MAF: Masked Autoregressive Flow"},{"location":"self-supervised/generative/vae/","text":"Variational AutoEncoder \u00b6 Variational AutoEncoder (VAE) is very different from AE . In VAE, we introduce a variational distribution \\(q\\) to help us work out the weighted integral after introducing the latent space variable \\(z\\) , \\[ \\begin{align} \\ln p_\\theta(x) &= \\int \\left(\\ln p_\\theta (x\\mid z) \\right)p(z) \\,\\mathrm d z \\\\ &= \\int \\left(\\ln\\frac{q_{\\phi}(z\\mid x)}{q_{\\phi}(z\\mid x)} p_\\theta (x\\mid z) \\right) p(z) \\, \\mathrm d z \\end{align} \\] In the above derivation, \\({}_\\theta\\) is the model for inference, and \\({}_\\phi\\) is the model for variational approximation. Tricks \\(p_\\theta(x\\mid z)\\) is usually Gaussian distribution of \\(x\\) but with mean parameterized by the latent variable \\(z\\) and the model parameters \\(\\theta\\) . The latent space variable \\(p(z)\\) is usually assumed to be a normal distribution. The marginalization of the latent variable increase the expressive power. Instead of modeling a complex likelihood \\(p(x\\mid z)\\) directly, we only need to model parameters of Gaussian distributions, e.g., a function \\(f(z, \\theta)\\) for the mean of the Gaussian distribution. From simple distribution in latent space to a more complex distribution. [Doersch2016] The demo looks great. However, sampling from latent space becomes more difficult as the dimension of the latent space increase. We need a more efficient way to sample from the latent space. We use the variational method which uses a model that samples \\(z\\) based on \\(x\\) to sample \\(z\\) , i.e., introduce a function \\(q(z\\mid x)\\) to help us with sampling. \\[ \\begin{align} \\ln p_\\theta(x) &= \\int \\left(\\ln p_\\theta (x\\mid z) \\right)p(z) \\,\\mathrm d z \\\\ &= \\int \\left(\\ln\\frac{q_{\\phi}(z\\mid x)}{q_{\\phi}(z\\mid x)} p_\\theta (x\\mid z) \\right) p(z) \\, \\mathrm d z \\\\ &= \\int dz q(z\\mid x) \\ln \\frac{p(x,z)}{q(z\\mid x)} + \\int dz q(z\\mid x) \\ln \\frac{q(z\\mid x)}{p(z\\mid x)} \\\\ &= - \\left[ D_{\\mathrm{KL}} ( q_{\\phi}(z\\mid x) \\mathrel{\\Vert} p(z) ) - \\mathbb E_q ( \\ln p_\\theta (x\\mid z) ) \\right] + D_{\\mathrm{KL}}( q(z\\mid x)\\parallel p(z\\mid x) ) \\\\ & \\geq - \\left[ D_{\\mathrm{KL}} ( q_{\\phi}(z\\mid x) \\mathrel{\\Vert} p(z) ) - \\mathbb E_q ( \\ln p_\\theta (x\\mid z) ) \\right] \\\\ &\\equiv - F(x) \\\\ &\\equiv \\mathcal L . \\end{align} \\] In the derivation, we used \\(\\int dz q(z\\mid x) = 1\\) . The term \\(F(x)\\) is the free energy, while the negative of it, \\(-F(x)=\\mathcal L\\) , is the so-called Evidence Lower Bound (ELBO) , \\[ \\mathcal L = - D_{\\mathrm{KL}} ( q_{\\phi}(z\\mid x) \\mathrel{\\Vert} p(z) ) + \\mathbb E_q ( \\ln p_\\theta (x\\mid z) ). \\] We also dropped the term \\(D_{\\mathrm{KL}}( q(z\\mid x)\\parallel p(z\\mid x) )\\) which is always nonnegative. The reason is that we can not maximize this KL divergence as we do not know \\(p(z\\mid x)\\) . But the KL divergence is always non-negative. So if we find a \\(q\\) that can maximize \\(\\mathcal L\\) , then we are also miminizing the KL divergence (with a function \\(q(z\\mid x)\\) that is close to \\(p(z\\mid x)\\) ) and maximizing the loglikelihood loss. Now we only need to find a way to maximize \\(\\mathcal L\\) . More about this ELBO We do not know \\(p(x,z)\\) either but we can rewrite \\(\\mathcal L\\) , \\[\\begin{align} \\mathcal L(q) =& \\int dz q(z\\mid x) \\ln\\frac{p(x,z)}{q(z\\mid x)} \\\\\\\\ =& \\int dz q(z\\mid x)\\ln \\frac{p(x\\mid z)p(z)}{q(z\\mid x)} \\\\\\\\ = & \\int dz q(z\\mid x) \\ln p(x\\mid z) + \\int dz q(z\\mid x) \\ln \\frac{p(z)}{q(z\\mid x)} \\\\\\\\ = & \\int dz q(z\\mid x) \\ln p(x\\mid z) - \\operatorname{KL} \\left( q(z\\mid x) \\parallel p(z) \\right) \\end{align}\\] Our loss function becomes \\[- \\mathcal L(q) = - \\mathbb E_{q} \\ln {\\color{red}p(x\\mid z)} + \\operatorname{KL} \\left( {\\color{blue}q(z\\mid x) }\\parallel p(z) \\right),\\] where \\({\\color{blue}q(z\\mid x) }\\) is our encoder which encodes data \\(x\\) to the latent data \\(z\\) , and \\({\\color{red}p(x\\mid z)}\\) is our decoder. The second term ensures our encoder is similar to our priors. Using Neural networks \u00b6 We model the parameters of the Gaussian distribution \\(p_\\theta(x\\mid z)\\) , e.g., \\(f(z, \\theta)\\) , using a neural network. In reality, we choose a gaussian form of the variational functional with the mean and variance depends on the data \\(x\\) and the latent variable \\(z\\) \\[ q(z\\mid x) = \\mathcal N ( \\mu(x,z), \\Sigma (x,z) ). \\] We have \\[ \\begin{align} &\\ln p_\\theta(x\\mid z) \\\\ =& \\ln \\mathscr N( x\\mid f(z, \\theta), \\sigma^2 I )\\\\ =& \\ln \\left( \\frac{1}{\\sqrt{2\\pi \\sigma^2}} \\exp{\\left( -\\frac{(x -f(z,\\theta)^2)}{\\sigma^2} \\right)} \\right) \\\\ =& -(x - f(z, \\theta))^2 + \\mathrm{Const.} \\end{align} \\] Why don't we simply draw \\(q\\) from \\(p(z)\\) ? If we are sort of minimizing the KL divergence \\(\\operatorname{KL} \\left( {\\color{blue}q(z\\mid x) }\\parallel p(z) \\right)\\) too, why don't we simply draw \\(q\\) from \\(p(z)\\) ? First of all, we also have to take care of the first term. Secondly, we need a latent space that connects to the actual data for reconstruction. Structure \u00b6 Doersch wrote a very nice tutorial on VAE 1 . We can find the detailed structures of VAE. Another key component of VAE is the reparametrization trick . The variational approximation \\(q_\\phi\\) is usually a Gaussian distribution. Once we get the parameters for the Gaussian distribution, we will have to sample from the Gaussian distribution based on the parameters. However, this sampling process prohibits us from propagating errors. The reparametrization trick solves this problem. Loss Explanation \u00b6 VAE Loss Explained 1 Code \u00b6 See Lippe 2 . Doersch C. Tutorial on Variational Autoencoders. arXiv [stat.ML]. 2016. Available: http://arxiv.org/abs/1606.05908 \u21a9 \u21a9 Lippe P. Tutorial 9: Deep Autoencoders \u2014 UvA DL Notebooks v1.1 documentation. In: UvA Deep Learning Tutorials [Internet]. [cited 20 Sep 2021]. Available: https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/tutorial9/AE_CIFAR10.html \u21a9","title":"VAE"},{"location":"self-supervised/generative/vae/#variational-autoencoder","text":"Variational AutoEncoder (VAE) is very different from AE . In VAE, we introduce a variational distribution \\(q\\) to help us work out the weighted integral after introducing the latent space variable \\(z\\) , \\[ \\begin{align} \\ln p_\\theta(x) &= \\int \\left(\\ln p_\\theta (x\\mid z) \\right)p(z) \\,\\mathrm d z \\\\ &= \\int \\left(\\ln\\frac{q_{\\phi}(z\\mid x)}{q_{\\phi}(z\\mid x)} p_\\theta (x\\mid z) \\right) p(z) \\, \\mathrm d z \\end{align} \\] In the above derivation, \\({}_\\theta\\) is the model for inference, and \\({}_\\phi\\) is the model for variational approximation. Tricks \\(p_\\theta(x\\mid z)\\) is usually Gaussian distribution of \\(x\\) but with mean parameterized by the latent variable \\(z\\) and the model parameters \\(\\theta\\) . The latent space variable \\(p(z)\\) is usually assumed to be a normal distribution. The marginalization of the latent variable increase the expressive power. Instead of modeling a complex likelihood \\(p(x\\mid z)\\) directly, we only need to model parameters of Gaussian distributions, e.g., a function \\(f(z, \\theta)\\) for the mean of the Gaussian distribution. From simple distribution in latent space to a more complex distribution. [Doersch2016] The demo looks great. However, sampling from latent space becomes more difficult as the dimension of the latent space increase. We need a more efficient way to sample from the latent space. We use the variational method which uses a model that samples \\(z\\) based on \\(x\\) to sample \\(z\\) , i.e., introduce a function \\(q(z\\mid x)\\) to help us with sampling. \\[ \\begin{align} \\ln p_\\theta(x) &= \\int \\left(\\ln p_\\theta (x\\mid z) \\right)p(z) \\,\\mathrm d z \\\\ &= \\int \\left(\\ln\\frac{q_{\\phi}(z\\mid x)}{q_{\\phi}(z\\mid x)} p_\\theta (x\\mid z) \\right) p(z) \\, \\mathrm d z \\\\ &= \\int dz q(z\\mid x) \\ln \\frac{p(x,z)}{q(z\\mid x)} + \\int dz q(z\\mid x) \\ln \\frac{q(z\\mid x)}{p(z\\mid x)} \\\\ &= - \\left[ D_{\\mathrm{KL}} ( q_{\\phi}(z\\mid x) \\mathrel{\\Vert} p(z) ) - \\mathbb E_q ( \\ln p_\\theta (x\\mid z) ) \\right] + D_{\\mathrm{KL}}( q(z\\mid x)\\parallel p(z\\mid x) ) \\\\ & \\geq - \\left[ D_{\\mathrm{KL}} ( q_{\\phi}(z\\mid x) \\mathrel{\\Vert} p(z) ) - \\mathbb E_q ( \\ln p_\\theta (x\\mid z) ) \\right] \\\\ &\\equiv - F(x) \\\\ &\\equiv \\mathcal L . \\end{align} \\] In the derivation, we used \\(\\int dz q(z\\mid x) = 1\\) . The term \\(F(x)\\) is the free energy, while the negative of it, \\(-F(x)=\\mathcal L\\) , is the so-called Evidence Lower Bound (ELBO) , \\[ \\mathcal L = - D_{\\mathrm{KL}} ( q_{\\phi}(z\\mid x) \\mathrel{\\Vert} p(z) ) + \\mathbb E_q ( \\ln p_\\theta (x\\mid z) ). \\] We also dropped the term \\(D_{\\mathrm{KL}}( q(z\\mid x)\\parallel p(z\\mid x) )\\) which is always nonnegative. The reason is that we can not maximize this KL divergence as we do not know \\(p(z\\mid x)\\) . But the KL divergence is always non-negative. So if we find a \\(q\\) that can maximize \\(\\mathcal L\\) , then we are also miminizing the KL divergence (with a function \\(q(z\\mid x)\\) that is close to \\(p(z\\mid x)\\) ) and maximizing the loglikelihood loss. Now we only need to find a way to maximize \\(\\mathcal L\\) . More about this ELBO We do not know \\(p(x,z)\\) either but we can rewrite \\(\\mathcal L\\) , \\[\\begin{align} \\mathcal L(q) =& \\int dz q(z\\mid x) \\ln\\frac{p(x,z)}{q(z\\mid x)} \\\\\\\\ =& \\int dz q(z\\mid x)\\ln \\frac{p(x\\mid z)p(z)}{q(z\\mid x)} \\\\\\\\ = & \\int dz q(z\\mid x) \\ln p(x\\mid z) + \\int dz q(z\\mid x) \\ln \\frac{p(z)}{q(z\\mid x)} \\\\\\\\ = & \\int dz q(z\\mid x) \\ln p(x\\mid z) - \\operatorname{KL} \\left( q(z\\mid x) \\parallel p(z) \\right) \\end{align}\\] Our loss function becomes \\[- \\mathcal L(q) = - \\mathbb E_{q} \\ln {\\color{red}p(x\\mid z)} + \\operatorname{KL} \\left( {\\color{blue}q(z\\mid x) }\\parallel p(z) \\right),\\] where \\({\\color{blue}q(z\\mid x) }\\) is our encoder which encodes data \\(x\\) to the latent data \\(z\\) , and \\({\\color{red}p(x\\mid z)}\\) is our decoder. The second term ensures our encoder is similar to our priors.","title":"Variational AutoEncoder"},{"location":"self-supervised/generative/vae/#using-neural-networks","text":"We model the parameters of the Gaussian distribution \\(p_\\theta(x\\mid z)\\) , e.g., \\(f(z, \\theta)\\) , using a neural network. In reality, we choose a gaussian form of the variational functional with the mean and variance depends on the data \\(x\\) and the latent variable \\(z\\) \\[ q(z\\mid x) = \\mathcal N ( \\mu(x,z), \\Sigma (x,z) ). \\] We have \\[ \\begin{align} &\\ln p_\\theta(x\\mid z) \\\\ =& \\ln \\mathscr N( x\\mid f(z, \\theta), \\sigma^2 I )\\\\ =& \\ln \\left( \\frac{1}{\\sqrt{2\\pi \\sigma^2}} \\exp{\\left( -\\frac{(x -f(z,\\theta)^2)}{\\sigma^2} \\right)} \\right) \\\\ =& -(x - f(z, \\theta))^2 + \\mathrm{Const.} \\end{align} \\] Why don't we simply draw \\(q\\) from \\(p(z)\\) ? If we are sort of minimizing the KL divergence \\(\\operatorname{KL} \\left( {\\color{blue}q(z\\mid x) }\\parallel p(z) \\right)\\) too, why don't we simply draw \\(q\\) from \\(p(z)\\) ? First of all, we also have to take care of the first term. Secondly, we need a latent space that connects to the actual data for reconstruction.","title":"Using Neural networks"},{"location":"self-supervised/generative/vae/#structure","text":"Doersch wrote a very nice tutorial on VAE 1 . We can find the detailed structures of VAE. Another key component of VAE is the reparametrization trick . The variational approximation \\(q_\\phi\\) is usually a Gaussian distribution. Once we get the parameters for the Gaussian distribution, we will have to sample from the Gaussian distribution based on the parameters. However, this sampling process prohibits us from propagating errors. The reparametrization trick solves this problem.","title":"Structure"},{"location":"self-supervised/generative/vae/#loss-explanation","text":"VAE Loss Explained 1","title":"Loss Explanation"},{"location":"self-supervised/generative/vae/#code","text":"See Lippe 2 . Doersch C. Tutorial on Variational Autoencoders. arXiv [stat.ML]. 2016. Available: http://arxiv.org/abs/1606.05908 \u21a9 \u21a9 Lippe P. Tutorial 9: Deep Autoencoders \u2014 UvA DL Notebooks v1.1 documentation. In: UvA Deep Learning Tutorials [Internet]. [cited 20 Sep 2021]. Available: https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/tutorial9/AE_CIFAR10.html \u21a9","title":"Code"},{"location":"supplementary/","text":"Appendices \u00b6 Many formulae and concepts are reused again and again in different models. In this chapter, we will provide support for such concepts.","title":"Appendices"},{"location":"supplementary/#appendices","text":"Many formulae and concepts are reused again and again in different models. In this chapter, we will provide support for such concepts.","title":"Appendices"},{"location":"supplementary/alignment-and-uniformity/","text":"Alignment and Uniformity \u00b6 A good representation should be able to separate different instances, and cluster similar instances. Wang et al proposed two concepts that matches the above two ideas, alignment and uniformity, on a hypersphere 1 . From Wang et al 1 . Wang T, Isola P. Understanding Contrastive Representation Learning through Alignment and Uniformity on the Hypersphere. arXiv [cs.LG]. 2020. Available: http://arxiv.org/abs/2005.10242 \u21a9 \u21a9","title":"Alignment and Uniformity"},{"location":"supplementary/alignment-and-uniformity/#alignment-and-uniformity","text":"A good representation should be able to separate different instances, and cluster similar instances. Wang et al proposed two concepts that matches the above two ideas, alignment and uniformity, on a hypersphere 1 . From Wang et al 1 . Wang T, Isola P. Understanding Contrastive Representation Learning through Alignment and Uniformity on the Hypersphere. arXiv [cs.LG]. 2020. Available: http://arxiv.org/abs/2005.10242 \u21a9 \u21a9","title":"Alignment and Uniformity"},{"location":"supplementary/elbo/","text":"ELBO \u00b6 2022. 12. 31 \u00b6 \u6ca1\u6709\u4eba\u4f1a\u4e3b\u52a8\u5730\u628a\u81ea\u5df1\u6295\u5165\u75db\u82e6\u4e4b\u4e2d\uff0c\u5373\u4f7f\u6709\u4e9b\u4eba\u60f3\u8981\u9003\u79bb\u5374\u65e0\u6cd5\u9003\u79bb\u81ea\u5df1\u7ed9\u81ea\u5df1\u5236\u9020\u7684\u75db\u82e6\u800c\u5bfb\u6c42\u5916\u754c\u7684\u5e2e\u52a9\uff0c\u90a3\u4e5f\u53ea\u662f\u4ed6\u4eec\u6ca1\u6709\u610f\u8bc6\u5230\u4ed6\u4eec\u6240\u505a\u7684 is the only way that makes themselves enjoyed. \u6211\u603b\u662f\u60f3\u529e\u6cd5\u8ba9\u6211\u7684\u5de5\u4f5c\u6548\u7387\u63d0\u9ad8\uff0c\u51cf\u5c11\u65f6\u95f4\u7684\u6d6a\u8d39\u3002\u60f3\u626b\u6e05\u4e00\u5207\u969c\u788d\uff0c\u4ee5\u81f3\u4e8e\u6700\u540e\u5173\u6ce8\u5230\u4e00\u4e9b\u7ec6\u679d\u672b\u8282\u3002It works to some extend in certain circumstance. \u4f46\u662f\u6211\u597d\u50cf\u5ffd\u89c6\u4e86\u95ee\u9898\u7684\u53e6\u4e00\u9762\uff0c\u52a8\u529b\u3002 What is the problem (pattern) that I'm using in my work? \u5728\u6211\u76ee\u524d\u7684\u79d1\u7814\u5de5\u4f5c\u4e2d\uff0c\u4e00\u4e2a\u5f88\u7a81\u51fa\u7684\u95ee\u9898\u5c31\u662f\u6ca1\u80fd\u5408\u7406\u5730\u5206\u914d\u65f6\u95f4\uff0c\u800c\u4e14\u7528\u5728\u79d1\u7814\u4e0a\u7684\u65f6\u95f4\u8fdc\u8fdc\u4e0d\u591f\u4e00\u4e2aphd\u6bd5\u4e1a\u6240\u9700\u8981\u7684\u5de5\u4f5c\u65f6\u95f4\u3002\u603b\u662f\u5728\u6253\u6e38\u620f\u6216\u8005\u65e0\u6240\u4e8b\u4e8b\u4e2d\u5ea6\u8fc7\u5468\u672b\u548c\u5468\u4e00\uff0c\u6216\u8005\u662f\u82b1\u5728\u4e86\u4e00\u4e9b\u5f88\u6ca1\u6709\u6548\u7387\u7684discussion\u548ccoding\u4e0a\u3002\u800c\u5230\u4e86\u9700\u8981\u6c47\u62a5\u6210\u679c\u6216\u8005\u5f00\u4f1a\u7684\u90a3\u51e0\u5929\uff0c\u603b\u662f\u60f3\u8d76\u51fa\u6765\u4e00\u4e9bresults\uff0c\u800c\u8fd9\u4e9bresults\u53c8\u6ca1\u6709\u7ecf\u8fc7\u6df1\u601d\u719f\u8651\uff0c\u4e00\u4e9b\u91cd\u8981\u4e14\u82b1\u8d39\u65f6\u95f4\u7684\u5de5\u4f5c\u5c31\u65e0\u6cd5\u8fdb\u884c\u3002 What makes this pattern? \u5bf9\u4e0e\u7b2c\u4e00\u4e2a\u95ee\u9898\uff0c\u65f6\u95f4\u5206\u914d\u4e0d\u8db3\uff0c\u6211\u80fd\u60f3\u51fa\u7684\u6700\u7b80\u5355\u7684\u539f\u56e0\u5c31\u662f I'm not enjoying it very much. Deep in my consciousness, I feel like my time should be spent on something else but not all in research although I never claim it. If I enjoy what I'm doing and think it worth the time, I'd spend more time on it rather than what I'm doing right now. \u5bf9\u4e8e\u7b2c\u4e8c\u4e2a\u95ee\u9898\uff0c\u65f6\u95f4\u5206\u914d\u7684\u4e0d\u5408\u7406\uff0c\u539f\u56e0\u4e5f\u5f88\u76f4\u63a5\uff0c\u56e0\u4e3a\u4e34\u8fd1deadline\u7684\u65f6\u5019\u6211\u7684\u6548\u7387\u4f1a\u66f4\u9ad8\u3002\u6ce8\u610f\u529b\u4e5f\u66f4\u96c6\u4e2d\u3002\u867d\u7136\u8868\u9762\u4e0a\u6211\u5f88\u4e0d\u559c\u6b22\u8fd9\u6837\u7684\u5de5\u4f5c\u6a21\u5f0f\uff0c\u5b83\u7684\u538b\u8feb\u611f\u8ba9\u4eba\u5341\u5206\u96be\u53d7\u3002\u4f46\u5176\u5b9e\u5185\u5fc3\u91cc\u6211\u66f4\u4e3a\u63a5\u53d7\u5b83\u7684\u9ad8\u6548\u7387\u3002 \u5bf9\u4e8e\u7b2c\u4e00\u4e2a\u95ee\u9898\u7684\u5f62\u6210\u539f\u56e0\u7684\u8fdb\u4e00\u6b65\u5206\u6790\uff0c\u6211\u6ca1\u6709\u5f88enjoy what I'm working on\uff0c\u662f\u56e0\u4e3a\uff1a\u7b2c\u4e00\uff0c\u9996\u5148\u5bf9\u6211\u5728\u7814\u7a76\u7684\u95ee\u9898\u7684\u80cc\u666f\u6ca1\u6709\u7279\u522b\u6df1\u5165\u7684\u4e86\u89e3\uff1b\u7b2c\u4e8c\uff0c\u8fd9\u4e0d\u662f\u6211\u5341\u5206\u64c5\u957f\u7684\u5de5\u4f5c\uff1b\u7b2c\u4e09\uff0c\u5bf9\u6211\u6240\u505a\u7684\u5de5\u4f5c\u7684\u6210\u679c\u4f1a\u6709\u4ec0\u4e48\u7528\u9014\u6ca1\u6709\u6e05\u6670\u7684\u8ba4\u77e5\u3002\u9664\u4e86\u8fd9\u4e09\u70b9\u6700\u76f4\u63a5\u7684\u539f\u56e0\u4e4b\u5916\uff0c\u6216\u8005\u8bf4\u7efc\u5408\u8d77\u6765\u9000\u4e00\u6b65\u8bb2\uff0cI think there are something more important things for me to do, there are some else worth my time. What is that thing? (I will spend time to think and write it down.) How do I solve this problem? \u7b2c\u4e00\uff0c\u6211\u9700\u8981\u5206\u914d\u8db3\u591f\u7684\u65f6\u95f4\u5728\u6211\u8ba4\u4e3a\u6709\u4ef7\u503c\u7684\u4e8b\u60c5\u4e0a\u3002\u4e00\u4e2a\u4e00\u592912\u4e2a\u5c0f\u65f6research work\u7684\u8ba1\u5212\u53ea\u662f\u5728\u6b3a\u9a97\u81ea\u5df1\uff0c\u6211\u5185\u5fc3\u5e76\u4e0d\u4f1a\u8ba4\u540c\u5b83,\u800c\u4e14\u4f1a\u5bf9\u8fd9\u6837\u7684\u8ba1\u5212\u611f\u5230\u975e\u5e38\u7684frustrated\u3002\u7b2c\u4e8c\uff0c\u8981\u5199\u4e00\u4e2a\u6211\u81ea\u5df1\u7814\u7a76\u7684\u95ee\u9898\u7684review\uff0c\u5e76\u4e14\u8981\u62ff\u7740\u5b83\u53bb\u548c\u522b\u4eba\u8ba8\u8bba\u3002\u7b2c\u4e09\uff0c\u8981\u5206\u6e05work\u7684\u4e3b\u6b21\uff0c\u626d\u8f6c\u90a3\u4e9b\u4f4e\u6548\u7684\u82b1\u65f6\u95f4\u7684\u884c\u4e3a\u3002\uff08\u8fd9\u4e2a\u7b2c\u4e09\u70b9\u8fd8\u6ca1\u6709\u8003\u8651\u597d\u3002\uff09 \u4eca\u5929\u770b\u4e86\u4e00\u4f1a\u9ec4\u77f3\u7b2c\u4e94\u5b63\uff0cI felt like there will be some work/job that I'd enjoy very much although right now I don't know what it is. But there are some work/job I definitely don't what to get involved in. I know what they are. 2022. 01. 11 \u00b6","title":"ELBO"},{"location":"supplementary/elbo/#elbo","text":"","title":"ELBO"},{"location":"supplementary/elbo/#2022-12-31","text":"\u6ca1\u6709\u4eba\u4f1a\u4e3b\u52a8\u5730\u628a\u81ea\u5df1\u6295\u5165\u75db\u82e6\u4e4b\u4e2d\uff0c\u5373\u4f7f\u6709\u4e9b\u4eba\u60f3\u8981\u9003\u79bb\u5374\u65e0\u6cd5\u9003\u79bb\u81ea\u5df1\u7ed9\u81ea\u5df1\u5236\u9020\u7684\u75db\u82e6\u800c\u5bfb\u6c42\u5916\u754c\u7684\u5e2e\u52a9\uff0c\u90a3\u4e5f\u53ea\u662f\u4ed6\u4eec\u6ca1\u6709\u610f\u8bc6\u5230\u4ed6\u4eec\u6240\u505a\u7684 is the only way that makes themselves enjoyed. \u6211\u603b\u662f\u60f3\u529e\u6cd5\u8ba9\u6211\u7684\u5de5\u4f5c\u6548\u7387\u63d0\u9ad8\uff0c\u51cf\u5c11\u65f6\u95f4\u7684\u6d6a\u8d39\u3002\u60f3\u626b\u6e05\u4e00\u5207\u969c\u788d\uff0c\u4ee5\u81f3\u4e8e\u6700\u540e\u5173\u6ce8\u5230\u4e00\u4e9b\u7ec6\u679d\u672b\u8282\u3002It works to some extend in certain circumstance. \u4f46\u662f\u6211\u597d\u50cf\u5ffd\u89c6\u4e86\u95ee\u9898\u7684\u53e6\u4e00\u9762\uff0c\u52a8\u529b\u3002 What is the problem (pattern) that I'm using in my work? \u5728\u6211\u76ee\u524d\u7684\u79d1\u7814\u5de5\u4f5c\u4e2d\uff0c\u4e00\u4e2a\u5f88\u7a81\u51fa\u7684\u95ee\u9898\u5c31\u662f\u6ca1\u80fd\u5408\u7406\u5730\u5206\u914d\u65f6\u95f4\uff0c\u800c\u4e14\u7528\u5728\u79d1\u7814\u4e0a\u7684\u65f6\u95f4\u8fdc\u8fdc\u4e0d\u591f\u4e00\u4e2aphd\u6bd5\u4e1a\u6240\u9700\u8981\u7684\u5de5\u4f5c\u65f6\u95f4\u3002\u603b\u662f\u5728\u6253\u6e38\u620f\u6216\u8005\u65e0\u6240\u4e8b\u4e8b\u4e2d\u5ea6\u8fc7\u5468\u672b\u548c\u5468\u4e00\uff0c\u6216\u8005\u662f\u82b1\u5728\u4e86\u4e00\u4e9b\u5f88\u6ca1\u6709\u6548\u7387\u7684discussion\u548ccoding\u4e0a\u3002\u800c\u5230\u4e86\u9700\u8981\u6c47\u62a5\u6210\u679c\u6216\u8005\u5f00\u4f1a\u7684\u90a3\u51e0\u5929\uff0c\u603b\u662f\u60f3\u8d76\u51fa\u6765\u4e00\u4e9bresults\uff0c\u800c\u8fd9\u4e9bresults\u53c8\u6ca1\u6709\u7ecf\u8fc7\u6df1\u601d\u719f\u8651\uff0c\u4e00\u4e9b\u91cd\u8981\u4e14\u82b1\u8d39\u65f6\u95f4\u7684\u5de5\u4f5c\u5c31\u65e0\u6cd5\u8fdb\u884c\u3002 What makes this pattern? \u5bf9\u4e0e\u7b2c\u4e00\u4e2a\u95ee\u9898\uff0c\u65f6\u95f4\u5206\u914d\u4e0d\u8db3\uff0c\u6211\u80fd\u60f3\u51fa\u7684\u6700\u7b80\u5355\u7684\u539f\u56e0\u5c31\u662f I'm not enjoying it very much. Deep in my consciousness, I feel like my time should be spent on something else but not all in research although I never claim it. If I enjoy what I'm doing and think it worth the time, I'd spend more time on it rather than what I'm doing right now. \u5bf9\u4e8e\u7b2c\u4e8c\u4e2a\u95ee\u9898\uff0c\u65f6\u95f4\u5206\u914d\u7684\u4e0d\u5408\u7406\uff0c\u539f\u56e0\u4e5f\u5f88\u76f4\u63a5\uff0c\u56e0\u4e3a\u4e34\u8fd1deadline\u7684\u65f6\u5019\u6211\u7684\u6548\u7387\u4f1a\u66f4\u9ad8\u3002\u6ce8\u610f\u529b\u4e5f\u66f4\u96c6\u4e2d\u3002\u867d\u7136\u8868\u9762\u4e0a\u6211\u5f88\u4e0d\u559c\u6b22\u8fd9\u6837\u7684\u5de5\u4f5c\u6a21\u5f0f\uff0c\u5b83\u7684\u538b\u8feb\u611f\u8ba9\u4eba\u5341\u5206\u96be\u53d7\u3002\u4f46\u5176\u5b9e\u5185\u5fc3\u91cc\u6211\u66f4\u4e3a\u63a5\u53d7\u5b83\u7684\u9ad8\u6548\u7387\u3002 \u5bf9\u4e8e\u7b2c\u4e00\u4e2a\u95ee\u9898\u7684\u5f62\u6210\u539f\u56e0\u7684\u8fdb\u4e00\u6b65\u5206\u6790\uff0c\u6211\u6ca1\u6709\u5f88enjoy what I'm working on\uff0c\u662f\u56e0\u4e3a\uff1a\u7b2c\u4e00\uff0c\u9996\u5148\u5bf9\u6211\u5728\u7814\u7a76\u7684\u95ee\u9898\u7684\u80cc\u666f\u6ca1\u6709\u7279\u522b\u6df1\u5165\u7684\u4e86\u89e3\uff1b\u7b2c\u4e8c\uff0c\u8fd9\u4e0d\u662f\u6211\u5341\u5206\u64c5\u957f\u7684\u5de5\u4f5c\uff1b\u7b2c\u4e09\uff0c\u5bf9\u6211\u6240\u505a\u7684\u5de5\u4f5c\u7684\u6210\u679c\u4f1a\u6709\u4ec0\u4e48\u7528\u9014\u6ca1\u6709\u6e05\u6670\u7684\u8ba4\u77e5\u3002\u9664\u4e86\u8fd9\u4e09\u70b9\u6700\u76f4\u63a5\u7684\u539f\u56e0\u4e4b\u5916\uff0c\u6216\u8005\u8bf4\u7efc\u5408\u8d77\u6765\u9000\u4e00\u6b65\u8bb2\uff0cI think there are something more important things for me to do, there are some else worth my time. What is that thing? (I will spend time to think and write it down.) How do I solve this problem? \u7b2c\u4e00\uff0c\u6211\u9700\u8981\u5206\u914d\u8db3\u591f\u7684\u65f6\u95f4\u5728\u6211\u8ba4\u4e3a\u6709\u4ef7\u503c\u7684\u4e8b\u60c5\u4e0a\u3002\u4e00\u4e2a\u4e00\u592912\u4e2a\u5c0f\u65f6research work\u7684\u8ba1\u5212\u53ea\u662f\u5728\u6b3a\u9a97\u81ea\u5df1\uff0c\u6211\u5185\u5fc3\u5e76\u4e0d\u4f1a\u8ba4\u540c\u5b83,\u800c\u4e14\u4f1a\u5bf9\u8fd9\u6837\u7684\u8ba1\u5212\u611f\u5230\u975e\u5e38\u7684frustrated\u3002\u7b2c\u4e8c\uff0c\u8981\u5199\u4e00\u4e2a\u6211\u81ea\u5df1\u7814\u7a76\u7684\u95ee\u9898\u7684review\uff0c\u5e76\u4e14\u8981\u62ff\u7740\u5b83\u53bb\u548c\u522b\u4eba\u8ba8\u8bba\u3002\u7b2c\u4e09\uff0c\u8981\u5206\u6e05work\u7684\u4e3b\u6b21\uff0c\u626d\u8f6c\u90a3\u4e9b\u4f4e\u6548\u7684\u82b1\u65f6\u95f4\u7684\u884c\u4e3a\u3002\uff08\u8fd9\u4e2a\u7b2c\u4e09\u70b9\u8fd8\u6ca1\u6709\u8003\u8651\u597d\u3002\uff09 \u4eca\u5929\u770b\u4e86\u4e00\u4f1a\u9ec4\u77f3\u7b2c\u4e94\u5b63\uff0cI felt like there will be some work/job that I'd enjoy very much although right now I don't know what it is. But there are some work/job I definitely don't what to get involved in. I know what they are.","title":"2022. 12. 31"},{"location":"supplementary/elbo/#2022-01-11","text":"","title":"2022. 01. 11"},{"location":"supplementary/entropy/","text":"Entropy \u00b6 Shannon Entropy \u00b6 Shannon entropy \\(S\\) is the expectation of information content \\(I(X)=-\\log \\left(p\\right)\\) 1 , \\[\\begin{equation} H(p) = \\mathbb E_{p}\\left[ -\\log \\left(p\\right) \\right]. \\end{equation}\\] Cross Entropy \u00b6 Cross entropy is 2 \\[ H(p, q) = \\mathbb E_{p} \\left[ -\\log q \\right]. \\] Cross entropy \\(H(p, q)\\) can also be decomposed, \\[ H(p, q) = H(p) + \\operatorname{D}_{\\mathrm{KL}} \\left( p \\parallel q \\right), \\] where \\(H(p)\\) is the entropy of \\(P\\) and \\(\\operatorname{D}_{\\mathrm{KL}}\\) is the KL Divergence . Cross entropy is widely used in classification problems, e.g., logistic regression. Contributors to Wikimedia projects. Entropy (information theory). In: Wikipedia [Internet]. 29 Aug 2021 [cited 4 Sep 2021]. Available: https://en.wikipedia.org/wiki/Entropy_(information_theory ) \u21a9 Contributors to Wikimedia projects. Cross entropy. In: Wikipedia [Internet]. 4 Jul 2021 [cited 4 Sep 2021]. Available: https://en.wikipedia.org/wiki/Cross_entropy \u21a9","title":"Entropy"},{"location":"supplementary/entropy/#entropy","text":"","title":"Entropy"},{"location":"supplementary/entropy/#shannon-entropy","text":"Shannon entropy \\(S\\) is the expectation of information content \\(I(X)=-\\log \\left(p\\right)\\) 1 , \\[\\begin{equation} H(p) = \\mathbb E_{p}\\left[ -\\log \\left(p\\right) \\right]. \\end{equation}\\]","title":"Shannon Entropy"},{"location":"supplementary/entropy/#cross-entropy","text":"Cross entropy is 2 \\[ H(p, q) = \\mathbb E_{p} \\left[ -\\log q \\right]. \\] Cross entropy \\(H(p, q)\\) can also be decomposed, \\[ H(p, q) = H(p) + \\operatorname{D}_{\\mathrm{KL}} \\left( p \\parallel q \\right), \\] where \\(H(p)\\) is the entropy of \\(P\\) and \\(\\operatorname{D}_{\\mathrm{KL}}\\) is the KL Divergence . Cross entropy is widely used in classification problems, e.g., logistic regression. Contributors to Wikimedia projects. Entropy (information theory). In: Wikipedia [Internet]. 29 Aug 2021 [cited 4 Sep 2021]. Available: https://en.wikipedia.org/wiki/Entropy_(information_theory ) \u21a9 Contributors to Wikimedia projects. Cross entropy. In: Wikipedia [Internet]. 4 Jul 2021 [cited 4 Sep 2021]. Available: https://en.wikipedia.org/wiki/Cross_entropy \u21a9","title":"Cross Entropy"},{"location":"supplementary/f-divergence/","text":"f-Divergence \u00b6 The f-divergence is defined as 1 \\[ \\operatorname{D}_f = \\int f\\left(\\frac{p}{q}\\right) q\\mathrm d\\mu, \\] where \\(p\\) and \\(q\\) are two densities and \\(\\mu\\) is a reference distribution. Requirements on the generating function The generating function \\(f\\) is required to be convex, and \\(f(1) =0\\) . For \\(f(x) = x \\log x\\) with \\(x=p/q\\) , f-divergence is reduced to the KL divergence \\[ \\begin{align} &\\int f\\left(\\frac{p}{q}\\right) q\\mathrm d\\mu \\\\ =& \\int \\frac{p}{q} \\log \\left( \\frac{p}{q} \\right) \\mathrm d\\mu \\\\ =& \\int p \\log \\left( \\frac{p}{q} \\right) \\mathrm d\\mu. \\end{align} \\] For more special cases of f-divergence, please refer to wikipedia 1 . Nowozin 2016 also provides a concise review of f-divergence 2 . Contributors to Wikimedia projects. F-divergence. In: Wikipedia [Internet]. 17 Jul 2021 [cited 4 Sep 2021]. Available: https://en.wikipedia.org/wiki/F-divergence \u21a9 \u21a9 Nowozin S, Cseke B, Tomioka R. f-GAN: Training Generative Neural Samplers using Variational Divergence Minimization. arXiv [stat.ML]. 2016. Available: http://arxiv.org/abs/1606.00709 \u21a9","title":"f-divergence"},{"location":"supplementary/f-divergence/#f-divergence","text":"The f-divergence is defined as 1 \\[ \\operatorname{D}_f = \\int f\\left(\\frac{p}{q}\\right) q\\mathrm d\\mu, \\] where \\(p\\) and \\(q\\) are two densities and \\(\\mu\\) is a reference distribution. Requirements on the generating function The generating function \\(f\\) is required to be convex, and \\(f(1) =0\\) . For \\(f(x) = x \\log x\\) with \\(x=p/q\\) , f-divergence is reduced to the KL divergence \\[ \\begin{align} &\\int f\\left(\\frac{p}{q}\\right) q\\mathrm d\\mu \\\\ =& \\int \\frac{p}{q} \\log \\left( \\frac{p}{q} \\right) \\mathrm d\\mu \\\\ =& \\int p \\log \\left( \\frac{p}{q} \\right) \\mathrm d\\mu. \\end{align} \\] For more special cases of f-divergence, please refer to wikipedia 1 . Nowozin 2016 also provides a concise review of f-divergence 2 . Contributors to Wikimedia projects. F-divergence. In: Wikipedia [Internet]. 17 Jul 2021 [cited 4 Sep 2021]. Available: https://en.wikipedia.org/wiki/F-divergence \u21a9 \u21a9 Nowozin S, Cseke B, Tomioka R. f-GAN: Training Generative Neural Samplers using Variational Divergence Minimization. arXiv [stat.ML]. 2016. Available: http://arxiv.org/abs/1606.00709 \u21a9","title":"f-Divergence"},{"location":"supplementary/kl-divergence/","text":"KL Divergence \u00b6 The Kullback\u2013Leibler (KL) divergence is defined as \\[ \\begin{align} \\operatorname{D}_\\mathrm{KL}(p \\parallel q ) =& \\mathbb E_{p} \\left[\\log\\left(\\frac{p}{q}\\right) \\right] \\\\ =& \\int_{-\\infty}^\\infty p \\log\\left(\\frac{p}{q}\\right)\\, dx . \\end{align} \\] Suppose \\(p\\) is a Gaussian distribution and \\(q\\) is a bimodal Gaussian mixture, the KL divergence \\(\\operatorname{D}_\\mathrm{KL}(p \\parallel q )\\) and \\(\\operatorname{D}_\\mathrm{KL}(q \\parallel p )\\) are different as KL divergence is not necessarily symmetric. Thus the KL divergence is not a proper distance definition. KL divergence is a special case of f-divergence .","title":"KL Divergence"},{"location":"supplementary/kl-divergence/#kl-divergence","text":"The Kullback\u2013Leibler (KL) divergence is defined as \\[ \\begin{align} \\operatorname{D}_\\mathrm{KL}(p \\parallel q ) =& \\mathbb E_{p} \\left[\\log\\left(\\frac{p}{q}\\right) \\right] \\\\ =& \\int_{-\\infty}^\\infty p \\log\\left(\\frac{p}{q}\\right)\\, dx . \\end{align} \\] Suppose \\(p\\) is a Gaussian distribution and \\(q\\) is a bimodal Gaussian mixture, the KL divergence \\(\\operatorname{D}_\\mathrm{KL}(p \\parallel q )\\) and \\(\\operatorname{D}_\\mathrm{KL}(q \\parallel p )\\) are different as KL divergence is not necessarily symmetric. Thus the KL divergence is not a proper distance definition. KL divergence is a special case of f-divergence .","title":"KL Divergence"},{"location":"supplementary/mutual-information/","text":"Mutual Information \u00b6 Mutual information is \\[ I(X;Y) = \\mathbb E_{p_{XY}} \\ln \\frac{P_{XY}}{P_X P_Y}. \\] Mutual information is closed related to KL divergence , \\[ I(X;Y) = D_{\\mathrm{KL}} \\left( P_{XY}(x,y) \\parallel P_X(x) P_{Y}(y) \\right). \\]","title":"Mutual Information"},{"location":"supplementary/mutual-information/#mutual-information","text":"Mutual information is \\[ I(X;Y) = \\mathbb E_{p_{XY}} \\ln \\frac{P_{XY}}{P_X P_Y}. \\] Mutual information is closed related to KL divergence , \\[ I(X;Y) = D_{\\mathrm{KL}} \\left( P_{XY}(x,y) \\parallel P_X(x) P_{Y}(y) \\right). \\]","title":"Mutual Information"},{"location":"supplementary/nce/","text":"NCE \u00b6","title":"NCE"},{"location":"supplementary/nce/#nce","text":"","title":"NCE"},{"location":"time-series/","text":"Time Series Forecasting using Deep Learning \u00b6 Time series forecasting using deep learning is a fast growing topic in the research community. To get a grasp of the trend, we created the following chart using the keyword \"deep learning forecasting\" on dimensions.ai ). 1 This chart is obtained on 2022-08-06, from Digital Science\u2019s Dimensions platform, available at https://app.dimensions.ai Time Series Data \u00b6 Time series data comes from a variety of data generating processes. There are also different formulations and views of time series data. Time series data can be formulated time series data as sequence of vectors as a function of time. 2 There are many different types of tasks on time series data, for example, classification, anomaly detection, and forecasting. In this chapter, we focus on the forecasting problem. The Forecasting Problem \u00b6 To make it easier to formulate the forecasting problem, we group the time series features based on the role they play in a forecasting problem. Given a dataset \\(\\mathcal D\\) , with \\(y^{(i)}_t\\) , the sequential variable to be forecasted, \\(x^{(i)}_t\\) , exogenous data for the time series data, \\(u^{(i)}_t\\) , some features that can be obtained or planned in advance, where \\({}^{(i)}\\) indicates the \\(i\\) th variable, \\({}_ t\\) denotes time. In a forecasting task, we use \\(y^{(i)} _ {t-K:t}\\) , \\(x^{(i) _ {t-K:t}}\\) , and \\(u^{(i)} _ {t-K:t+H}\\) , to forecast the future \\(y^{(i)} _ {t+1:t+H}\\) . In these notations, \\(K\\) is the input sequence length and \\(H\\) is the forecast horizon. A forecasting model \\(f\\) will use \\(x^{(i)} _ {t-K:t}\\) and \\(u^{(i)} _ {t-K:t+H}\\) to forecast \\(y^{(i)} _ {t+1:t+H}\\) . The Time Delay Embedding Representation \u00b6 The time delay embedding representation of a time series forecasting problem is a concise representation of the forecasting problem 3 . For simplicity, we only write down the representation for a problem with time series \\(y_{1}, \\cdots, y_{t}\\) , and forecasting \\(y_{t+1}\\) . We rewrite the series into a matrix, in an autoregressive way, \\[ \\begin{align} \\mathbf Y = \\begin{bmatrix} y_1 & y_2 & \\cdots & y_p &\\Big| & {\\color{red}y_{p+1}} \\\\ y_{1+1} & y_{1+2} & \\cdots & y_{1+p} &\\Big| & {\\color{red}y_{1+p+1}} \\\\ \\vdots & \\vdots & \\ddots & \\vdots &\\Big| & {\\color{red}\\vdots} \\\\ y_{i-p+1} & y_{i-p+2} & \\cdots & y_{i} &\\Big| & {\\color{red}y_{i+1}} \\\\ \\vdots & \\vdots & \\ddots & \\vdots &\\Big| & {\\color{red}\\vdots} \\\\ y_{t-p+1} & y_{t-p+2} & \\cdots & y_{t} &\\Big| & {\\color{red}y_{t+1}} \\\\ \\end{bmatrix} \\end{align} \\] which indicates that we will use everything on the left, a matrix of shape \\((t-p+1,p)\\) , to predict the vector on the right (in red). Methods of Forecasting Methods \u00b6 T. Januschowsk et al proposed a framework to classify the different forecasting methods. 4 We illustrate the different methods in the following charts. flowchart TB subgraph Objective params_shared[\"Parameter Shared Accross Series\"] params_shared --\"True\"-->Global params_shared --\"False\"-->Local uncertainty[\"Uncertainty in Forecasts\"] uncertainty --\"True\"--> Probabilistic[\"Probabilistic Forecasts:\\n forecasts with predictive uncertainty\"] uncertainty --\"False\"--> Point[\"Point Forecasts\"] computational_complexity[\"Computational Complexity\"] end subgraph Subjective structural_assumptions[\"Strong Structural Assumption\"] --\"Yes\"--> model_driven[\"Model-Driven\"] structural_assumptions --\"No\"--> data_driven[\"Data-Driven\"] model_comb[\"Model Combinations\"] discriminative_generative[\"Discriminative or Generative\"] theoretical_guarantees[\"Theoretical Guarantees\"] predictability_interpretability[\"Predictability and Interpretibility\"] end Daniel W. Hook, Simon J. Porter, and Christian Herzog. Dimensions: building context for search and evaluation. Frontiers in Research Metrics and Analytics , 3():23, 2018. https://www.frontiersin.org/articles/10.3389/frma.2018.00023/pdf . URL: https://app.dimensions.ai/details/publication/pub.1106289502 , doi:10.3389/frma.2018.00023 . \u21a9 Georg Dorffner. Neural networks for time series processing. Neural Network World , 6:447\u2013468, 1996. URL: http://machine-learning.martinsewell.com/ann/Dorf96.pdf . \u21a9 Hansika Hewamalage, Klaus Ackermann, and Christoph Bergmeir. Forecast evaluation for data scientists: common pitfalls and best practices. 21 March 2022. URL: http://arxiv.org/abs/2203.10716 , arXiv:2203.10716 . \u21a9 Tim Januschowski, Jan Gasthaus, Yuyang Wang, David Salinas, Valentin Flunkert, Michael Bohlke-Schneider, and Laurent Callot. Criteria for classifying forecasting methods. International journal of forecasting , 36(1):167\u2013177, 1 January 2020. URL: https://www.sciencedirect.com/science/article/pii/S0169207019301529 , doi:10.1016/j.ijforecast.2019.05.008 . \u21a9","title":"Time Series Forecasting using Deep Learning"},{"location":"time-series/#time-series-forecasting-using-deep-learning","text":"Time series forecasting using deep learning is a fast growing topic in the research community. To get a grasp of the trend, we created the following chart using the keyword \"deep learning forecasting\" on dimensions.ai ). 1 This chart is obtained on 2022-08-06, from Digital Science\u2019s Dimensions platform, available at https://app.dimensions.ai","title":"Time Series Forecasting using Deep Learning"},{"location":"time-series/#time-series-data","text":"Time series data comes from a variety of data generating processes. There are also different formulations and views of time series data. Time series data can be formulated time series data as sequence of vectors as a function of time. 2 There are many different types of tasks on time series data, for example, classification, anomaly detection, and forecasting. In this chapter, we focus on the forecasting problem.","title":"Time Series Data"},{"location":"time-series/#the-forecasting-problem","text":"To make it easier to formulate the forecasting problem, we group the time series features based on the role they play in a forecasting problem. Given a dataset \\(\\mathcal D\\) , with \\(y^{(i)}_t\\) , the sequential variable to be forecasted, \\(x^{(i)}_t\\) , exogenous data for the time series data, \\(u^{(i)}_t\\) , some features that can be obtained or planned in advance, where \\({}^{(i)}\\) indicates the \\(i\\) th variable, \\({}_ t\\) denotes time. In a forecasting task, we use \\(y^{(i)} _ {t-K:t}\\) , \\(x^{(i) _ {t-K:t}}\\) , and \\(u^{(i)} _ {t-K:t+H}\\) , to forecast the future \\(y^{(i)} _ {t+1:t+H}\\) . In these notations, \\(K\\) is the input sequence length and \\(H\\) is the forecast horizon. A forecasting model \\(f\\) will use \\(x^{(i)} _ {t-K:t}\\) and \\(u^{(i)} _ {t-K:t+H}\\) to forecast \\(y^{(i)} _ {t+1:t+H}\\) .","title":"The Forecasting Problem"},{"location":"time-series/#the-time-delay-embedding-representation","text":"The time delay embedding representation of a time series forecasting problem is a concise representation of the forecasting problem 3 . For simplicity, we only write down the representation for a problem with time series \\(y_{1}, \\cdots, y_{t}\\) , and forecasting \\(y_{t+1}\\) . We rewrite the series into a matrix, in an autoregressive way, \\[ \\begin{align} \\mathbf Y = \\begin{bmatrix} y_1 & y_2 & \\cdots & y_p &\\Big| & {\\color{red}y_{p+1}} \\\\ y_{1+1} & y_{1+2} & \\cdots & y_{1+p} &\\Big| & {\\color{red}y_{1+p+1}} \\\\ \\vdots & \\vdots & \\ddots & \\vdots &\\Big| & {\\color{red}\\vdots} \\\\ y_{i-p+1} & y_{i-p+2} & \\cdots & y_{i} &\\Big| & {\\color{red}y_{i+1}} \\\\ \\vdots & \\vdots & \\ddots & \\vdots &\\Big| & {\\color{red}\\vdots} \\\\ y_{t-p+1} & y_{t-p+2} & \\cdots & y_{t} &\\Big| & {\\color{red}y_{t+1}} \\\\ \\end{bmatrix} \\end{align} \\] which indicates that we will use everything on the left, a matrix of shape \\((t-p+1,p)\\) , to predict the vector on the right (in red).","title":"The Time Delay Embedding Representation"},{"location":"time-series/#methods-of-forecasting-methods","text":"T. Januschowsk et al proposed a framework to classify the different forecasting methods. 4 We illustrate the different methods in the following charts. flowchart TB subgraph Objective params_shared[\"Parameter Shared Accross Series\"] params_shared --\"True\"-->Global params_shared --\"False\"-->Local uncertainty[\"Uncertainty in Forecasts\"] uncertainty --\"True\"--> Probabilistic[\"Probabilistic Forecasts:\\n forecasts with predictive uncertainty\"] uncertainty --\"False\"--> Point[\"Point Forecasts\"] computational_complexity[\"Computational Complexity\"] end subgraph Subjective structural_assumptions[\"Strong Structural Assumption\"] --\"Yes\"--> model_driven[\"Model-Driven\"] structural_assumptions --\"No\"--> data_driven[\"Data-Driven\"] model_comb[\"Model Combinations\"] discriminative_generative[\"Discriminative or Generative\"] theoretical_guarantees[\"Theoretical Guarantees\"] predictability_interpretability[\"Predictability and Interpretibility\"] end Daniel W. Hook, Simon J. Porter, and Christian Herzog. Dimensions: building context for search and evaluation. Frontiers in Research Metrics and Analytics , 3():23, 2018. https://www.frontiersin.org/articles/10.3389/frma.2018.00023/pdf . URL: https://app.dimensions.ai/details/publication/pub.1106289502 , doi:10.3389/frma.2018.00023 . \u21a9 Georg Dorffner. Neural networks for time series processing. Neural Network World , 6:447\u2013468, 1996. URL: http://machine-learning.martinsewell.com/ann/Dorf96.pdf . \u21a9 Hansika Hewamalage, Klaus Ackermann, and Christoph Bergmeir. Forecast evaluation for data scientists: common pitfalls and best practices. 21 March 2022. URL: http://arxiv.org/abs/2203.10716 , arXiv:2203.10716 . \u21a9 Tim Januschowski, Jan Gasthaus, Yuyang Wang, David Salinas, Valentin Flunkert, Michael Bohlke-Schneider, and Laurent Callot. Criteria for classifying forecasting methods. International journal of forecasting , 36(1):167\u2013177, 1 January 2020. URL: https://www.sciencedirect.com/science/article/pii/S0169207019301529 , doi:10.1016/j.ijforecast.2019.05.008 . \u21a9","title":"Methods of Forecasting Methods"},{"location":"time-series/timeseries-basics.ar/","text":"AR \u00b6 Autoregressive (AR) models are simple model to model time series. A general AR(p) model is described by the following process: \\[ s(t) = \\phi_0 + \\sum_{i=1}^p \\phi_i s(t-i) + \\epsilon. \\] AR(1) \u00b6 A first order AR model, aka AR(1), is as simple as \\[ s(t) = \\phi_0 + \\phi_1 s(t-1) + \\epsilon. \\] By staring at this equation, we can build up our intuitions. \\(\\phi_0\\) \\(\\phi_1\\) \\(\\epsilon\\) Behavior - \\(0\\) - constant + noise \\(0\\) \\(1\\) - constant + noise \\(0\\) \\(\\phi_1>1\\) or \\(0\\le\\phi_1 \\lt 1\\) - exponential + noise Exponential Behavior doesn't Always Approach Positive Inifinity For example, the combination \\(\\phi_0=0\\) and \\(\\phi_1>1\\) without noise leads to exponential growth if the initial series value is positive. However, it approaches negative infinity if the initial series is negative. Example: Constant Example: Decay Example: Exponential Example: Linear Code: Python import copy from dataclasses import dataclass from typing import Dict , Iterator import matplotlib.pyplot as plt import numpy as np import pandas as pd import seaborn as sns ; sns . set () class GaussianEpsilon : \"\"\"Gaussian noise :param mu: mean value of the noise :param std: standard deviation of the noise \"\"\" def __init__ ( self , mu , std , seed = None ): self . mu = mu self . std = std self . rng = np . random . default_rng ( seed = seed ) def __next__ ( self ): return self . rng . normal ( self . mu , self . std ) class ZeroEpsilon : \"\"\"Constant noise :param epsilon: the constant value to be returned \"\"\" def __init__ ( self , epsilon = 0 ): self . epsilon = epsilon def __next__ ( self ): return self . epsilon @dataclass ( frozen = True ) class ARModelParams : \"\"\"Parameters of our AR model, $$s(t+1) = \\phi_0 + \\phi_1 s(t) + \\epsilon.$$ :param delta_t: step size of time in each iteration :param phi0: pho_0 in the AR model :param phi1: pho_1 in the AR model :param epsilon: noise iterator, e.g., Gaussian noise :param initial_state: a dictionary of the initial state, e.g., `{\"s\": 1}` \"\"\" delta_t : float phi0 : float phi1 : float epsilon : Iterator initial_state : Dict [ str , float ] class AR1Stepper : \"\"\"Stepper that calculates the next step in time in an AR model :param model_params: parameters for the AR model \"\"\" def __init__ ( self , model_params ): self . model_params = model_params self . current_state = copy . deepcopy ( self . model_params . initial_state ) def __iter__ ( self ): return self def __next__ ( self ): phi0 = self . model_params . phi0 phi1 = self . model_params . phi1 epsilon = next ( self . model_params . epsilon ) next_s = ( self . model_params . phi0 + self . model_params . phi1 * self . current_state [ \"s\" ] + epsilon ) self . current_state = { \"s\" : next_s } return copy . deepcopy ( self . current_state ) def visualize_vr1 ( delta_t , phi0 , phi1 , length = 200 , savefig = False ): mu = 0 std = 0.1 geps = GaussianEpsilon ( mu = mu , std = std ) zeps = ZeroEpsilon () initial_state = { \"s\" : - 1 } ar1_params = ARModelParams ( delta_t = delta_t , phi0 = phi0 , phi1 = phi1 , epsilon = geps , initial_state = initial_state ) ar1_params_zero_noise = ARModelParams ( delta_t = delta_t , phi0 = phi0 , phi1 = phi1 , epsilon = zeps , initial_state = initial_state ) ar1_stepper = AR1Stepper ( model_params = ar1_params ) ar1_stepper_no_noise = AR1Stepper ( model_params = ar1_params_zero_noise ) history = [] history_zero_noise = [] for l in range ( length ): history . append ( next ( ar1_stepper )) history_zero_noise . append ( next ( ar1_stepper_no_noise )) df = pd . DataFrame ( history ) df_zero_noise = pd . DataFrame ( history_zero_noise ) fig , ax = plt . subplots ( figsize = ( 10 , 6.18 )) sns . lineplot ( x = np . linspace ( 0 , length - 1 , length ) * delta_t , y = df . s , ax = ax , marker = \".\" , label = \"AR1\" , color = \"r\" , alpha = 0.9 , ) sns . lineplot ( x = np . linspace ( 0 , length - 1 , length ) * delta_t , y = df_zero_noise . s , ax = ax , marker = \".\" , label = \"AR1 (wihout Noise)\" , color = \"g\" , alpha = 0.5 , ) ax . set_title ( f \"AR(1) Example ($\\phi_0= { phi0 } $, $\\phi_1= { phi1 } $; $\\epsilon$: $\\mu= { mu } $, $\\sigma= { std } $; $s(0)= { initial_state [ 's' ] } $)\" ) ax . set_xlabel ( \"Time\" ) ax . set_ylabel ( \"Values\" ) if savefig : plt . savefig ( f \"/work/timeseries-dgp-ar-var/exports/ar1-phi0- { phi0 } -phi1- { phi1 } -std- { std } -init- { initial_state [ 's' ] } .png\" ) Call the function visualize_vr1 to make some plots. visualize_vr1 ( delta_t = 0.01 , phi0 = 0 , phi1 = 1.1 , length = 200 , savefig = True ) Kumar A. Autoregressive (AR) models with Python examples. In: Data Analytics [Internet]. 25 Apr 2022 [cited 11 Aug 2022]. Available: https://vitalflux.com/autoregressive-ar-models-with-python-examples/ \u21a9","title":"AR"},{"location":"time-series/timeseries-basics.ar/#ar","text":"Autoregressive (AR) models are simple model to model time series. A general AR(p) model is described by the following process: \\[ s(t) = \\phi_0 + \\sum_{i=1}^p \\phi_i s(t-i) + \\epsilon. \\]","title":"AR"},{"location":"time-series/timeseries-basics.ar/#ar1","text":"A first order AR model, aka AR(1), is as simple as \\[ s(t) = \\phi_0 + \\phi_1 s(t-1) + \\epsilon. \\] By staring at this equation, we can build up our intuitions. \\(\\phi_0\\) \\(\\phi_1\\) \\(\\epsilon\\) Behavior - \\(0\\) - constant + noise \\(0\\) \\(1\\) - constant + noise \\(0\\) \\(\\phi_1>1\\) or \\(0\\le\\phi_1 \\lt 1\\) - exponential + noise Exponential Behavior doesn't Always Approach Positive Inifinity For example, the combination \\(\\phi_0=0\\) and \\(\\phi_1>1\\) without noise leads to exponential growth if the initial series value is positive. However, it approaches negative infinity if the initial series is negative. Example: Constant Example: Decay Example: Exponential Example: Linear Code: Python import copy from dataclasses import dataclass from typing import Dict , Iterator import matplotlib.pyplot as plt import numpy as np import pandas as pd import seaborn as sns ; sns . set () class GaussianEpsilon : \"\"\"Gaussian noise :param mu: mean value of the noise :param std: standard deviation of the noise \"\"\" def __init__ ( self , mu , std , seed = None ): self . mu = mu self . std = std self . rng = np . random . default_rng ( seed = seed ) def __next__ ( self ): return self . rng . normal ( self . mu , self . std ) class ZeroEpsilon : \"\"\"Constant noise :param epsilon: the constant value to be returned \"\"\" def __init__ ( self , epsilon = 0 ): self . epsilon = epsilon def __next__ ( self ): return self . epsilon @dataclass ( frozen = True ) class ARModelParams : \"\"\"Parameters of our AR model, $$s(t+1) = \\phi_0 + \\phi_1 s(t) + \\epsilon.$$ :param delta_t: step size of time in each iteration :param phi0: pho_0 in the AR model :param phi1: pho_1 in the AR model :param epsilon: noise iterator, e.g., Gaussian noise :param initial_state: a dictionary of the initial state, e.g., `{\"s\": 1}` \"\"\" delta_t : float phi0 : float phi1 : float epsilon : Iterator initial_state : Dict [ str , float ] class AR1Stepper : \"\"\"Stepper that calculates the next step in time in an AR model :param model_params: parameters for the AR model \"\"\" def __init__ ( self , model_params ): self . model_params = model_params self . current_state = copy . deepcopy ( self . model_params . initial_state ) def __iter__ ( self ): return self def __next__ ( self ): phi0 = self . model_params . phi0 phi1 = self . model_params . phi1 epsilon = next ( self . model_params . epsilon ) next_s = ( self . model_params . phi0 + self . model_params . phi1 * self . current_state [ \"s\" ] + epsilon ) self . current_state = { \"s\" : next_s } return copy . deepcopy ( self . current_state ) def visualize_vr1 ( delta_t , phi0 , phi1 , length = 200 , savefig = False ): mu = 0 std = 0.1 geps = GaussianEpsilon ( mu = mu , std = std ) zeps = ZeroEpsilon () initial_state = { \"s\" : - 1 } ar1_params = ARModelParams ( delta_t = delta_t , phi0 = phi0 , phi1 = phi1 , epsilon = geps , initial_state = initial_state ) ar1_params_zero_noise = ARModelParams ( delta_t = delta_t , phi0 = phi0 , phi1 = phi1 , epsilon = zeps , initial_state = initial_state ) ar1_stepper = AR1Stepper ( model_params = ar1_params ) ar1_stepper_no_noise = AR1Stepper ( model_params = ar1_params_zero_noise ) history = [] history_zero_noise = [] for l in range ( length ): history . append ( next ( ar1_stepper )) history_zero_noise . append ( next ( ar1_stepper_no_noise )) df = pd . DataFrame ( history ) df_zero_noise = pd . DataFrame ( history_zero_noise ) fig , ax = plt . subplots ( figsize = ( 10 , 6.18 )) sns . lineplot ( x = np . linspace ( 0 , length - 1 , length ) * delta_t , y = df . s , ax = ax , marker = \".\" , label = \"AR1\" , color = \"r\" , alpha = 0.9 , ) sns . lineplot ( x = np . linspace ( 0 , length - 1 , length ) * delta_t , y = df_zero_noise . s , ax = ax , marker = \".\" , label = \"AR1 (wihout Noise)\" , color = \"g\" , alpha = 0.5 , ) ax . set_title ( f \"AR(1) Example ($\\phi_0= { phi0 } $, $\\phi_1= { phi1 } $; $\\epsilon$: $\\mu= { mu } $, $\\sigma= { std } $; $s(0)= { initial_state [ 's' ] } $)\" ) ax . set_xlabel ( \"Time\" ) ax . set_ylabel ( \"Values\" ) if savefig : plt . savefig ( f \"/work/timeseries-dgp-ar-var/exports/ar1-phi0- { phi0 } -phi1- { phi1 } -std- { std } -init- { initial_state [ 's' ] } .png\" ) Call the function visualize_vr1 to make some plots. visualize_vr1 ( delta_t = 0.01 , phi0 = 0 , phi1 = 1.1 , length = 200 , savefig = True ) Kumar A. Autoregressive (AR) models with Python examples. In: Data Analytics [Internet]. 25 Apr 2022 [cited 11 Aug 2022]. Available: https://vitalflux.com/autoregressive-ar-models-with-python-examples/ \u21a9","title":"AR(1)"},{"location":"time-series/timeseries-basics.statistical-models/","text":"Multivariate Time Series Forecasting \u00b6 Though statistical models are not our focus, it is always beneficial to understand how those famous statistical models work. To best understand how the models work, we will build some data generating process using these models and explore their behavior. In the following paragraphs, we list some of the most applied statistical models. For a comprehensive review of statistical models, please refer to Petropoulos et al., 2022 and Hyndman et al., 2021 3 4 . ARIMA \u00b6 ARIMA is one of the most famous forecasting models 1 . We sketch the relations between the different components of the ARIMA model. flowchart TD AR --\"interdependencies\"--> VAR MA --\"add autoregressive\"--> ARMA AR --\"add moving average\"--> ARMA ARMA --\"difference between values\"--> ARIMA ARMA --\"interdependencies\"--> VARMA VAR --\"moving average\"--> VARMA ARIMA --\"interdependencies\"--> VARIMA VAR --\"difference and moving average\"--> VARIMA VARMA --\"difference\"--> VARIMA Exponential Smoothing \u00b6 A Naive Forecast In time series forecasting, one of the naive forecasts we can use it the previous observation, i.e., \\[ \\hat s(t+1) = s(t), \\] where we use \\(\\hat s\\) to denote the forecasts and \\(s\\) for the observations. A naive version of the exponential smoothing model is the Simple Exponential Smoothing (SES) 3 4 . The SES is an average of the most recent observation and the previous forecasts. \\[ \\hat s(t+1) = \\alpha s(t) + (1-\\alpha) \\hat s(t), \\] where \\(\\hat s\\) is the forecast and \\(s\\) is the observation. Expanding this form, we observe the exponential decaying effect of the history in the long past 4 . State Space Models \u00b6 State space models (SSM) are amazing models due to their simplicity. SSM applies Markov chains but is not limited to the Markovian assumptions 5 . Cerqueira V, Torgo L, Soares C. Machine Learning vs Statistical Methods for Time Series Forecasting: Size Matters. arXiv [stat.ML]. 2019. Available: http://arxiv.org/abs/1909.13316 \u21a9 Wu Z, Pan S, Long G, Jiang J, Chang X, Zhang C. Connecting the Dots: Multivariate Time Series Forecasting with Graph Neural Networks. arXiv [cs.LG]. 2020. Available: http://arxiv.org/abs/2005.11650 \u21a9 Petropoulos F, Apiletti D, Assimakopoulos V, Babai MZ, Barrow DK, Ben Taieb S, et al. Forecasting: theory and practice. Int J Forecast. 2022;38: 705\u2013871. doi:10.1016/j.ijforecast.2021.11.001 \u21a9 \u21a9 Hyndman, R.J., & Athanasopoulos, G. (2021) Forecasting: principles and practice, 3rd edition, OTexts: Melbourne, Australia. OTexts.com/fpp3. Accessed on 2022-11-27. \u21a9 \u21a9 \u21a9 Bishop CM. Pattern Recognition and Machine Learning. Springer; 2006. Available: https://play.google.com/store/books/details?id=qWPwnQEACAAJ \u21a9","title":"Statistical Models"},{"location":"time-series/timeseries-basics.statistical-models/#multivariate-time-series-forecasting","text":"Though statistical models are not our focus, it is always beneficial to understand how those famous statistical models work. To best understand how the models work, we will build some data generating process using these models and explore their behavior. In the following paragraphs, we list some of the most applied statistical models. For a comprehensive review of statistical models, please refer to Petropoulos et al., 2022 and Hyndman et al., 2021 3 4 .","title":"Multivariate Time Series Forecasting"},{"location":"time-series/timeseries-basics.statistical-models/#arima","text":"ARIMA is one of the most famous forecasting models 1 . We sketch the relations between the different components of the ARIMA model. flowchart TD AR --\"interdependencies\"--> VAR MA --\"add autoregressive\"--> ARMA AR --\"add moving average\"--> ARMA ARMA --\"difference between values\"--> ARIMA ARMA --\"interdependencies\"--> VARMA VAR --\"moving average\"--> VARMA ARIMA --\"interdependencies\"--> VARIMA VAR --\"difference and moving average\"--> VARIMA VARMA --\"difference\"--> VARIMA","title":"ARIMA"},{"location":"time-series/timeseries-basics.statistical-models/#exponential-smoothing","text":"A Naive Forecast In time series forecasting, one of the naive forecasts we can use it the previous observation, i.e., \\[ \\hat s(t+1) = s(t), \\] where we use \\(\\hat s\\) to denote the forecasts and \\(s\\) for the observations. A naive version of the exponential smoothing model is the Simple Exponential Smoothing (SES) 3 4 . The SES is an average of the most recent observation and the previous forecasts. \\[ \\hat s(t+1) = \\alpha s(t) + (1-\\alpha) \\hat s(t), \\] where \\(\\hat s\\) is the forecast and \\(s\\) is the observation. Expanding this form, we observe the exponential decaying effect of the history in the long past 4 .","title":"Exponential Smoothing"},{"location":"time-series/timeseries-basics.statistical-models/#state-space-models","text":"State space models (SSM) are amazing models due to their simplicity. SSM applies Markov chains but is not limited to the Markovian assumptions 5 . Cerqueira V, Torgo L, Soares C. Machine Learning vs Statistical Methods for Time Series Forecasting: Size Matters. arXiv [stat.ML]. 2019. Available: http://arxiv.org/abs/1909.13316 \u21a9 Wu Z, Pan S, Long G, Jiang J, Chang X, Zhang C. Connecting the Dots: Multivariate Time Series Forecasting with Graph Neural Networks. arXiv [cs.LG]. 2020. Available: http://arxiv.org/abs/2005.11650 \u21a9 Petropoulos F, Apiletti D, Assimakopoulos V, Babai MZ, Barrow DK, Ben Taieb S, et al. Forecasting: theory and practice. Int J Forecast. 2022;38: 705\u2013871. doi:10.1016/j.ijforecast.2021.11.001 \u21a9 \u21a9 Hyndman, R.J., & Athanasopoulos, G. (2021) Forecasting: principles and practice, 3rd edition, OTexts: Melbourne, Australia. OTexts.com/fpp3. Accessed on 2022-11-27. \u21a9 \u21a9 \u21a9 Bishop CM. Pattern Recognition and Machine Learning. Springer; 2006. Available: https://play.google.com/store/books/details?id=qWPwnQEACAAJ \u21a9","title":"State Space Models"},{"location":"time-series/timeseries-basics.var/","text":"VAR \u00b6 VAR(1) \u00b6 VAR(1) is similar to AR(1) but models time series with interactions between the series. For example, a two dimensional VAR(1) model is \\[ \\begin{pmatrix}s^{(1)}(t+1) \\\\ s^{(2)}(t+1) \\end{pmatrix} = \\begin{pmatrix} \\phi^{(1)}_0 \\\\ \\phi^{(2)}_0 \\end{pmatrix} + \\begin{pmatrix}\\phi_{1, 11} & \\phi_{1, 12}\\\\ \\phi_{1, 21} & \\phi_{1, 22} \\end{pmatrix} \\begin{pmatrix}s^{(1)}(t) \\\\ s^{(2)}(t) \\end{pmatrix} + \\begin{pmatrix}\\epsilon^{(1)} \\\\ \\epsilon^{(2)} \\end{pmatrix}. \\] A more compact form is \\[ \\mathbf s (t+1) = \\boldsymbol \\phi_0 + \\boldsymbol \\phi_1 \\mathbf s(t) + \\boldsymbol \\epsilon. \\] Stability of VAR For VAR(1), our series blows up when the max eigenvalue of the matrix \\(\\boldsymbol \\phi_1\\) is large than 1 1 . Otherwise ,we get stable series. In the following examples, we denote the largest eigenvalue of \\(\\boldsymbol \\phi_1\\) as \\(\\lambda_0\\) . VAR(1) Stable VAR(1) Unstable VAR(1) without Noise VAR(1) with Zero Mean Noise VAR(1) with Nonzero Mean Noise Python Code The figure is created using the code from the \"Python Code\" tab, and the following parameters. var_params_stable = VAR1ModelParams ( delta_t = 0.01 , phi0 = np . array ([ 0.1 , 0.1 ]), phi1 = np . array ([ [ 0.5 , - 0.25 ], [ - 0.35 , 0.45 + 0.2 ] ]), epsilon = ConstantEpsilon ( epsilon = np . array ([ 0 , 0 ])), initial_state = np . array ([ 1 , 0 ]) ) var1_visualize ( var_params = var_params_stable ) The figure is created using the code from the \"Python Code\" tab, and the following parameters. var_params_unstable = VAR1ModelParams ( delta_t = 0.01 , phi0 = np . array ([ 0.1 , 0.1 ]), phi1 = np . array ([ [ 0.5 , - 0.25 ], [ - 0.35 , 0.45 + 0.5 ] ]), epsilon = ConstantEpsilon ( epsilon = np . array ([ 0 , 0 ])), initial_state = np . array ([ 1 , 0 ]) ) var1_visualize ( var_params = var_params_unstable ) The figure is created using the code from the \"Python Code\" tab, and the following parameters. var_params_no_noise = VAR1ModelParams ( delta_t = 0.01 , phi0 = np . array ([ - 1 , 1 ]), phi1 = np . array ([ [ 0.7 , 0.2 ], [ 0.2 , 0.7 ] ]), epsilon = ConstantEpsilon ( epsilon = np . array ([ 0 , 0 ])), initial_state = np . array ([ 1 , 0 ]) ) var1_visualize ( var_params = var_params_no_noise ) The figure is created using the code from the \"Python Code\" tab, and the following parameters. var_params_zero_mean_noise = VAR1ModelParams ( delta_t = 0.01 , phi0 = np . array ([ - 1 , 1 ]), phi1 = np . array ([ [ 0.7 , 0.2 ], [ 0.2 , 0.7 ] ]), epsilon = MultiGaussianNoise ( mu = np . array ([ 0 , 0 ]), cov = np . array ([[ 1 , 0.5 ],[ 0.5 , 1 ]])), initial_state = np . array ([ 1 , 0 ]) ) var1_visualize ( var_params = var_params_zero_mean_noise ) The figure is created using the code from the \"Python Code\" tab, and the following parameters. var_params_nonzero_mean_noise = VAR1ModelParams ( delta_t = 0.01 , phi0 = np . array ([ - 1 , 1 ]), phi1 = np . array ([ [ 0.7 , 0.2 ], [ 0.2 , 0.7 ] ]), epsilon = MultiGaussianNoise ( mu = np . array ([ 1 , 2 ]), cov = np . array ([[ 1 , 0.5 ],[ 0.5 , 1 ]])), initial_state = np . array ([ 1 , 0 ]) ) var1_visualize ( var_params = var_params_nonzero_mean_noise ) import copy from dataclasses import dataclass from typing import Iterator import numpy as np class MultiGaussianNoise : \"\"\"A multivariate Gaussian noise :param mu: means of the variables :param cov: covariance of the variables :param seed: seed of the random number generator for reproducibility \"\"\" def __init__ ( self , mu : np . ndarray , cov : np . ndarray , seed : Optional [ float ] = None ): self . mu = mu self . cov = cov self . rng = np . random . default_rng ( seed = seed ) def __next__ ( self ) -> np . ndarray : return self . rng . multivariate_normal ( self . mu , self . cov ) class ConstantEpsilon : \"\"\"Constant noise :param epsilon: the constant value to be returned \"\"\" def __init__ ( self , epsilon = 0 ): self . epsilon = epsilon def __next__ ( self ): return self . epsilon @dataclass ( frozen = True ) class VAR1ModelParams : \"\"\"Parameters of our VAR model, :param delta_t: step size of time in each iteration :param phi0: pho_0 in the AR model :param phi1: pho_1 in the AR model :param epsilon: noise iterator, e.g., Gaussian noise :param initial_state: a dictionary of the initial state, e.g., `{\"s\": 1}` \"\"\" delta_t : float phi0 : np . ndarray phi1 : np . ndarray epsilon : Iterator initial_state : np . ndarray class VAR1Stepper : \"\"\"Calculate the next values using VAR(1) model. :param model_params: the parameters of the VAR(1) model, e.g., [`VAR1ModelParams`][eerily.data.generators.var.VAR1ModelParams] \"\"\" def __init__ ( self , model_params ): self . model_params = model_params self . current_state = copy . deepcopy ( self . model_params . initial_state ) def __iter__ ( self ): return self def __next__ ( self ): epsilon = next ( self . model_params . epsilon ) phi0 = self . model_params . phi0 phi1 = self . model_params . phi1 self . current_state = phi0 + np . matmul ( phi1 , self . current_state ) + epsilon return copy . deepcopy ( self . current_state ) class Factory : \"\"\"A generator that creates the data points based on the stepper.\"\"\" def __init__ ( self ): pass def __call__ ( self , stepper , length ): i = 0 while i < length : yield next ( stepper ) i += 1 We create a function to visualize the series. def var1_visualize ( var_params ): phi1_eig_max = max ( np . linalg . eig ( var_params . phi1 )[ 0 ]) var1_stepper = VAR1Stepper ( model_params = var_params ) length = 200 fact = Factory () history = list ( fact ( var1_stepper , length = length )) df = pd . DataFrame ( history , columns = [ \"s1\" , \"s2\" ]) print ( df . head ()) fig , ax = plt . subplots ( figsize = ( 10 , 6.18 )) sns . lineplot ( x = np . linspace ( 0 , length - 1 , length ) * var_params . delta_t , y = df . s1 , ax = ax , marker = \"o\" , ) sns . lineplot ( x = np . linspace ( 0 , length - 1 , length ) * var_params . delta_t , y = df . s2 , ax = ax , marker = \"o\" , ) ax . set_title ( f \"VAR(1) Example ($\\lambda_0= { phi1_eig_max : 0.2f } $)\" ) ax . set_xlabel ( \"Time\" ) ax . set_ylabel ( \"Values\" ) Zivot E, Wang J. Modeling Financial Time Series with S-PLUS\u00ae. Springer New York; 2006. doi:10.1007/978-0-387-32348-0 \u21a9","title":"VAR"},{"location":"time-series/timeseries-basics.var/#var","text":"","title":"VAR"},{"location":"time-series/timeseries-basics.var/#var1","text":"VAR(1) is similar to AR(1) but models time series with interactions between the series. For example, a two dimensional VAR(1) model is \\[ \\begin{pmatrix}s^{(1)}(t+1) \\\\ s^{(2)}(t+1) \\end{pmatrix} = \\begin{pmatrix} \\phi^{(1)}_0 \\\\ \\phi^{(2)}_0 \\end{pmatrix} + \\begin{pmatrix}\\phi_{1, 11} & \\phi_{1, 12}\\\\ \\phi_{1, 21} & \\phi_{1, 22} \\end{pmatrix} \\begin{pmatrix}s^{(1)}(t) \\\\ s^{(2)}(t) \\end{pmatrix} + \\begin{pmatrix}\\epsilon^{(1)} \\\\ \\epsilon^{(2)} \\end{pmatrix}. \\] A more compact form is \\[ \\mathbf s (t+1) = \\boldsymbol \\phi_0 + \\boldsymbol \\phi_1 \\mathbf s(t) + \\boldsymbol \\epsilon. \\] Stability of VAR For VAR(1), our series blows up when the max eigenvalue of the matrix \\(\\boldsymbol \\phi_1\\) is large than 1 1 . Otherwise ,we get stable series. In the following examples, we denote the largest eigenvalue of \\(\\boldsymbol \\phi_1\\) as \\(\\lambda_0\\) . VAR(1) Stable VAR(1) Unstable VAR(1) without Noise VAR(1) with Zero Mean Noise VAR(1) with Nonzero Mean Noise Python Code The figure is created using the code from the \"Python Code\" tab, and the following parameters. var_params_stable = VAR1ModelParams ( delta_t = 0.01 , phi0 = np . array ([ 0.1 , 0.1 ]), phi1 = np . array ([ [ 0.5 , - 0.25 ], [ - 0.35 , 0.45 + 0.2 ] ]), epsilon = ConstantEpsilon ( epsilon = np . array ([ 0 , 0 ])), initial_state = np . array ([ 1 , 0 ]) ) var1_visualize ( var_params = var_params_stable ) The figure is created using the code from the \"Python Code\" tab, and the following parameters. var_params_unstable = VAR1ModelParams ( delta_t = 0.01 , phi0 = np . array ([ 0.1 , 0.1 ]), phi1 = np . array ([ [ 0.5 , - 0.25 ], [ - 0.35 , 0.45 + 0.5 ] ]), epsilon = ConstantEpsilon ( epsilon = np . array ([ 0 , 0 ])), initial_state = np . array ([ 1 , 0 ]) ) var1_visualize ( var_params = var_params_unstable ) The figure is created using the code from the \"Python Code\" tab, and the following parameters. var_params_no_noise = VAR1ModelParams ( delta_t = 0.01 , phi0 = np . array ([ - 1 , 1 ]), phi1 = np . array ([ [ 0.7 , 0.2 ], [ 0.2 , 0.7 ] ]), epsilon = ConstantEpsilon ( epsilon = np . array ([ 0 , 0 ])), initial_state = np . array ([ 1 , 0 ]) ) var1_visualize ( var_params = var_params_no_noise ) The figure is created using the code from the \"Python Code\" tab, and the following parameters. var_params_zero_mean_noise = VAR1ModelParams ( delta_t = 0.01 , phi0 = np . array ([ - 1 , 1 ]), phi1 = np . array ([ [ 0.7 , 0.2 ], [ 0.2 , 0.7 ] ]), epsilon = MultiGaussianNoise ( mu = np . array ([ 0 , 0 ]), cov = np . array ([[ 1 , 0.5 ],[ 0.5 , 1 ]])), initial_state = np . array ([ 1 , 0 ]) ) var1_visualize ( var_params = var_params_zero_mean_noise ) The figure is created using the code from the \"Python Code\" tab, and the following parameters. var_params_nonzero_mean_noise = VAR1ModelParams ( delta_t = 0.01 , phi0 = np . array ([ - 1 , 1 ]), phi1 = np . array ([ [ 0.7 , 0.2 ], [ 0.2 , 0.7 ] ]), epsilon = MultiGaussianNoise ( mu = np . array ([ 1 , 2 ]), cov = np . array ([[ 1 , 0.5 ],[ 0.5 , 1 ]])), initial_state = np . array ([ 1 , 0 ]) ) var1_visualize ( var_params = var_params_nonzero_mean_noise ) import copy from dataclasses import dataclass from typing import Iterator import numpy as np class MultiGaussianNoise : \"\"\"A multivariate Gaussian noise :param mu: means of the variables :param cov: covariance of the variables :param seed: seed of the random number generator for reproducibility \"\"\" def __init__ ( self , mu : np . ndarray , cov : np . ndarray , seed : Optional [ float ] = None ): self . mu = mu self . cov = cov self . rng = np . random . default_rng ( seed = seed ) def __next__ ( self ) -> np . ndarray : return self . rng . multivariate_normal ( self . mu , self . cov ) class ConstantEpsilon : \"\"\"Constant noise :param epsilon: the constant value to be returned \"\"\" def __init__ ( self , epsilon = 0 ): self . epsilon = epsilon def __next__ ( self ): return self . epsilon @dataclass ( frozen = True ) class VAR1ModelParams : \"\"\"Parameters of our VAR model, :param delta_t: step size of time in each iteration :param phi0: pho_0 in the AR model :param phi1: pho_1 in the AR model :param epsilon: noise iterator, e.g., Gaussian noise :param initial_state: a dictionary of the initial state, e.g., `{\"s\": 1}` \"\"\" delta_t : float phi0 : np . ndarray phi1 : np . ndarray epsilon : Iterator initial_state : np . ndarray class VAR1Stepper : \"\"\"Calculate the next values using VAR(1) model. :param model_params: the parameters of the VAR(1) model, e.g., [`VAR1ModelParams`][eerily.data.generators.var.VAR1ModelParams] \"\"\" def __init__ ( self , model_params ): self . model_params = model_params self . current_state = copy . deepcopy ( self . model_params . initial_state ) def __iter__ ( self ): return self def __next__ ( self ): epsilon = next ( self . model_params . epsilon ) phi0 = self . model_params . phi0 phi1 = self . model_params . phi1 self . current_state = phi0 + np . matmul ( phi1 , self . current_state ) + epsilon return copy . deepcopy ( self . current_state ) class Factory : \"\"\"A generator that creates the data points based on the stepper.\"\"\" def __init__ ( self ): pass def __call__ ( self , stepper , length ): i = 0 while i < length : yield next ( stepper ) i += 1 We create a function to visualize the series. def var1_visualize ( var_params ): phi1_eig_max = max ( np . linalg . eig ( var_params . phi1 )[ 0 ]) var1_stepper = VAR1Stepper ( model_params = var_params ) length = 200 fact = Factory () history = list ( fact ( var1_stepper , length = length )) df = pd . DataFrame ( history , columns = [ \"s1\" , \"s2\" ]) print ( df . head ()) fig , ax = plt . subplots ( figsize = ( 10 , 6.18 )) sns . lineplot ( x = np . linspace ( 0 , length - 1 , length ) * var_params . delta_t , y = df . s1 , ax = ax , marker = \"o\" , ) sns . lineplot ( x = np . linspace ( 0 , length - 1 , length ) * var_params . delta_t , y = df . s2 , ax = ax , marker = \"o\" , ) ax . set_title ( f \"VAR(1) Example ($\\lambda_0= { phi1_eig_max : 0.2f } $)\" ) ax . set_xlabel ( \"Time\" ) ax . set_ylabel ( \"Values\" ) Zivot E, Wang J. Modeling Financial Time Series with S-PLUS\u00ae. Springer New York; 2006. doi:10.1007/978-0-387-32348-0 \u21a9","title":"VAR(1)"},{"location":"time-series/timeseries-data.analysis/","text":"Time Series Analysis \u00b6 Time series analysis is not our focus here. However, it is beneficial to grasp some basic ideas of time series. Stationarity \u00b6 Time series data is stationary if the distribution of the observables do not change 1 2 6 . A strict stationary series guarantees the same distribution for a segment \\(\\{x_{i+1}, \\cdots, x_{x+k}\\}\\) and a time shifted segment \\(\\{x_{i+1+\\Delta}, \\cdots, x_{x+k+\\Delta}\\}\\) for integer \\(\\Delta\\) 1 . A less strict form (WSS) concerns only the mean and autocorrelation 1 3 , i.e., \\[ \\begin{align} \\mathbb E[x_{i+1}] &= \\mathbb E[x_{i+\\Delta}] \\\\ \\mathbb{Cov}[x_{i+1}, x_{i+k}] &= \\mathbb{Cov}[x_{i+1+\\Delta}, x_{x+k+\\Delta}] \\end{align} \\] In deep learning, a lot of models requires the training data to be I.I.D. 4 7 . The I.I.D. requirements in time series is stationarity. Stationary time series is clean and pure. However, real world data is not necessarily stationary, e.g., macroeconomic series data are nonstationary 6 . Serial Dependence \u00b6 Autocorrelation measures the serial dependency of a time series 5 . By definition the autocorrelation is the autocovariance normalized by the variance, \\[ \\rho = \\frac{\\mathbb{Cov}[x_t, x_{t+\\delta}]}{\\mathbb{Var}[x_t]}. \\] One naive expectation is that the autocorrelation diminishes if \\(\\delta \\to \\infty\\) 3 . Contributors to Wikimedia projects. Stationary process. In: Wikipedia [Internet]. 18 Sep 2022 [cited 13 Nov 2022]. Available: https://en.wikipedia.org/wiki/Stationary_process \u21a9 \u21a9 \u21a9 6.4.4.2. Stationarity. In: Engineering Statistics Handbook [Internet]. NIST; [cited 13 Nov 2022]. Available: https://www.itl.nist.gov/div898/handbook/pmc/section4/pmc442.htm#:~:text=Stationarity%20can%20be%20defined%20in,no%20periodic%20fluctuations%20(seasonality ). \u21a9 Shalizi C. 36-402, Undergraduate Advanced Data Analysis (2012). In: Undergraduate Advanced Data Analysis [Internet]. 2012 [cited 13 Nov 2022]. Available: https://www.stat.cmu.edu/~cshalizi/uADA/12/ \u21a9 \u21a9 Sch\u00f6lkopf B, Locatello F, Bauer S, Ke NR, Kalchbrenner N, Goyal A, et al. Toward Causal Representation Learning. Proc IEEE. 2021;109: 612\u2013634. doi:10.1109/JPROC.2021.3058954 \u21a9 Contributors to Wikimedia projects. Autocorrelation. In: Wikipedia [Internet]. 10 Nov 2022 [cited 13 Nov 2022]. Available: https://en.wikipedia.org/wiki/Autocorrelation \u21a9 Das P. Econometrics in Theory and Practice. Springer Nature Singapore; doi:10.1007/978-981-32-9019-8 \u21a9 \u21a9 Dawid P, Tewari A. On learnability under general stochastic processes. Harvard Data Science Review. 2022;4. doi:10.1162/99608f92.dec7d780 \u21a9","title":"Time Series Data Analysis"},{"location":"time-series/timeseries-data.analysis/#time-series-analysis","text":"Time series analysis is not our focus here. However, it is beneficial to grasp some basic ideas of time series.","title":"Time Series Analysis"},{"location":"time-series/timeseries-data.analysis/#stationarity","text":"Time series data is stationary if the distribution of the observables do not change 1 2 6 . A strict stationary series guarantees the same distribution for a segment \\(\\{x_{i+1}, \\cdots, x_{x+k}\\}\\) and a time shifted segment \\(\\{x_{i+1+\\Delta}, \\cdots, x_{x+k+\\Delta}\\}\\) for integer \\(\\Delta\\) 1 . A less strict form (WSS) concerns only the mean and autocorrelation 1 3 , i.e., \\[ \\begin{align} \\mathbb E[x_{i+1}] &= \\mathbb E[x_{i+\\Delta}] \\\\ \\mathbb{Cov}[x_{i+1}, x_{i+k}] &= \\mathbb{Cov}[x_{i+1+\\Delta}, x_{x+k+\\Delta}] \\end{align} \\] In deep learning, a lot of models requires the training data to be I.I.D. 4 7 . The I.I.D. requirements in time series is stationarity. Stationary time series is clean and pure. However, real world data is not necessarily stationary, e.g., macroeconomic series data are nonstationary 6 .","title":"Stationarity"},{"location":"time-series/timeseries-data.analysis/#serial-dependence","text":"Autocorrelation measures the serial dependency of a time series 5 . By definition the autocorrelation is the autocovariance normalized by the variance, \\[ \\rho = \\frac{\\mathbb{Cov}[x_t, x_{t+\\delta}]}{\\mathbb{Var}[x_t]}. \\] One naive expectation is that the autocorrelation diminishes if \\(\\delta \\to \\infty\\) 3 . Contributors to Wikimedia projects. Stationary process. In: Wikipedia [Internet]. 18 Sep 2022 [cited 13 Nov 2022]. Available: https://en.wikipedia.org/wiki/Stationary_process \u21a9 \u21a9 \u21a9 6.4.4.2. Stationarity. In: Engineering Statistics Handbook [Internet]. NIST; [cited 13 Nov 2022]. Available: https://www.itl.nist.gov/div898/handbook/pmc/section4/pmc442.htm#:~:text=Stationarity%20can%20be%20defined%20in,no%20periodic%20fluctuations%20(seasonality ). \u21a9 Shalizi C. 36-402, Undergraduate Advanced Data Analysis (2012). In: Undergraduate Advanced Data Analysis [Internet]. 2012 [cited 13 Nov 2022]. Available: https://www.stat.cmu.edu/~cshalizi/uADA/12/ \u21a9 \u21a9 Sch\u00f6lkopf B, Locatello F, Bauer S, Ke NR, Kalchbrenner N, Goyal A, et al. Toward Causal Representation Learning. Proc IEEE. 2021;109: 612\u2013634. doi:10.1109/JPROC.2021.3058954 \u21a9 Contributors to Wikimedia projects. Autocorrelation. In: Wikipedia [Internet]. 10 Nov 2022 [cited 13 Nov 2022]. Available: https://en.wikipedia.org/wiki/Autocorrelation \u21a9 Das P. Econometrics in Theory and Practice. Springer Nature Singapore; doi:10.1007/978-981-32-9019-8 \u21a9 \u21a9 Dawid P, Tewari A. On learnability under general stochastic processes. Harvard Data Science Review. 2022;4. doi:10.1162/99608f92.dec7d780 \u21a9","title":"Serial Dependence"},{"location":"time-series/timeseries-data.data-augmentation/","text":"Data Augmentation for Time Series \u00b6 In deep learning, our dataset should help the optimization mechanism locate a good spot in the parameter space. However, real-world data is not necessarily diverse enough that covers the required situations with enough records. For example, some datasets maybe extremely imbalanced class labels which leads to poor performance in classification tasks. 1 Another problem with a limited dataset is that the trained model may not generalize well. 2 3 We will cover two topics in this section: Augmenting the dataset and application of the augmented data to model training. Augmenting the Dataset \u00b6 There are many different ways of augmenting time series data. 2 4 We categorize the methods into the following groups: Random transformations, e.g., jittering; Pattern mixing, e.g., DBA; 5 Generative models, e.g., phenomenological generative models such as AR, 6 first principle models such as economical models, 7 deep generative models such as TimeGAN or TS GAN. 8 9 We also treat the first two methods, random transformations and pattern mixing as basic methods. Basic Methods \u00b6 In the following table, we group some of the data augmentation methods by two dimensions, the category of the method, and domain of where the method is applied. Projected Domain Time Scale Magnitude Random Transformation Frequency Masking, Frequency Warping, Fourier Transform, STFT Permutation, Slicing, Time Warping, Time Masking, Cropping Jittering, Flipping, Scaling, Magnitude Warping Pattern Mixing EMDA 10 , SFM 11 Guided Warping 12 DFM 7 , Interpolation, DBA 5 For completeness, we will explain some of the methods in more details in the following. Perturbation in Fourier Domain \u00b6 In the Fourier domain, for each the amplitude \\(A_f\\) and phase \\(\\phi_f\\) at a specific frequency, we can perform 13 magnitude replacement using a Gaussian distribution, and phase shift by adding a Gaussian noise. We perform such perturbations at some chosen frequency. Slicing, Permutation, and Bootstrapping \u00b6 We can slice a series into small segments. With the slices, we can perform different operations to create new series. Window Slicing ( WS ): In a classification tasks, we can take the slices from the original series and assign the same class label to the slice. 14 The slices can also be interpolated to match the length of the original series. 2 Permutation: We take the slices and permute them to form a new series. 15 Moving Block Bootstrapping ( MBB ): First, we remove the trend and seasonability. Then we draw blocks of fixed length from the residual of the series, until the desired length of series is met. Finally, we combine the newly formed residual with trend and seasonality to form a new series. 16 Warping \u00b6 Both the time scale and magnitude can be warped. For example, Time Warping: We distort time intervals by taking a range of data points and up sample or down sample it. 4 Magnitude Warping: the magnitude of the time series is rescaled. Series Mixing \u00b6 Another class of data augmentation methods is mixing the series. For example, we take two random drawn series and average them using DTW Barycenter Averaging ( DBA ). 5 (DTW, dynamic time warping, is an algorithm to calculate the distance between sequential datasets by matching the data points on each of the series. 5 17 ) To augment a dataset, we can choose from a list of strategies: 18 19 Average All series using different sets of weights to create new synthetic series. Average Selected series based on some strategies. For example, Forestier et al proposed to choose an initial series and combine it with its nearest neighbors. 19 Average Selected with Distance is Average Selected but neighbors that are far from the initial series is down weighted. 19 Some other similar methods are Equalized Mixture Data Augmentation ( EMDA ) calculates the weighted average of spectrograms of the same class label. 10 Stochastic Feature Mapping ( SFM ) is a data augmentation method in audio data. 11 Data Generating Process \u00b6 Time series data can also be augmented using some assumed data generating process ( DGP ). Some methods, such as GRATIS 6 , utilizes simple generic methods such as AR/MAR. Some other methods, such as Gaussian Trees 20 , utilizes more complicated hidden structure using graphs, which can approximate more complicated data generating process. These methods do not necessarily reflect the actual data generating process but the data is generated using some parsimonious phenomenological models. Some other methods are more tuned towards the detailed mechanisms. There are also methods using generative deep neural networks such as GAN . Dynamic Factor Model ( DFM ) \u00b6 For example, we have a series \\(X(t)\\) which depends on a latent variable \\(f(t)\\) , 7 \\[ X(t) = \\mathbf A f(t) + \\eta(t), \\] where \\(f(t)\\) is determined by a differential equation \\[ \\frac{f(t)}{dt} = \\mathbf B f(t) + \\xi(t). \\] In the above equations, \\(\\eta(t)\\) and \\(\\xi(t)\\) are the irreducible noise. The above two equatioins can be combined into one first-order differential equation. Once the model is fit, it can be used to generate new data points. However, we will have to understand whether the data is generated in such processes. Applying the Synthetic Data to Model Training \u00b6 Once we prepared the synthetic dataset, there are two strategies to include them in our model training. 18 Strategy Description Pooled Strategy Synthetic data + original data -> model Transfer Strategy Synthetic data -> pre-trained model; pre-trained model + original data -> model The pooled strategy takes the synthetic data and original data, then feed them together into the training pipeline. The transfer strategy uses the synthetic data to pre-train the model, then using transfer learning methods (e.g., freeze weights of some layers) to train the model on the original data. Ramin Hasibi, Matin Shokri, and Mehdi Dehghan. Augmentation scheme for dealing with imbalanced network traffic classification using deep learning. 1 January 2019. URL: http://arxiv.org/abs/1901.00204 , arXiv:1901.00204 . \u21a9 Brian Kenji Iwana and Seiichi Uchida. An empirical survey of data augmentation for time series classification with neural networks. 31 July 2020. URL: http://arxiv.org/abs/2007.15951 , arXiv:2007.15951 . \u21a9 \u21a9 \u21a9 Connor Shorten and Taghi M Khoshgoftaar. A survey on image data augmentation for deep learning. Journal of Big Data , 6(1):1\u201348, 6 July 2019. URL: https://journalofbigdata.springeropen.com/articles/10.1186/s40537-019-0197-0 , doi:10.1186/s40537-019-0197-0 . \u21a9 Qingsong Wen, Liang Sun, Fan Yang, Xiaomin Song, Jingkun Gao, Xue Wang, and Huan Xu. Time series data augmentation for deep learning: a survey. 27 February 2020. URL: http://arxiv.org/abs/2002.12478 , arXiv:2002.12478 . \u21a9 \u21a9 Fran\u00e7ois Petitjean, Alain Ketterlin, and Pierre Gan\u00e7arski. A global averaging method for dynamic time warping, with applications to clustering. Pattern recognition , 44(3):678\u2013693, 1 March 2011. URL: https://www.sciencedirect.com/science/article/pii/S003132031000453X , doi:10.1016/j.patcog.2010.09.013 . \u21a9 \u21a9 \u21a9 \u21a9 Yanfei Kang, Rob J Hyndman, and Feng Li. GRATIS: GeneRAting TIme series with diverse and controllable characteristics. 7 March 2019. URL: http://arxiv.org/abs/1903.02787 , arXiv:1903.02787 . \u21a9 \u21a9 J H Stock and M W Watson. Chapter 8 - dynamic factor models, Factor-Augmented vector autoregressions, and structural vector autoregressions in macroeconomics. In John B Taylor and Harald Uhlig, editors, Handbook of Macroeconomics , volume 2, pages 415\u2013525. Elsevier, 1 January 2016. URL: https://www.sciencedirect.com/science/article/pii/S1574004816300027 , doi:10.1016/bs.hesmac.2016.04.002 . \u21a9 \u21a9 \u21a9 Jinsung Yoon, Daniel Jarrett, and Mihaela van der Schaar. Time-series generative adversarial networks. In H Wallach, H Larochell, A Beygelzime, F dAlche Buc, E Fox, and R Garnett, editors, Advances in Neural Information Processing Systems , volume 32. Curran Associates, Inc., 2019. URL: https://papers.nips.cc/paper/2019/hash/c9efe5f26cd17ba6216bbe2a7d26d490-Abstract.html . \u21a9 Eoin Brophy, Zhengwei Wang, Qi She, and Tomas Ward. Generative adversarial networks in time series: a survey and taxonomy. 23 July 2021. URL: http://arxiv.org/abs/2107.11098 , arXiv:2107.11098 . \u21a9 Naoya Takahashi, Michael Gygli, and Luc Van Gool. AENet: learning deep audio features for video analysis. 3 January 2017. URL: http://arxiv.org/abs/1701.00599 , arXiv:1701.00599 . \u21a9 \u21a9 Xiaodong Cui, Vaibhava Goel, and Brian Kingsbury. Data augmentation for deep neural network acoustic modeling. In 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) , 5582\u20135586. May 2014. URL: http://dx.doi.org/10.1109/ICASSP.2014.6854671 , doi:10.1109/ICASSP.2014.6854671 . \u21a9 \u21a9 Brian Kenji Iwana and Seiichi Uchida. Time series data augmentation for neural networks by time warping with a discriminative teacher. 19 April 2020. URL: http://arxiv.org/abs/2004.08780 , arXiv:2004.08780 . \u21a9 Jingkun Gao, Xiaomin Song, Qingsong Wen, Pichao Wang, Liang Sun, and Huan Xu. RobustTAD: robust time series anomaly detection via decomposition and convolutional neural networks. 21 February 2020. URL: http://arxiv.org/abs/2002.09545 , arXiv:2002.09545 . \u21a9 Arthur Le Guennec, Simon Malinowski, and Romain Tavenard. Data augmentation for time series classification using convolutional neural networks. In ECML/PKDD workshop on advanced analytics and learning on temporal data . 2016. URL: https://halshs.archives-ouvertes.fr/halshs-01357973/document . \u21a9 Terry Taewoong Um, Franz Michael Josef Pfister, Daniel Pichler, Satoshi Endo, Muriel Lang, Sandra Hirche, Urban Fietzek, and Dana Kuli\u0107. Data augmentation of wearable sensor data for parkinson's disease monitoring using convolutional neural networks. 2 June 2017. URL: http://arxiv.org/abs/1706.00527 , arXiv:1706.00527 . \u21a9 Christoph Bergmeir, Rob J Hyndman, and Jos\u00e9 M Ben\u00edtez. Bagging exponential smoothing methods using STL decomposition and Box\u2013Cox transformation. International journal of forecasting , 32(2):303\u2013312, 1 April 2016. URL: https://www.sciencedirect.com/science/article/pii/S0169207015001120 , doi:10.1016/j.ijforecast.2015.07.002 . \u21a9 Hansika Hewamalage, Christoph Bergmeir, and Kasun Bandara. Recurrent neural networks for time series forecasting: current status and future directions. 2 September 2019. URL: http://arxiv.org/abs/1909.00590 , arXiv:1909.00590 . \u21a9 Kasun Bandara, Hansika Hewamalage, Yuan-Hao Liu, Yanfei Kang, and Christoph Bergmeir. Improving the accuracy of global forecasting models using time series data augmentation. 6 August 2020. URL: http://arxiv.org/abs/2008.02663 , arXiv:2008.02663 . \u21a9 \u21a9 Germain Forestier, Fran\u00e7ois Petitjean, Hoang Anh Dau, Geoffrey I Webb, and Eamonn Keogh. Generating synthetic time series to augment sparse datasets. In 2017 IEEE International Conference on Data Mining (ICDM) , 865\u2013870. November 2017. URL: http://dx.doi.org/10.1109/ICDM.2017.106 , doi:10.1109/ICDM.2017.106 . \u21a9 \u21a9 \u21a9 Hong Cao, Vincent Y F Tan, and John Z F Pang. A parsimonious mixture of gaussian trees model for oversampling in imbalanced and multimodal time-series classification. IEEE transactions on neural networks and learning systems , 25(12):2226\u20132239, December 2014. URL: http://dx.doi.org/10.1109/TNNLS.2014.2308321 , doi:10.1109/TNNLS.2014.2308321 . \u21a9","title":"Augmentation"},{"location":"time-series/timeseries-data.data-augmentation/#data-augmentation-for-time-series","text":"In deep learning, our dataset should help the optimization mechanism locate a good spot in the parameter space. However, real-world data is not necessarily diverse enough that covers the required situations with enough records. For example, some datasets maybe extremely imbalanced class labels which leads to poor performance in classification tasks. 1 Another problem with a limited dataset is that the trained model may not generalize well. 2 3 We will cover two topics in this section: Augmenting the dataset and application of the augmented data to model training.","title":"Data Augmentation for Time Series"},{"location":"time-series/timeseries-data.data-augmentation/#augmenting-the-dataset","text":"There are many different ways of augmenting time series data. 2 4 We categorize the methods into the following groups: Random transformations, e.g., jittering; Pattern mixing, e.g., DBA; 5 Generative models, e.g., phenomenological generative models such as AR, 6 first principle models such as economical models, 7 deep generative models such as TimeGAN or TS GAN. 8 9 We also treat the first two methods, random transformations and pattern mixing as basic methods.","title":"Augmenting the Dataset"},{"location":"time-series/timeseries-data.data-augmentation/#basic-methods","text":"In the following table, we group some of the data augmentation methods by two dimensions, the category of the method, and domain of where the method is applied. Projected Domain Time Scale Magnitude Random Transformation Frequency Masking, Frequency Warping, Fourier Transform, STFT Permutation, Slicing, Time Warping, Time Masking, Cropping Jittering, Flipping, Scaling, Magnitude Warping Pattern Mixing EMDA 10 , SFM 11 Guided Warping 12 DFM 7 , Interpolation, DBA 5 For completeness, we will explain some of the methods in more details in the following.","title":"Basic Methods"},{"location":"time-series/timeseries-data.data-augmentation/#perturbation-in-fourier-domain","text":"In the Fourier domain, for each the amplitude \\(A_f\\) and phase \\(\\phi_f\\) at a specific frequency, we can perform 13 magnitude replacement using a Gaussian distribution, and phase shift by adding a Gaussian noise. We perform such perturbations at some chosen frequency.","title":"Perturbation in Fourier Domain"},{"location":"time-series/timeseries-data.data-augmentation/#slicing-permutation-and-bootstrapping","text":"We can slice a series into small segments. With the slices, we can perform different operations to create new series. Window Slicing ( WS ): In a classification tasks, we can take the slices from the original series and assign the same class label to the slice. 14 The slices can also be interpolated to match the length of the original series. 2 Permutation: We take the slices and permute them to form a new series. 15 Moving Block Bootstrapping ( MBB ): First, we remove the trend and seasonability. Then we draw blocks of fixed length from the residual of the series, until the desired length of series is met. Finally, we combine the newly formed residual with trend and seasonality to form a new series. 16","title":"Slicing, Permutation, and Bootstrapping"},{"location":"time-series/timeseries-data.data-augmentation/#warping","text":"Both the time scale and magnitude can be warped. For example, Time Warping: We distort time intervals by taking a range of data points and up sample or down sample it. 4 Magnitude Warping: the magnitude of the time series is rescaled.","title":"Warping"},{"location":"time-series/timeseries-data.data-augmentation/#series-mixing","text":"Another class of data augmentation methods is mixing the series. For example, we take two random drawn series and average them using DTW Barycenter Averaging ( DBA ). 5 (DTW, dynamic time warping, is an algorithm to calculate the distance between sequential datasets by matching the data points on each of the series. 5 17 ) To augment a dataset, we can choose from a list of strategies: 18 19 Average All series using different sets of weights to create new synthetic series. Average Selected series based on some strategies. For example, Forestier et al proposed to choose an initial series and combine it with its nearest neighbors. 19 Average Selected with Distance is Average Selected but neighbors that are far from the initial series is down weighted. 19 Some other similar methods are Equalized Mixture Data Augmentation ( EMDA ) calculates the weighted average of spectrograms of the same class label. 10 Stochastic Feature Mapping ( SFM ) is a data augmentation method in audio data. 11","title":"Series Mixing"},{"location":"time-series/timeseries-data.data-augmentation/#data-generating-process","text":"Time series data can also be augmented using some assumed data generating process ( DGP ). Some methods, such as GRATIS 6 , utilizes simple generic methods such as AR/MAR. Some other methods, such as Gaussian Trees 20 , utilizes more complicated hidden structure using graphs, which can approximate more complicated data generating process. These methods do not necessarily reflect the actual data generating process but the data is generated using some parsimonious phenomenological models. Some other methods are more tuned towards the detailed mechanisms. There are also methods using generative deep neural networks such as GAN .","title":"Data Generating Process"},{"location":"time-series/timeseries-data.data-augmentation/#dynamic-factor-model-dfm","text":"For example, we have a series \\(X(t)\\) which depends on a latent variable \\(f(t)\\) , 7 \\[ X(t) = \\mathbf A f(t) + \\eta(t), \\] where \\(f(t)\\) is determined by a differential equation \\[ \\frac{f(t)}{dt} = \\mathbf B f(t) + \\xi(t). \\] In the above equations, \\(\\eta(t)\\) and \\(\\xi(t)\\) are the irreducible noise. The above two equatioins can be combined into one first-order differential equation. Once the model is fit, it can be used to generate new data points. However, we will have to understand whether the data is generated in such processes.","title":"Dynamic Factor Model (DFM)"},{"location":"time-series/timeseries-data.data-augmentation/#applying-the-synthetic-data-to-model-training","text":"Once we prepared the synthetic dataset, there are two strategies to include them in our model training. 18 Strategy Description Pooled Strategy Synthetic data + original data -> model Transfer Strategy Synthetic data -> pre-trained model; pre-trained model + original data -> model The pooled strategy takes the synthetic data and original data, then feed them together into the training pipeline. The transfer strategy uses the synthetic data to pre-train the model, then using transfer learning methods (e.g., freeze weights of some layers) to train the model on the original data. Ramin Hasibi, Matin Shokri, and Mehdi Dehghan. Augmentation scheme for dealing with imbalanced network traffic classification using deep learning. 1 January 2019. URL: http://arxiv.org/abs/1901.00204 , arXiv:1901.00204 . \u21a9 Brian Kenji Iwana and Seiichi Uchida. An empirical survey of data augmentation for time series classification with neural networks. 31 July 2020. URL: http://arxiv.org/abs/2007.15951 , arXiv:2007.15951 . \u21a9 \u21a9 \u21a9 Connor Shorten and Taghi M Khoshgoftaar. A survey on image data augmentation for deep learning. Journal of Big Data , 6(1):1\u201348, 6 July 2019. URL: https://journalofbigdata.springeropen.com/articles/10.1186/s40537-019-0197-0 , doi:10.1186/s40537-019-0197-0 . \u21a9 Qingsong Wen, Liang Sun, Fan Yang, Xiaomin Song, Jingkun Gao, Xue Wang, and Huan Xu. Time series data augmentation for deep learning: a survey. 27 February 2020. URL: http://arxiv.org/abs/2002.12478 , arXiv:2002.12478 . \u21a9 \u21a9 Fran\u00e7ois Petitjean, Alain Ketterlin, and Pierre Gan\u00e7arski. A global averaging method for dynamic time warping, with applications to clustering. Pattern recognition , 44(3):678\u2013693, 1 March 2011. URL: https://www.sciencedirect.com/science/article/pii/S003132031000453X , doi:10.1016/j.patcog.2010.09.013 . \u21a9 \u21a9 \u21a9 \u21a9 Yanfei Kang, Rob J Hyndman, and Feng Li. GRATIS: GeneRAting TIme series with diverse and controllable characteristics. 7 March 2019. URL: http://arxiv.org/abs/1903.02787 , arXiv:1903.02787 . \u21a9 \u21a9 J H Stock and M W Watson. Chapter 8 - dynamic factor models, Factor-Augmented vector autoregressions, and structural vector autoregressions in macroeconomics. In John B Taylor and Harald Uhlig, editors, Handbook of Macroeconomics , volume 2, pages 415\u2013525. Elsevier, 1 January 2016. URL: https://www.sciencedirect.com/science/article/pii/S1574004816300027 , doi:10.1016/bs.hesmac.2016.04.002 . \u21a9 \u21a9 \u21a9 Jinsung Yoon, Daniel Jarrett, and Mihaela van der Schaar. Time-series generative adversarial networks. In H Wallach, H Larochell, A Beygelzime, F dAlche Buc, E Fox, and R Garnett, editors, Advances in Neural Information Processing Systems , volume 32. Curran Associates, Inc., 2019. URL: https://papers.nips.cc/paper/2019/hash/c9efe5f26cd17ba6216bbe2a7d26d490-Abstract.html . \u21a9 Eoin Brophy, Zhengwei Wang, Qi She, and Tomas Ward. Generative adversarial networks in time series: a survey and taxonomy. 23 July 2021. URL: http://arxiv.org/abs/2107.11098 , arXiv:2107.11098 . \u21a9 Naoya Takahashi, Michael Gygli, and Luc Van Gool. AENet: learning deep audio features for video analysis. 3 January 2017. URL: http://arxiv.org/abs/1701.00599 , arXiv:1701.00599 . \u21a9 \u21a9 Xiaodong Cui, Vaibhava Goel, and Brian Kingsbury. Data augmentation for deep neural network acoustic modeling. In 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) , 5582\u20135586. May 2014. URL: http://dx.doi.org/10.1109/ICASSP.2014.6854671 , doi:10.1109/ICASSP.2014.6854671 . \u21a9 \u21a9 Brian Kenji Iwana and Seiichi Uchida. Time series data augmentation for neural networks by time warping with a discriminative teacher. 19 April 2020. URL: http://arxiv.org/abs/2004.08780 , arXiv:2004.08780 . \u21a9 Jingkun Gao, Xiaomin Song, Qingsong Wen, Pichao Wang, Liang Sun, and Huan Xu. RobustTAD: robust time series anomaly detection via decomposition and convolutional neural networks. 21 February 2020. URL: http://arxiv.org/abs/2002.09545 , arXiv:2002.09545 . \u21a9 Arthur Le Guennec, Simon Malinowski, and Romain Tavenard. Data augmentation for time series classification using convolutional neural networks. In ECML/PKDD workshop on advanced analytics and learning on temporal data . 2016. URL: https://halshs.archives-ouvertes.fr/halshs-01357973/document . \u21a9 Terry Taewoong Um, Franz Michael Josef Pfister, Daniel Pichler, Satoshi Endo, Muriel Lang, Sandra Hirche, Urban Fietzek, and Dana Kuli\u0107. Data augmentation of wearable sensor data for parkinson's disease monitoring using convolutional neural networks. 2 June 2017. URL: http://arxiv.org/abs/1706.00527 , arXiv:1706.00527 . \u21a9 Christoph Bergmeir, Rob J Hyndman, and Jos\u00e9 M Ben\u00edtez. Bagging exponential smoothing methods using STL decomposition and Box\u2013Cox transformation. International journal of forecasting , 32(2):303\u2013312, 1 April 2016. URL: https://www.sciencedirect.com/science/article/pii/S0169207015001120 , doi:10.1016/j.ijforecast.2015.07.002 . \u21a9 Hansika Hewamalage, Christoph Bergmeir, and Kasun Bandara. Recurrent neural networks for time series forecasting: current status and future directions. 2 September 2019. URL: http://arxiv.org/abs/1909.00590 , arXiv:1909.00590 . \u21a9 Kasun Bandara, Hansika Hewamalage, Yuan-Hao Liu, Yanfei Kang, and Christoph Bergmeir. Improving the accuracy of global forecasting models using time series data augmentation. 6 August 2020. URL: http://arxiv.org/abs/2008.02663 , arXiv:2008.02663 . \u21a9 \u21a9 Germain Forestier, Fran\u00e7ois Petitjean, Hoang Anh Dau, Geoffrey I Webb, and Eamonn Keogh. Generating synthetic time series to augment sparse datasets. In 2017 IEEE International Conference on Data Mining (ICDM) , 865\u2013870. November 2017. URL: http://dx.doi.org/10.1109/ICDM.2017.106 , doi:10.1109/ICDM.2017.106 . \u21a9 \u21a9 \u21a9 Hong Cao, Vincent Y F Tan, and John Z F Pang. A parsimonious mixture of gaussian trees model for oversampling in imbalanced and multimodal time-series classification. IEEE transactions on neural networks and learning systems , 25(12):2226\u20132239, December 2014. URL: http://dx.doi.org/10.1109/TNNLS.2014.2308321 , doi:10.1109/TNNLS.2014.2308321 . \u21a9","title":"Applying the Synthetic Data to Model Training"},{"location":"time-series/timeseries-data.dtw-barycenter-averaging/","text":"DTW Barycenter Averaging \u00b6 DTW Barycenter Averaging ( DBA ) constructs a series \\(\\bar{\\mathcal S}\\) out of a set of series \\(\\{\\mathcal S^{(\\alpha)}\\}\\) so that \\(\\bar{\\mathcal S}\\) is the barycenter of \\(\\{\\mathcal S^{(\\alpha)}\\}\\) measured by Dynamic Time Warping ( DTW ) distance. 2 Dynamic Time Warping ( DTW ) \u00b6 Given two sequences, \\(S^{(1)}\\) and \\(S^{(2)}\\) , the Dynamic Time Warping ( DTW ) algorithm finds the best way to align two sequences. During this alignment process, we quantify the misalignment using a distance similar to the Levenshtein distance, where the distance between two series \\(S^{(1)}_{1:i}\\) (with \\(i\\) elements) and \\(S^{(2)}_{1:j}\\) (with \\(j\\) elements) is 2 \\[ \\begin{align} D(S^{(1)}_{1:i}, S^{(2)}_{1:j}) =& d(S^{(1)}_i, S^{(2)}_j)\\\\ & + \\operatorname{min}\\left[ D(S^{(1)}_{1:i-1}, S^{(2)}_{1:j-1}), D(S^{(1)}_{1:i}, S^{(2)}_{1:j-1}), D(S^{(1)}_{1:i-1}, S^{(2)}_{1:j}) \\right], \\end{align} \\] where \\(S^{(1)}_i\\) is the \\(i\\) the element of the series \\(S^{(1)}\\) , \\(d(x,y)\\) is a predetermined distance, e.g., Euclidean distance. This definition reveals the recursive nature of the DTW distance. Notations in the Definition: \\(S_{1:i}\\) and \\(S_{i}\\) The notation \\(S_{1:i}\\) stands for a series that contains the elements starting from the first to the \\(i\\) th in series \\(S\\) . For example, we have a series \\[ S^1 = [s^1_1, s^1_2, s^1_3, s^1_4, s^1_5, s^1_6]. \\] The notation \\(S^1_{1:4}\\) represents \\[ S^1_{1:4} = [s^1_1, s^1_2, s^1_3, s^1_4]. \\] The notation \\(S_i\\) indicates the \\(i\\) th element in \\(S\\) . For example, \\[ S^1_4 = s^1_4. \\] If we map these two notations to Python, \\(S_{1:i}\\) is equivalent to S[0:i] , and \\(S_i\\) is equivalent to S[i-1] . Note that the indices in Python looks strange. This is also the reason we choose to use subscripts not square brackets in our definition. Levenshtein Distance Given two words, e.g., \\(w^{a} = \\mathrm{cats}\\) and \\(w^{b} = \\mathrm{katz}\\) . Suppose we can only use three operations: insertions, deletions and substitutions. The Levenshtein distance calculates the number of such operations needed to change from the first word \\(w^a\\) to the second one \\(w^b\\) by applying single-character edits. In this example, we need two replacements, i.e., \"c\" -> \"k\" and \"s\" -> \"z\" . The Levenshtein distance can be solved using recursive algorithms. 1 Barycenter Averaging Based on DTW Distance \u00b6 Petitjean et al proposed an time series averaging algorithm based on DTW distance which is dubbed as DTW Barycenter Averaging ( DBA ). DBA Implementation https://github.com/fpetitjean/DBA trekhleb. javascript-algorithms/src/algorithms/string/levenshtein-distance at master \u00b7 trekhleb/javascript-algorithms. In: GitHub [Internet]. [cited 27 Jul 2022]. Available: https://github.com/trekhleb/javascript-algorithms/tree/master/src/algorithms/string/levenshtein-distance \u21a9 Fran\u00e7ois Petitjean, Alain Ketterlin, and Pierre Gan\u00e7arski. A global averaging method for dynamic time warping, with applications to clustering. Pattern recognition , 44(3):678\u2013693, 1 March 2011. URL: https://www.sciencedirect.com/science/article/pii/S003132031000453X , doi:10.1016/j.patcog.2010.09.013 . \u21a9 \u21a9","title":"DBA"},{"location":"time-series/timeseries-data.dtw-barycenter-averaging/#dtw-barycenter-averaging","text":"DTW Barycenter Averaging ( DBA ) constructs a series \\(\\bar{\\mathcal S}\\) out of a set of series \\(\\{\\mathcal S^{(\\alpha)}\\}\\) so that \\(\\bar{\\mathcal S}\\) is the barycenter of \\(\\{\\mathcal S^{(\\alpha)}\\}\\) measured by Dynamic Time Warping ( DTW ) distance. 2","title":"DTW Barycenter Averaging"},{"location":"time-series/timeseries-data.dtw-barycenter-averaging/#dynamic-time-warping-dtw","text":"Given two sequences, \\(S^{(1)}\\) and \\(S^{(2)}\\) , the Dynamic Time Warping ( DTW ) algorithm finds the best way to align two sequences. During this alignment process, we quantify the misalignment using a distance similar to the Levenshtein distance, where the distance between two series \\(S^{(1)}_{1:i}\\) (with \\(i\\) elements) and \\(S^{(2)}_{1:j}\\) (with \\(j\\) elements) is 2 \\[ \\begin{align} D(S^{(1)}_{1:i}, S^{(2)}_{1:j}) =& d(S^{(1)}_i, S^{(2)}_j)\\\\ & + \\operatorname{min}\\left[ D(S^{(1)}_{1:i-1}, S^{(2)}_{1:j-1}), D(S^{(1)}_{1:i}, S^{(2)}_{1:j-1}), D(S^{(1)}_{1:i-1}, S^{(2)}_{1:j}) \\right], \\end{align} \\] where \\(S^{(1)}_i\\) is the \\(i\\) the element of the series \\(S^{(1)}\\) , \\(d(x,y)\\) is a predetermined distance, e.g., Euclidean distance. This definition reveals the recursive nature of the DTW distance. Notations in the Definition: \\(S_{1:i}\\) and \\(S_{i}\\) The notation \\(S_{1:i}\\) stands for a series that contains the elements starting from the first to the \\(i\\) th in series \\(S\\) . For example, we have a series \\[ S^1 = [s^1_1, s^1_2, s^1_3, s^1_4, s^1_5, s^1_6]. \\] The notation \\(S^1_{1:4}\\) represents \\[ S^1_{1:4} = [s^1_1, s^1_2, s^1_3, s^1_4]. \\] The notation \\(S_i\\) indicates the \\(i\\) th element in \\(S\\) . For example, \\[ S^1_4 = s^1_4. \\] If we map these two notations to Python, \\(S_{1:i}\\) is equivalent to S[0:i] , and \\(S_i\\) is equivalent to S[i-1] . Note that the indices in Python looks strange. This is also the reason we choose to use subscripts not square brackets in our definition. Levenshtein Distance Given two words, e.g., \\(w^{a} = \\mathrm{cats}\\) and \\(w^{b} = \\mathrm{katz}\\) . Suppose we can only use three operations: insertions, deletions and substitutions. The Levenshtein distance calculates the number of such operations needed to change from the first word \\(w^a\\) to the second one \\(w^b\\) by applying single-character edits. In this example, we need two replacements, i.e., \"c\" -> \"k\" and \"s\" -> \"z\" . The Levenshtein distance can be solved using recursive algorithms. 1","title":"Dynamic Time Warping (DTW)"},{"location":"time-series/timeseries-data.dtw-barycenter-averaging/#barycenter-averaging-based-on-dtw-distance","text":"Petitjean et al proposed an time series averaging algorithm based on DTW distance which is dubbed as DTW Barycenter Averaging ( DBA ). DBA Implementation https://github.com/fpetitjean/DBA trekhleb. javascript-algorithms/src/algorithms/string/levenshtein-distance at master \u00b7 trekhleb/javascript-algorithms. In: GitHub [Internet]. [cited 27 Jul 2022]. Available: https://github.com/trekhleb/javascript-algorithms/tree/master/src/algorithms/string/levenshtein-distance \u21a9 Fran\u00e7ois Petitjean, Alain Ketterlin, and Pierre Gan\u00e7arski. A global averaging method for dynamic time warping, with applications to clustering. Pattern recognition , 44(3):678\u2013693, 1 March 2011. URL: https://www.sciencedirect.com/science/article/pii/S003132031000453X , doi:10.1016/j.patcog.2010.09.013 . \u21a9 \u21a9","title":"Barycenter Averaging Based on DTW Distance"},{"location":"time-series/timeseries-datasets.dgp.langevin/","text":"Time Series Data Generating Process: Langevin Equation \u00b6 Among the many data generating processes (DGP), Langevin equation is one of the most interesting DGP. Brownian Motion \u00b6 Brownian motion as a very simple stochastic process can be described by the Langevin equation 1 . In this section, we simulate a time series dataset from Brownian motion. Macroscopically, Brownian Motion can be described by the notion of random forces on the particles, \\[ \\frac{d}{dt} v(t) + \\gamma v(t) = R(t), \\] where \\(v(t)\\) is the velocity at time \\(t\\) and \\(R(t)\\) is the stochastic force density from the reservoir particles. Solving the equation, we get \\[ v(t) = v(0)e^{-\\gamma t} + \\int_0^t dt' e^{-\\gamma (t-t')} R(t') . \\] To generate a dataset numerically, we discretize it by replacing the integral with a sum, \\[ v(t) = v(0) e^{-\\gamma t} + \\sum_{n=0}^N \\Delta t e^{-\\gamma (t - t_n)} R(t_n) \\] where \\(t_i = i * \\Delta t\\) and \\(t = t_n\\) , thus the equation is further simplified, \\[ v(N\\Delta t) = v(0) e^{-\\gamma N\\Delta t} + \\sum_{n=0}^N e^{-\\gamma (N - n)\\Delta t} R(n\\Delta t) \\Delta t. \\] The first term in the solution is responsible for the exponential decay and the second term calculates the effect of the stochastic force. To simulate a Brownian motion, we can either use the formal solution or the differential equation itself. Here we choose to use the differential equation itself. To simulate the process numerically, we rewrite \\[ \\frac{d}{dt} v(t) + \\gamma v(t) = R(t), \\] as \\[ \\Delta v (t+1) = R(t) \\Delta t - \\gamma v(t) \\Delta t. \\] Brownian Motion Python Code The following is a simulated 1D Brownian motion. We create a stepper to calculate the next steps. import numpy as np import copy import matplotlib.pyplot as plt import seaborn as sns ; sns . set () ## Define Brownian Motion class GaussianForce : \"\"\"A Gaussian stochastic force iterator. Each iteration returns a single sample from the corresponding Gaussian distribution. :param mu: mean of the Gaussian distribution :param std: standard deviation of the Gaussian distribution :param seed: seed for the random generator \"\"\" def __init__ ( self , mu : float , std : float , seed : Optional [ float ] = None ): self . mu = mu self . std = std self . rng = np . random . default_rng ( seed = seed ) def __next__ ( self ) -> float : return self . rng . normal ( self . mu , self . std ) class BrownianMotionStepper : \"\"\"Calculates the next step in a brownian motion. :param gamma: the damping factor $\\gamma$ of the Brownian motion. :param delta_t: the minimum time step $\\Delta t$. :param force_densities: the stochastic force densities, e.g. [`GaussianForce`][eerily.data.generators.brownian.GaussianForce]. :param initial_state: the initial velocity $v(0)$. \"\"\" def __init__ ( self , gamma : float , delta_t : float , force_densities : Iterator , initial_state : Dict [ str , float ], ): self . gamma = gamma self . delta_t = delta_t self . forece_densities = copy . deepcopy ( force_densities ) self . current_state = copy . deepcopy ( initial_state ) def __iter__ ( self ): return self def __next__ ( self ) -> Dict [ str , float ]: force_density = next ( self . forece_densities ) v_current = self . current_state [ \"v\" ] v_next = v_current + force_density * self . delta_t - self . gamma * v_current * self . delta_t self . current_state [ \"force_density\" ] = force_density self . current_state [ \"v\" ] = v_next return copy . deepcopy ( self . current_state ) ## Generating time series delta_t = 0.1 stepper = BrownianMotionStepper ( gamma = 0 , delta_t = delta_t , force_densities = GaussianForece ( mu = 0 , std = 1 ), initial_state = { \"v\" : 0 }, ) length = 200 history = [] for _ in range ( length ): history . append ( next ( stepper )) df = pd . DataFrame ( history ) fig , ax = plt . subplots ( figsize = ( 10 , 6.18 )) sns . lineplot ( x = np . linspace ( 0 , length - 1 , length ) * delta_t , y = df . v , ax = ax , marker = \"o\" , ) ax . set_title ( \"Brownian Motion\" ) ax . set_xlabel ( \"Time\" ) ax . set_ylabel ( \"Velocity\" ) Ma L. Brownian Motion \u2014 Statistical Physics Notes. In: Statistical Physics [Internet]. [cited 17 Nov 2022]. Available: https://statisticalphysics.leima.is/nonequilibrium/brownian-motion.html \u21a9","title":"DGP: Langevin Equation"},{"location":"time-series/timeseries-datasets.dgp.langevin/#time-series-data-generating-process-langevin-equation","text":"Among the many data generating processes (DGP), Langevin equation is one of the most interesting DGP.","title":"Time Series Data Generating Process: Langevin Equation"},{"location":"time-series/timeseries-datasets.dgp.langevin/#brownian-motion","text":"Brownian motion as a very simple stochastic process can be described by the Langevin equation 1 . In this section, we simulate a time series dataset from Brownian motion. Macroscopically, Brownian Motion can be described by the notion of random forces on the particles, \\[ \\frac{d}{dt} v(t) + \\gamma v(t) = R(t), \\] where \\(v(t)\\) is the velocity at time \\(t\\) and \\(R(t)\\) is the stochastic force density from the reservoir particles. Solving the equation, we get \\[ v(t) = v(0)e^{-\\gamma t} + \\int_0^t dt' e^{-\\gamma (t-t')} R(t') . \\] To generate a dataset numerically, we discretize it by replacing the integral with a sum, \\[ v(t) = v(0) e^{-\\gamma t} + \\sum_{n=0}^N \\Delta t e^{-\\gamma (t - t_n)} R(t_n) \\] where \\(t_i = i * \\Delta t\\) and \\(t = t_n\\) , thus the equation is further simplified, \\[ v(N\\Delta t) = v(0) e^{-\\gamma N\\Delta t} + \\sum_{n=0}^N e^{-\\gamma (N - n)\\Delta t} R(n\\Delta t) \\Delta t. \\] The first term in the solution is responsible for the exponential decay and the second term calculates the effect of the stochastic force. To simulate a Brownian motion, we can either use the formal solution or the differential equation itself. Here we choose to use the differential equation itself. To simulate the process numerically, we rewrite \\[ \\frac{d}{dt} v(t) + \\gamma v(t) = R(t), \\] as \\[ \\Delta v (t+1) = R(t) \\Delta t - \\gamma v(t) \\Delta t. \\] Brownian Motion Python Code The following is a simulated 1D Brownian motion. We create a stepper to calculate the next steps. import numpy as np import copy import matplotlib.pyplot as plt import seaborn as sns ; sns . set () ## Define Brownian Motion class GaussianForce : \"\"\"A Gaussian stochastic force iterator. Each iteration returns a single sample from the corresponding Gaussian distribution. :param mu: mean of the Gaussian distribution :param std: standard deviation of the Gaussian distribution :param seed: seed for the random generator \"\"\" def __init__ ( self , mu : float , std : float , seed : Optional [ float ] = None ): self . mu = mu self . std = std self . rng = np . random . default_rng ( seed = seed ) def __next__ ( self ) -> float : return self . rng . normal ( self . mu , self . std ) class BrownianMotionStepper : \"\"\"Calculates the next step in a brownian motion. :param gamma: the damping factor $\\gamma$ of the Brownian motion. :param delta_t: the minimum time step $\\Delta t$. :param force_densities: the stochastic force densities, e.g. [`GaussianForce`][eerily.data.generators.brownian.GaussianForce]. :param initial_state: the initial velocity $v(0)$. \"\"\" def __init__ ( self , gamma : float , delta_t : float , force_densities : Iterator , initial_state : Dict [ str , float ], ): self . gamma = gamma self . delta_t = delta_t self . forece_densities = copy . deepcopy ( force_densities ) self . current_state = copy . deepcopy ( initial_state ) def __iter__ ( self ): return self def __next__ ( self ) -> Dict [ str , float ]: force_density = next ( self . forece_densities ) v_current = self . current_state [ \"v\" ] v_next = v_current + force_density * self . delta_t - self . gamma * v_current * self . delta_t self . current_state [ \"force_density\" ] = force_density self . current_state [ \"v\" ] = v_next return copy . deepcopy ( self . current_state ) ## Generating time series delta_t = 0.1 stepper = BrownianMotionStepper ( gamma = 0 , delta_t = delta_t , force_densities = GaussianForece ( mu = 0 , std = 1 ), initial_state = { \"v\" : 0 }, ) length = 200 history = [] for _ in range ( length ): history . append ( next ( stepper )) df = pd . DataFrame ( history ) fig , ax = plt . subplots ( figsize = ( 10 , 6.18 )) sns . lineplot ( x = np . linspace ( 0 , length - 1 , length ) * delta_t , y = df . v , ax = ax , marker = \"o\" , ) ax . set_title ( \"Brownian Motion\" ) ax . set_xlabel ( \"Time\" ) ax . set_ylabel ( \"Velocity\" ) Ma L. Brownian Motion \u2014 Statistical Physics Notes. In: Statistical Physics [Internet]. [cited 17 Nov 2022]. Available: https://statisticalphysics.leima.is/nonequilibrium/brownian-motion.html \u21a9","title":"Brownian Motion"},{"location":"time-series/timeseries-datasets.dgp/","text":"Generating Processes for Time Series \u00b6 The data generating processes (DGP) for time series is diverse. For example, in physics, we have all sort of dynamical systems that generates time series data and many dynamics models are formulated based on the time series data. In industries, time series data are often coming from stochastic processes. Simple Examples of DGP \u00b6 Exponential Growth Exponential growth is a frequently observed natural and economical phenomena. \\[ y = e^{c \\cdot t} \\] Circular Motion Circular motion shows some cyclic patterns. \\[ y = sin(w \\cdot t) \\] Random Gaussian Time series can also be noisy Gaussian samples. General Linear Processes \u00b6 A popular model for modeling as well as generating time series is the autoregressive (AR) model. An AR is formulated as \\[ x_t = \\phi_0 + \\phi_1 x_{t-1} + \\epsilon_t. \\] AR(p) and the Lag Operator A general autoregressive model of p-th order is \\[ x_t = \\sum_l \\phi _i x_{t-i} + \\epsilon_t, \\] where \\(l\\) is the lag. Define a lag operator \\(\\hat L\\) with \\(\\hat L x_t = x_{t-1}\\) . The definition can also be rewritten using the lag operator \\[ x_t = \\sum_l \\phi _i {\\hat L}^i x_{t} + \\epsilon_t. \\] We write down each time step in the following table. \\(t\\) \\(x_t\\) 0 \\(y_0\\) 1 \\(\\phi_0 + \\phi_1 y_0 + \\epsilon_1\\) 2 \\(\\phi_0 + \\phi_1 (\\phi_0 + \\phi_1 y_0 + \\epsilon_1) + \\epsilon_2 = \\phi_0 (1 + \\phi_1) + \\phi_1^2 y_0 + \\phi_1\\epsilon_1 + \\epsilon_2\\) 3 \\(\\phi_0 + \\phi_1 (\\phi_0 + \\phi_1\\phi_0 + \\phi_1^2 y_0 + \\phi_1\\epsilon_1 + \\epsilon_2) + \\epsilon_3 = \\phi_0(1 + \\phi_1 + \\phi_1^2) + \\phi_1^3 y_0 + \\phi_1^2\\epsilon_1 + \\phi_1\\epsilon_2 + \\epsilon_3\\) ... ... \\(t\\) \\(\\phi_0 \\sum_{i=0}^{t-1} \\phi_1^i + \\phi_1^t y_0 + \\sum_{i=1}^{t-1} \\phi_1^{t-i} \\epsilon_{i}\\) We have found a new formula for AR(1), i.e. \\[ x_t = \\phi_0 \\sum_{i=0}^{t-1} \\phi_1^i + \\phi_1^t y_0 + \\sum_{i=1}^{t-1} \\phi_1^{t-i} \\epsilon_{i}, \\] which is very similar to a general linear process 1 \\[ x_t - \\mu = \\sum_{i=0}^\\tau \\alpha_i \\epsilon_{t-i}. \\] The general linear process is the Taylor expansion of a arbitrary DGP \\(x_t = \\operatorname{DGP}(\\epsilon_t, ...)\\) 1 . Interactions between Series \u00b6 The interactions between the series can be modeled as explicit interactions, e.g., many spiking neurons, or through hidden variables, e.g., hidden state model 2 . Among these models, Vector Autoregressive model, aka VAR, is a simple but popular model. Das P. Econometrics in Theory and Practice. Springer Nature Singapore; doi:10.1007/978-981-32-9019-8 \u21a9 \u21a9 Contributors to Wikimedia projects. Hidden Markov model. In: Wikipedia [Internet]. 22 Oct 2022 [cited 22 Nov 2022]. Available: https://en.wikipedia.org/wiki/Hidden_Markov_model \u21a9","title":"DGP"},{"location":"time-series/timeseries-datasets.dgp/#generating-processes-for-time-series","text":"The data generating processes (DGP) for time series is diverse. For example, in physics, we have all sort of dynamical systems that generates time series data and many dynamics models are formulated based on the time series data. In industries, time series data are often coming from stochastic processes.","title":"Generating Processes for Time Series"},{"location":"time-series/timeseries-datasets.dgp/#simple-examples-of-dgp","text":"Exponential Growth Exponential growth is a frequently observed natural and economical phenomena. \\[ y = e^{c \\cdot t} \\] Circular Motion Circular motion shows some cyclic patterns. \\[ y = sin(w \\cdot t) \\] Random Gaussian Time series can also be noisy Gaussian samples.","title":"Simple Examples of DGP"},{"location":"time-series/timeseries-datasets.dgp/#general-linear-processes","text":"A popular model for modeling as well as generating time series is the autoregressive (AR) model. An AR is formulated as \\[ x_t = \\phi_0 + \\phi_1 x_{t-1} + \\epsilon_t. \\] AR(p) and the Lag Operator A general autoregressive model of p-th order is \\[ x_t = \\sum_l \\phi _i x_{t-i} + \\epsilon_t, \\] where \\(l\\) is the lag. Define a lag operator \\(\\hat L\\) with \\(\\hat L x_t = x_{t-1}\\) . The definition can also be rewritten using the lag operator \\[ x_t = \\sum_l \\phi _i {\\hat L}^i x_{t} + \\epsilon_t. \\] We write down each time step in the following table. \\(t\\) \\(x_t\\) 0 \\(y_0\\) 1 \\(\\phi_0 + \\phi_1 y_0 + \\epsilon_1\\) 2 \\(\\phi_0 + \\phi_1 (\\phi_0 + \\phi_1 y_0 + \\epsilon_1) + \\epsilon_2 = \\phi_0 (1 + \\phi_1) + \\phi_1^2 y_0 + \\phi_1\\epsilon_1 + \\epsilon_2\\) 3 \\(\\phi_0 + \\phi_1 (\\phi_0 + \\phi_1\\phi_0 + \\phi_1^2 y_0 + \\phi_1\\epsilon_1 + \\epsilon_2) + \\epsilon_3 = \\phi_0(1 + \\phi_1 + \\phi_1^2) + \\phi_1^3 y_0 + \\phi_1^2\\epsilon_1 + \\phi_1\\epsilon_2 + \\epsilon_3\\) ... ... \\(t\\) \\(\\phi_0 \\sum_{i=0}^{t-1} \\phi_1^i + \\phi_1^t y_0 + \\sum_{i=1}^{t-1} \\phi_1^{t-i} \\epsilon_{i}\\) We have found a new formula for AR(1), i.e. \\[ x_t = \\phi_0 \\sum_{i=0}^{t-1} \\phi_1^i + \\phi_1^t y_0 + \\sum_{i=1}^{t-1} \\phi_1^{t-i} \\epsilon_{i}, \\] which is very similar to a general linear process 1 \\[ x_t - \\mu = \\sum_{i=0}^\\tau \\alpha_i \\epsilon_{t-i}. \\] The general linear process is the Taylor expansion of a arbitrary DGP \\(x_t = \\operatorname{DGP}(\\epsilon_t, ...)\\) 1 .","title":"General Linear Processes"},{"location":"time-series/timeseries-datasets.dgp/#interactions-between-series","text":"The interactions between the series can be modeled as explicit interactions, e.g., many spiking neurons, or through hidden variables, e.g., hidden state model 2 . Among these models, Vector Autoregressive model, aka VAR, is a simple but popular model. Das P. Econometrics in Theory and Practice. Springer Nature Singapore; doi:10.1007/978-981-32-9019-8 \u21a9 \u21a9 Contributors to Wikimedia projects. Hidden Markov model. In: Wikipedia [Internet]. 22 Oct 2022 [cited 22 Nov 2022]. Available: https://en.wikipedia.org/wiki/Hidden_Markov_model \u21a9","title":"Interactions between Series"},{"location":"time-series/timeseries-datasets.ecb-exchange-rate/","text":"Time Series Dataset: ECB Exchange Rate \u00b6 We download the time series data in zip format using this link . We find 41 currencies in this dataset. The earliest date is 1999-01-04. Example Plots Missing Values","title":"Exchange Rate"},{"location":"time-series/timeseries-datasets.ecb-exchange-rate/#time-series-dataset-ecb-exchange-rate","text":"We download the time series data in zip format using this link . We find 41 currencies in this dataset. The earliest date is 1999-01-04. Example Plots Missing Values","title":"Time Series Dataset: ECB Exchange Rate"},{"location":"time-series/timeseries-datasets/","text":"Time Series Datasets \u00b6 We list a few useful time series datasets here. name link descriptions ECB Exchange Rate Website ECB Exchange Rate Details NREL Solar Power Website Electricity UCI ElectricityLoadDiagrams20112014 Data Set PEMS Caltrans PeMS","title":"Time Series Datasets"},{"location":"time-series/timeseries-datasets/#time-series-datasets","text":"We list a few useful time series datasets here. name link descriptions ECB Exchange Rate Website ECB Exchange Rate Details NREL Solar Power Website Electricity UCI ElectricityLoadDiagrams20112014 Data Set PEMS Caltrans PeMS","title":"Time Series Datasets"},{"location":"time-series/timeseries-datasets.nrel-solar-energy/","text":"Time Series Dataset: Solar Energy \u00b6 We download the time series data from this link . NREL's Solar Power Data for Integration Studies are synthetic solar photovoltaic (PV) power plant data points for the United States representing the year 2006. When we downloaded Alabama on 2022-11-05, and loaded Actual_30.45_-88.25_2006_UPV_70MW_5_Min.csv as an example. We found a lot of 0 entries (which is expected as the will be no power during dark nights). Power is Zero Number of Records False 57868 True 47252 The dataset contains multiple files with each file containing a time series with a time step of 5 minutes ( naming convention explained here ). Example Plots Power Distribution in this Example Missing Values","title":"NREL Solar Power Data"},{"location":"time-series/timeseries-datasets.nrel-solar-energy/#time-series-dataset-solar-energy","text":"We download the time series data from this link . NREL's Solar Power Data for Integration Studies are synthetic solar photovoltaic (PV) power plant data points for the United States representing the year 2006. When we downloaded Alabama on 2022-11-05, and loaded Actual_30.45_-88.25_2006_UPV_70MW_5_Min.csv as an example. We found a lot of 0 entries (which is expected as the will be no power during dark nights). Power is Zero Number of Records False 57868 True 47252 The dataset contains multiple files with each file containing a time series with a time step of 5 minutes ( naming convention explained here ). Example Plots Power Distribution in this Example Missing Values","title":"Time Series Dataset: Solar Energy"},{"location":"time-series/timeseries-datasets.pems/","text":"Time Series Dataset: PEMS \u00b6 California Department of Transportation (Caltrans) Performance Measurement System (PeMS) provides traffic data on their website . To download the data 1 , Register on the website and wait for approval, then login. Go to this page and choose the data we need using the filter on the top. For example, we choose Type = Station 5-Minute and District = District 3 . We do not show examples of this dataset here. VeritasYin. How to download the dataset from PeMS website? \u00b7 Issue #6 \u00b7 VeritasYin/STGCN_IJCAI-18. In: GitHub [Internet]. [cited 5 Nov 2022]. Available: https://github.com/VeritasYin/STGCN_IJCAI-18/issues/6 \u21a9","title":"PeMS Traffic Data"},{"location":"time-series/timeseries-datasets.pems/#time-series-dataset-pems","text":"California Department of Transportation (Caltrans) Performance Measurement System (PeMS) provides traffic data on their website . To download the data 1 , Register on the website and wait for approval, then login. Go to this page and choose the data we need using the filter on the top. For example, we choose Type = Station 5-Minute and District = District 3 . We do not show examples of this dataset here. VeritasYin. How to download the dataset from PeMS website? \u00b7 Issue #6 \u00b7 VeritasYin/STGCN_IJCAI-18. In: GitHub [Internet]. [cited 5 Nov 2022]. Available: https://github.com/VeritasYin/STGCN_IJCAI-18/issues/6 \u21a9","title":"Time Series Dataset: PEMS"},{"location":"time-series/timeseries-datasets.synthetic/","text":"Synthetic Time Series \u00b6 With a proper understanding of the DGP , we can build data generators around the DGP we choose. GluonTS \u00b6 GluonTS is a python package for probabilistic time series modeling. It comes with a simple yet easy to use synthetic data generator. For example, to generate a time series of random Gaussian, we only need the following code 1 . from gluonts.dataset.artificial import recipe as rcp g_rg = rcp . RandomGaussian ( stddev = 2 ) g_rp_series = rcp . evaluate ( g_rg , 100 ) For more complicated multivariate time series, we create recipes for our variables. We steal the example in the GluonTS tutorial. from gluonts.dataset.artificial import recipe as rcp import matplotlib.pyplot as plt import seaborn as sns ; sns . set () daily_smooth_seasonality = rcp . SmoothSeasonality ( period = 288 , phase =- 72 ) noise = rcp . RandomGaussian ( stddev = 0.1 ) signal = daily_smooth_seasonality + noise recipe = dict ( daily_smooth_seasonality = daily_smooth_seasonality , noise = noise , signal = signal ) rec_eval = rcp . evaluate ( recipe , 500 ) fig , ax = plt . subplots ( figsize = ( 10 , 6.18 )) sns . lineplot ( rec_eval ) Synthetic data generation. In: GluonTS documentation [Internet]. [cited 13 Nov 2022]. Available: https://ts.gluon.ai/stable/tutorials/data_manipulation/synthetic_data_generation.html \u21a9","title":"Creating Synthetic Dataset"},{"location":"time-series/timeseries-datasets.synthetic/#synthetic-time-series","text":"With a proper understanding of the DGP , we can build data generators around the DGP we choose.","title":"Synthetic Time Series"},{"location":"time-series/timeseries-datasets.synthetic/#gluonts","text":"GluonTS is a python package for probabilistic time series modeling. It comes with a simple yet easy to use synthetic data generator. For example, to generate a time series of random Gaussian, we only need the following code 1 . from gluonts.dataset.artificial import recipe as rcp g_rg = rcp . RandomGaussian ( stddev = 2 ) g_rp_series = rcp . evaluate ( g_rg , 100 ) For more complicated multivariate time series, we create recipes for our variables. We steal the example in the GluonTS tutorial. from gluonts.dataset.artificial import recipe as rcp import matplotlib.pyplot as plt import seaborn as sns ; sns . set () daily_smooth_seasonality = rcp . SmoothSeasonality ( period = 288 , phase =- 72 ) noise = rcp . RandomGaussian ( stddev = 0.1 ) signal = daily_smooth_seasonality + noise recipe = dict ( daily_smooth_seasonality = daily_smooth_seasonality , noise = noise , signal = signal ) rec_eval = rcp . evaluate ( recipe , 500 ) fig , ax = plt . subplots ( figsize = ( 10 , 6.18 )) sns . lineplot ( rec_eval ) Synthetic data generation. In: GluonTS documentation [Internet]. [cited 13 Nov 2022]. Available: https://ts.gluon.ai/stable/tutorials/data_manipulation/synthetic_data_generation.html \u21a9","title":"GluonTS"},{"location":"time-series/timeseries-datasets.uci-electricity/","text":"Time Series Dataset: Electricity \u00b6 This dataset is provided as the \"ElectricityLoadDiagrams20112014 Data Set\" on the UCI website . It is the time series of electricity consumption of 370 points/clients. We download the time series data in zip format using this link . We find that in total 140256 rows and 370 series, the earliest time is 2011-01-01 00:15:00, the latest time is 2015-01-01 00:00:00, a fixed time interval of 15 minutes. Example Plots Missing Values We only plot out three series. We only plot every 100 time steps. We fine no missing values. Loading and Basic Cleaning \u00b6 We provide some code to load the data from the UCI website. import requests , zipfile , io import pandas as pd # Download from remote URL data_uri = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00321/LD2011_2014.txt.zip\" r = requests . get ( data_uri ) z = zipfile . ZipFile ( io . BytesIO ( r . content )) z . extractall ( \"data/uci_electricity/\" ) # Load as pandas dataframe df = pd . read_csv ( \"data/uci_electricity/LD2011_2014.txt\" , delimiter = \";\" , decimal = ',' ) . rename ( columns = { \"Unnamed: 0\" : \"date\" }) . set_index ( \"date\" ) df . index = pd . to_datetime ( df . index )","title":"Electricity"},{"location":"time-series/timeseries-datasets.uci-electricity/#time-series-dataset-electricity","text":"This dataset is provided as the \"ElectricityLoadDiagrams20112014 Data Set\" on the UCI website . It is the time series of electricity consumption of 370 points/clients. We download the time series data in zip format using this link . We find that in total 140256 rows and 370 series, the earliest time is 2011-01-01 00:15:00, the latest time is 2015-01-01 00:00:00, a fixed time interval of 15 minutes. Example Plots Missing Values We only plot out three series. We only plot every 100 time steps. We fine no missing values.","title":"Time Series Dataset: Electricity"},{"location":"time-series/timeseries-datasets.uci-electricity/#loading-and-basic-cleaning","text":"We provide some code to load the data from the UCI website. import requests , zipfile , io import pandas as pd # Download from remote URL data_uri = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00321/LD2011_2014.txt.zip\" r = requests . get ( data_uri ) z = zipfile . ZipFile ( io . BytesIO ( r . content )) z . extractall ( \"data/uci_electricity/\" ) # Load as pandas dataframe df = pd . read_csv ( \"data/uci_electricity/LD2011_2014.txt\" , delimiter = \";\" , decimal = ',' ) . rename ( columns = { \"Unnamed: 0\" : \"date\" }) . set_index ( \"date\" ) df . index = pd . to_datetime ( df . index )","title":"Loading and Basic Cleaning"},{"location":"time-series/timeseries-hierarchical.data/","text":"Hierarchical Time Series Data \u00b6 Many real world time series data asserts some internal structure among the series. For example, the dataset used in the M5 competition is the sales data of different items but with the store and category information provided 1 . For simplicity, we simplified the dataset to only include the hierarchy of stores. Hierarchy Structure Visualization The simplified dataset can be found here . The original data can be found on the website of IIF . In this simplified version of the M5 dataset, we have the following hierarchy. flowchart LR top[\"Total Sales\"] ca[\"Sales in California\"] tx[\"Sales in Texas\"] wi[\"Sales in Wisconsin\"] top --- ca top --- tx top --- wi subgraph California ca1[\"Sales in Store #1 in CA\"] ca2[\"Sales in Store #2 in CA\"] ca3[\"Sales in Store #3 in CA\"] ca4[\"Sales in Store #4 in CA\"] ca --- ca1 ca --- ca2 ca --- ca3 ca --- ca4 end subgraph Texas tx1[\"Sales in Store #1 in TX\"] tx2[\"Sales in Store #2 in TX\"] tx3[\"Sales in Store #3 in TX\"] tx --- tx1 tx --- tx2 tx --- tx3 end subgraph Wisconsin wi1[\"Sales in Store #1 in WI\"] wi2[\"Sales in Store #2 in WI\"] wi3[\"Sales in Store #3 in WI\"] wi --- wi1 wi --- wi2 wi --- wi3 end The above tree is useful when thinking about the hierarchies. For example, it explicitly tells us that the sales in store #1, #2, #3 in TX should sum up to the sales in TX. We plotted the sales in CA as well as the individual stores in CA. We can already observe some synchronized anomalies. Summing Matrix \u00b6 The relations between the series is represented using an summing matrix \\(\\mathbf S\\) , which connects the bottom level series \\(\\mathbf b\\) and all the possible levels \\(\\mathbf s\\) 2 \\[ \\mathbf y(t) = \\mathbf S \\mathbf b. \\] Summing Matrix Example We take part of the above dataset and only consider the hierarchy of states, \\[ s(t) = s_\\mathrm{CA}(t) + s_\\mathrm{TX}(t) + s_\\mathrm{WI}(t). \\] The hierarchy is also revealed in the following tree. flowchart TD top[\"Total Sales\"] ca[\"Sales in California\"] tx[\"Sales in Texas\"] wi[\"Sales in Wisconsin\"] top --- ca top --- tx top --- wi In this example, the bottom level series are denoted as \\[ \\mathbf b(t) = \\begin{pmatrix} s_\\mathrm{CA}(t) \\\\ s_\\mathrm{TX}(t) \\\\ s_\\mathrm{WI}(t) \\end{pmatrix}, \\] and all the possible levels are denoted as \\[ \\mathbf y(t) = \\begin{pmatrix} s(t) \\\\ s_\\mathrm{CA}(t) \\\\ s_\\mathrm{TX}(t) \\\\ s_\\mathrm{WI}(t) \\end{pmatrix}. \\] The summing matrix is \\[ \\mathbf S = \\begin{pmatrix} 1 & 1 & 1 \\\\ 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\end{pmatrix}. \\] Makridakis S, Spiliotis E, Assimakopoulos V. The M5 competition: Background, organization, and implementation. Int J Forecast. 2022;38: 1325\u20131336. doi:10.1016/j.ijforecast.2021.07.007 \u21a9 Hyndman, R.J., & Athanasopoulos, G. (2021) Forecasting: principles and practice, 3rd edition, OTexts: Melbourne, Australia. OTexts.com/fpp3. Accessed on 2022-11-27. \u21a9","title":"Hierarchical Time Series Data"},{"location":"time-series/timeseries-hierarchical.data/#hierarchical-time-series-data","text":"Many real world time series data asserts some internal structure among the series. For example, the dataset used in the M5 competition is the sales data of different items but with the store and category information provided 1 . For simplicity, we simplified the dataset to only include the hierarchy of stores. Hierarchy Structure Visualization The simplified dataset can be found here . The original data can be found on the website of IIF . In this simplified version of the M5 dataset, we have the following hierarchy. flowchart LR top[\"Total Sales\"] ca[\"Sales in California\"] tx[\"Sales in Texas\"] wi[\"Sales in Wisconsin\"] top --- ca top --- tx top --- wi subgraph California ca1[\"Sales in Store #1 in CA\"] ca2[\"Sales in Store #2 in CA\"] ca3[\"Sales in Store #3 in CA\"] ca4[\"Sales in Store #4 in CA\"] ca --- ca1 ca --- ca2 ca --- ca3 ca --- ca4 end subgraph Texas tx1[\"Sales in Store #1 in TX\"] tx2[\"Sales in Store #2 in TX\"] tx3[\"Sales in Store #3 in TX\"] tx --- tx1 tx --- tx2 tx --- tx3 end subgraph Wisconsin wi1[\"Sales in Store #1 in WI\"] wi2[\"Sales in Store #2 in WI\"] wi3[\"Sales in Store #3 in WI\"] wi --- wi1 wi --- wi2 wi --- wi3 end The above tree is useful when thinking about the hierarchies. For example, it explicitly tells us that the sales in store #1, #2, #3 in TX should sum up to the sales in TX. We plotted the sales in CA as well as the individual stores in CA. We can already observe some synchronized anomalies.","title":"Hierarchical Time Series Data"},{"location":"time-series/timeseries-hierarchical.data/#summing-matrix","text":"The relations between the series is represented using an summing matrix \\(\\mathbf S\\) , which connects the bottom level series \\(\\mathbf b\\) and all the possible levels \\(\\mathbf s\\) 2 \\[ \\mathbf y(t) = \\mathbf S \\mathbf b. \\] Summing Matrix Example We take part of the above dataset and only consider the hierarchy of states, \\[ s(t) = s_\\mathrm{CA}(t) + s_\\mathrm{TX}(t) + s_\\mathrm{WI}(t). \\] The hierarchy is also revealed in the following tree. flowchart TD top[\"Total Sales\"] ca[\"Sales in California\"] tx[\"Sales in Texas\"] wi[\"Sales in Wisconsin\"] top --- ca top --- tx top --- wi In this example, the bottom level series are denoted as \\[ \\mathbf b(t) = \\begin{pmatrix} s_\\mathrm{CA}(t) \\\\ s_\\mathrm{TX}(t) \\\\ s_\\mathrm{WI}(t) \\end{pmatrix}, \\] and all the possible levels are denoted as \\[ \\mathbf y(t) = \\begin{pmatrix} s(t) \\\\ s_\\mathrm{CA}(t) \\\\ s_\\mathrm{TX}(t) \\\\ s_\\mathrm{WI}(t) \\end{pmatrix}. \\] The summing matrix is \\[ \\mathbf S = \\begin{pmatrix} 1 & 1 & 1 \\\\ 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\end{pmatrix}. \\] Makridakis S, Spiliotis E, Assimakopoulos V. The M5 competition: Background, organization, and implementation. Int J Forecast. 2022;38: 1325\u20131336. doi:10.1016/j.ijforecast.2021.07.007 \u21a9 Hyndman, R.J., & Athanasopoulos, G. (2021) Forecasting: principles and practice, 3rd edition, OTexts: Melbourne, Australia. OTexts.com/fpp3. Accessed on 2022-11-27. \u21a9","title":"Summing Matrix"},{"location":"time-series/timeseries-synthetic/","text":"Synthetic Time Series \u00b6 Synthetic time series data is useful in time series modeling, such as forecasting. Real world time series data often comes with complex dynamics in the data generating process . Benchmarking models using real world data often doesn't reflect the special designs in forecasting models. Synthetic time series data provides a good playground for benchmarking models as it can provide useful insights. Another application of synthetic data is to improve model performance. Synthetic data can be used to augment the training data 2 as well as in transfer learning 1 . A third application of synthetic data is data sharing without compromising privacy and business secret 3 . Though being useful, synthesizing proper artificial time series data can be very complicated as there are enormous amount of diverse theories associated with time series data. On the other hand, many time series generators are quite universal. For example, GAN can be used to generate realistic time series 4 . In this chapter, we will explain the basic ideas and demonstrate our generic programming framework for synthetic time series. With the basics explored, we will focus on a special cases of synthetic time series: time series with interactions. Rotem Y, Shimoni N, Rokach L, Shapira B. Transfer learning for time series classification using synthetic data generation. arXiv [cs.LG]. 2022. Available: http://arxiv.org/abs/2207.07897 \u21a9 Bandara K, Hewamalage H, Liu Y-H, Kang Y, Bergmeir C. Improving the Accuracy of Global Forecasting Models using Time Series Data Augmentation. arXiv [cs.LG]. 2020. Available: http://arxiv.org/abs/2008.02663 \u21a9 Lin Z, Jain A, Wang C, Fanti G, Sekar V. Using GANs for Sharing Networked Time Series Data: Challenges, Initial Promise, and Open Questions. arXiv [cs.LG]. 2019. Available: http://arxiv.org/abs/1909.13403 \u21a9 Leznik M, Michalsky P, Willis P, Schanzel B, \u00d6stberg P-O, Domaschka J. Multivariate Time Series Synthesis Using Generative Adversarial Networks. Proceedings of the ACM/SPEC International Conference on Performance Engineering. New York, NY, USA: Association for Computing Machinery; 2021. pp. 43\u201350. doi:10.1145/3427921.3450257 \u21a9","title":"Synthetic Time Series"},{"location":"time-series/timeseries-synthetic/#synthetic-time-series","text":"Synthetic time series data is useful in time series modeling, such as forecasting. Real world time series data often comes with complex dynamics in the data generating process . Benchmarking models using real world data often doesn't reflect the special designs in forecasting models. Synthetic time series data provides a good playground for benchmarking models as it can provide useful insights. Another application of synthetic data is to improve model performance. Synthetic data can be used to augment the training data 2 as well as in transfer learning 1 . A third application of synthetic data is data sharing without compromising privacy and business secret 3 . Though being useful, synthesizing proper artificial time series data can be very complicated as there are enormous amount of diverse theories associated with time series data. On the other hand, many time series generators are quite universal. For example, GAN can be used to generate realistic time series 4 . In this chapter, we will explain the basic ideas and demonstrate our generic programming framework for synthetic time series. With the basics explored, we will focus on a special cases of synthetic time series: time series with interactions. Rotem Y, Shimoni N, Rokach L, Shapira B. Transfer learning for time series classification using synthetic data generation. arXiv [cs.LG]. 2022. Available: http://arxiv.org/abs/2207.07897 \u21a9 Bandara K, Hewamalage H, Liu Y-H, Kang Y, Bergmeir C. Improving the Accuracy of Global Forecasting Models using Time Series Data Augmentation. arXiv [cs.LG]. 2020. Available: http://arxiv.org/abs/2008.02663 \u21a9 Lin Z, Jain A, Wang C, Fanti G, Sekar V. Using GANs for Sharing Networked Time Series Data: Challenges, Initial Promise, and Open Questions. arXiv [cs.LG]. 2019. Available: http://arxiv.org/abs/1909.13403 \u21a9 Leznik M, Michalsky P, Willis P, Schanzel B, \u00d6stberg P-O, Domaschka J. Multivariate Time Series Synthesis Using Generative Adversarial Networks. Proceedings of the ACM/SPEC International Conference on Performance Engineering. New York, NY, USA: Association for Computing Machinery; 2021. pp. 43\u201350. doi:10.1145/3427921.3450257 \u21a9","title":"Synthetic Time Series"},{"location":"topics/intro/","text":"Topics \u00b6","title":"Introduction"},{"location":"topics/intro/#topics","text":"","title":"Topics"},{"location":"topics/ltd-ltp/","text":"LTD/LTP \u00b6","title":"LTD/LTP"},{"location":"topics/ltd-ltp/#ltdltp","text":"","title":"LTD/LTP"},{"location":"topics/predictive-coding/","text":"Predictive Coding Approximates Backprop along Arbitrary Computation Graphs \u00b6","title":"Predictive Coding"},{"location":"topics/predictive-coding/#predictive-coding-approximates-backprop-along-arbitrary-computation-graphs","text":"","title":"Predictive Coding Approximates Backprop along Arbitrary Computation Graphs"},{"location":"tags/","text":"Tags \u00b6 Following is a list of relevant tags:","title":"Tags"},{"location":"tags/#tags","text":"Following is a list of relevant tags:","title":"Tags"}]}